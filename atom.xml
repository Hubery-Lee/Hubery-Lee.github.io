<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hubery-Lee</title>
  
  <subtitle>蒹葭苍苍，白露为霜</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://hubery-lee.github.io/"/>
  <updated>2021-03-20T04:08:01.306Z</updated>
  <id>https://hubery-lee.github.io/</id>
  
  <author>
    <name>李会</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>综述-便携式gamma相机</title>
    <link href="https://hubery-lee.github.io/2021/03/20/%E7%BB%BC%E8%BF%B0-%E4%BE%BF%E6%90%BA%E5%BC%8Fgamma%E7%9B%B8%E6%9C%BA/"/>
    <id>https://hubery-lee.github.io/2021/03/20/%E7%BB%BC%E8%BF%B0-%E4%BE%BF%E6%90%BA%E5%BC%8Fgamma%E7%9B%B8%E6%9C%BA/</id>
    <published>2021-03-20T04:06:55.000Z</published>
    <updated>2021-03-20T04:08:01.306Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Portable-Gamma-Camera-for-Nuclear-Power-Plants"><a href="#Portable-Gamma-Camera-for-Nuclear-Power-Plants" class="headerlink" title="Portable Gamma Camera for Nuclear Power Plants"></a>Portable Gamma Camera for Nuclear Power Plants</h1><p><strong>SONG *<em>YuShou1, *</em>LI</strong> <strong>Hui</strong> 1, <strong>HU Liyuan1,</strong> <strong>HOU</strong> <strong>Yingwei1</strong>, LIU Huilan1 </p><p><strong>Abstract:</strong> Gamma camera is a powerful tool to locate radioactive sources and contaminations in nuclear facilities. It is widely used in activities decommission, decontamination, maintenance and emergency response of nuclear power plants (NPPs). In recent decades, especially after the Fukushima nuclear accident a big progress has been made for this technique. A brief review of the principles and characteristics of three predominant imaging approaches are presented. The existing practical applications are summarized and potential application fields are discussed. </p><p><strong>Keyword:</strong> portable gamma camera; nuclear power plants; decommission; emergency response</p><a id="more"></a><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p>The nuclear emergency response has attracted much attention since the most recent nuclear catastrophe in Fukushima in 2011[1,2]. The investigation of the radioactive isotopes is very important for the activities of response and evacuation of the citizens around the power plants. The excellent performance of a gamma camera in radiation detection had attracted much attention. The gamma camera application for nuclear disaster response can be retrospect to the Chernobyl nuclear power plants accident [3-5]. A gamma camera equipped with a pinhole collimator called Gamma-Visor was used in the emergency response. It was developed by the Kurchatov Institute of Russia.</p><p>Before Chernobyl disaster, a series of devices for imaging gamma sources had been used in nuclear medicine and astrophysics research [6, 7]. Anger Camera is a famous gamma camera applied in nuclear medicine. Multichannel collimators are used to form gamma images on a position sensitive detector. However, the industrial products of gamma camera used in medicine and astrophysics are not fit to inspect the radiation of nuclear power plants (NPPs). The containment of an NPP is filled with instruments and there is high level of radiation. It requited that a gamma camera should a small dimensions and light weight and can be controlled remotely. Further, the multichannel collimator is not able to visualize the radiation contaminated objects at a distance. And the multichannel collimator intended for medical application is not able to image the radioactive object at a distance.</p><p>Consequently, several research groups developed portable gamma cameras for NPPs [2, 4, 8, 9], which can be mounted on a tripod or a mobile robot. They can be used to access radiation premise in the NPPs (Nuclear Power Plants) and inspect the radiation distribution during emergency response [10-15] and decommissioning [16-22]. In accidents of nuclear power plants, gamma cameras are supposed to provide the information about the leakage, contamination of radioactive matter to the emergency response. With the developments of nuclear power industry for decades, a lot of commercial and research nuclear plants have reached the end of their operating lifetime and are being shut-down. Before disassembling the reactors, the instruments in the reactor need to be decontaminated. Optimal decontamination strategies need to be used to minimize the staff radiation exposure according to the character of the contamination. The gamma camera is also a powerful tool to investigate the radiation contaminations [16-21, 23].</p><p>This report gives an overview of the different gamma cameras used for the NPPs. The following three sections (section 2 to section 4) describe the three imaging approaches of the existing gamma cameras: the pinhole[4], the coded mask[24, 25] and the Compton scatter[26-28], respectively. The evolution of image processes and radiation sensors is discussed in section 5 and section 6, and a future perspective is placed in section 7. A summary is given in the last section.</p><h2 id="2-The-pinhole-gamma-camera"><a href="#2-The-pinhole-gamma-camera" class="headerlink" title="2 The pinhole gamma camera"></a>2 The pinhole gamma camera</h2><p>The pinhole collimated gamma camera is based on the pinhole imaging principle [3-5, 8, 29-31]. The schematic diagram of the measuring head of pinhole collimated gamma camera is shown in Fig. 1. It consists of pinhole collimator, portable position sensitive detector, lead or tungsten alloy shielding, video camera and collimator stopper (shutter or filter).</p><p>​                 <img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210320115551843.png" alt="image-20210320115551843">       </p><p>Fig. 1 The schematic diagram of the gamma camera with the pinhole collimator</p><p>The overturned gamma image of the visualized radioactive object is projected by the two-cone pinhole collimator. The diameter of the mini part of the collimator is less than 10mm. The distance between the pinhole and the scintillator is a constant as designed. Position sensitive scintillator matrix is connected with the image intensifier. The image intensifier composes of fiber tapers and photomultiplier or photodiode. The image intensifier connects with the CCD matrix to convert the radiation signal to digital signal which can be saved to the computer and used to reconstruct the composited image. A feature of this kind of gamma camera is the shutter in front of the collimator. When the shutter is closed, the background is measured, which may be used to eliminate the specific background from the image measured with the shutter open. With the shutter, one may increase the signal-to-noise ratio, meanwhile not increase the shielding.</p><p>In the 1980s, researchers began to use gamma cameras in the field of searching the radiation source at NPPs. The Kurchatov Institute of Russia and the European research team CEA (French Alternative Energies and Atomic Energy Commission) developed their gamma cameras respectively [2, 4, 8, 9].</p><p>The Gamma Visor prototype was designed by the Kurchatov Institute. The industrial products were applied to inspect the near-reactor premises under the complex gamma field conditions of high contaminated nuclear facilities in Russia and Germany. It is shown that the application of the portable gamma-ray imager is the fastest way for search and identification of the most contaminated fragments of equipment. In addition, it is verified that the major contaminated parts of the pipelines are their bends, places of pipes connection, and valves [3-5, 30, 31]. The gamma-ray imager also discovered some fragments with high contamination level which were not known earlier. For example, around the connection of two pipes the radioactive contamination concentrated much more at the weld place rather than the connecting place.</p><p> <img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210320115617646.png" alt="image-20210320115617646"></p><p>Fig. 2 The schematic diagram of gamma camera imaging on films</p><p>At the same time, CEA also developed a pinhole-collimated gamma camera independently. It images gamma radiation and visual-light on films[29]. The schematic diagram is showed in Fig. 2. Two different types of films are presented for gamma ray sources and visible-light objects imaging respectively. The images are formed by exposing twice: once for the gamma rays sources with the shutter closed, and the second time for visual-lights objects with the shutter open. This device obtained a typical image which revealed the contamination inside a valve during a measurement campaign in the EDF power station at Bugey in 1985[29]. The brief design and its simple operation ensure the reliability in industrial applications. The most distinctive characteristic is that the device does not require electronic signal processing system and external power supply. The film allows for a wide dynamic energy range and permits simultaneous exposure of several emulsions with different sensitivities to cover a wide range of dose rates. The apparent disadvantage is its inherent offline measurement. The unit has to be placed blindly and the interesting field of view (FOV) can not be determined without the knowledge of the premises. The device must be set up after each exposure; and the handling operations before and after each exposure (cutting film sheets, placing them in the proper sequence, insertion in the chamber, removal, development, drying, etc.) must be performed with considerable care. The most serious drawback is the long exposure time (up to 24 hours) necessary to obtain a suitable image, which limits the application as a real-time monitor.</p><p>CEA improved the film gamma camera to be an advanced online measuring system later [29]. It developed ALADIN, which adopted a scintillator radiation sensor CsI and an electronic data acquisition system. The angular resolution ranged from 1°to over 4°which depended on the radiation energy, the type of collimators used and the FOV of the device. A novel feature of ALADIN is that the visible-light image and gamma image are both obtained using the same acquisition system. </p><p>In recent years, the Argonne National Laboratory developed a gamma camera using pinhole collimator RadSearch. It employs a sensitive and highly collimated LaBr3 scintillator as the detector head. An optical camera with controllable zoom and focus and a laser range finder are used to localize the objects. The schematic diagram of RadSearch detector head is shown in Fig. 3. The radiation sensor LaBr3 scintillator is shielded by tungsten. The collimator is made up of steel barrel and steel filter insert which has the similar function as the shutter of Gamma Visor.</p><p> <img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210320115644300.png" alt="image-20210320115644300"></p><p>Fig. 3 The schematic diagram of RadSearch detector head</p><p>The detector head is mounted on a pan/tilt mechanism with a range of motion of 360 degree (pan) and 180 degree (tilt). The scan process is based on a rectangular grid scan of an area or object, which is known as the Scan Area or Scan Grid. The Scan Area is divided into rectangular Scan Elements, each of which is either equal to or less than the detector field of view, either 4 degrees with the collimator barrel fitted or 18 degrees with the collimator barrel removed. In normal operation, RadSearch provides a video image of the object or surface with a colored overlay showing the distribution of radioactivity. A gamma-ray spectrum is obtained for each Scan Element. From each measured spectrum a number of different radionuclides can be identified. And the radioactive source distribution can be determined according to the distribution of the counting rates in the scan area. The activity of different radionuclides and their spatial distribution in a waste container can be given by this instrument. Based on such information, one may establish the approach to assay canisters prior to processing [22, 32, 33]. </p><p>The instrument is portable and the combined weight of all the components (including the tripod) is less than 54 kg. Therefore, it can be deployed by a single person in less than 10 min. During the measurement, the device can be controlled remotely. The device can be controlled wireless and modularized. Thus, it can be mounted on a tripod or mobile robot. The remote monitoring station makes up of a notebook computer and small power supply unit. RadSearch is normally operated from a notebook computer, which can be located up to 100 meters away from the detector head with the power supply unit. The device can be deployed readily indoors or in the field by an operator. Software allows both automatic and manual operation; and an operator can specify coordinates to search a specific position or area. A search can be conducted automatically in 4π steradians, using the full capabilities of the pan/tilt mechanism.</p><p>China Academy of Engineering Physics developed a portable radionuclide identification system[34]. This system is a gamma ray spectrometer using a scintillator detector and a pulse height multi-channel analyzer. It can help to inspect the outflow of NPPs securing the radioactive safety. This portable gamma spectrometer consists of alternative LaBr3 or NaI detector (according to user demand) and a panel computer. The communication between the panel computer and the detector can be by Bluetooth and USB. With the Bluetooth type connection, the maximum distance between the detector and the panel computer is 15 meters. It has two types of measurement model, 30 s and 120 s for identifying different radionuclides. The experimental test shows that 30 s is long enough to identify radionuclides successfully. The data for different radionuclide is saved in the panel computer. The artificial neutral network algorithm is adopted to perform the nuclide identification.</p><h2 id="3-The-coded-mask-gamma-camera"><a href="#3-The-coded-mask-gamma-camera" class="headerlink" title="3 The coded mask gamma camera"></a>3 The coded mask gamma camera</h2><p>During the development of these pinhole gamma camera products, researchers found out the fact that the sensitivity of a gamma camera increases and the angle resolution decreases with enlarging the diameter of the pinhole aperture. For example, two pinhole collimators with FOVs of 30°and 50°were provided to form gamma image for CARTOGAM. In Table 1 the FWHM values measured at 660keV (137Cs) and 1.25MeV (60Co) are listed for different camera configurations. According to Table 1, we can see that gamma cameras equipped with 30°pinhole collimator has better spatial resolution than fixed with 50°pinhole collimator. And if a gamma camera equips with the same FOV collimator, the 2 millimeter thick scintillator has better spatial resolution.</p><p><strong>Table 1</strong> <strong>The angular response (FWHM) of CARTOGAM measured for different gamma energies, scintillator thicknesses and collimator types</strong></p><table><thead><tr><th></th><th>241Am  (59keV)</th><th>137Cs  (660keV)</th><th>60Co  (1.25MeV)</th><th></th><th></th></tr></thead><tbody><tr><td>Thickness</td><td>4mm</td><td>2mm</td><td>4mm</td><td>2mm</td><td>4mm</td></tr><tr><td>30°collimator</td><td>2.0°</td><td>1.9°</td><td>2.3°</td><td>2.8°</td><td>3.2°</td></tr><tr><td>50°collimator</td><td>3.1°</td><td>3.3°</td><td>4.6°</td><td>6.1°</td><td>6.7°</td></tr></tbody></table><p>Using a pinhole to image is very simple in principle but very inefficient in practice. A highly attractive alternative is to substitute the pinhole with a coded mask collimator. The coded mask collimated gamma camera is also composed of a radiation detector and a video camera. The radiation detector consists of a coded mask, a scintillator plate, image intensifiers, and CCD matrix. The principle of the measuring process is as follows. </p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210320120136574.png" alt="image-20210320120136574"></p><p>(a)</p><p> <img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210320120152625.png" alt="image-20210320120152625"></p><p>(b)</p><p>Fig.4 The imaging procedure for a camera with code masks collimator (a) and its structural schematic (b). </p><p>Gamma rays interact with scintillator crystal, fluorescing and forming the radiation image which is modulated by the coded mask. The coded images should be decoded by the computer to get the images which reflect the radiation distribution accurately (Fig.4 (a)). Such coded masks have been designed and used for several decades, mainly for astrophysical applications [6, 7], but in most cases their size is of the magnitude of 1m. So that it can not be used in the premises of NPPs. And the video camera obtains the visual light images. The schematic diagram of gamma-imaging structural using coded mask collimator is shown in Fig.4 (b).</p><p>CEA and the Kurchatov Institute both had their products using coded mask collimators. The ALADIN and CARTOGAM gamma camera developed by the CEA was tested combining with a very compact coded-mask [25, 35-37]. Based on the experience of developing the pinhole gamma camera, Gamma Visor, the Kurchatov Institute used coded mask collimators on gamma cameras for nuclear reactor decontamination and decommissioning missions for the first time in 1999[31, 38-41]. </p><p>The coded aperture mask is used to optimize the trade-off between the sensitivity and the spatial resolution. Three HURA (hexagonal uniformly redundant array) masks had been fabricated and tested, with different numbers of holes and thicknesses (Table 2), and fixed to ALADIN and CARTOGAM. The results of the first tests in laboratory showed a gain of a factor between 5 and 20 in sensitivity (according to the exposure) compared to the pinhole configuration, and a factor between 2 and 2.5 in angular resolution (according to gamma energy)[25]. They also demonstrated the ability of this device to efficiently remove the background noise, thanks to a mask pattern anti-symmetric by 60 degree rotation.</p><p><strong>Table</strong> <strong>2</strong> <strong>Characteristics of the masks</strong></p><table><thead><tr><th>Mask</th><th>Rank 6</th><th>Rank 9</th></tr></thead><tbody><tr><td>Thickness</td><td>12mm</td><td>6mm</td></tr><tr><td>Distance  between holes</td><td>1.85mm</td><td>1.26mm</td></tr><tr><td>Number of  holes in central pattern</td><td>64</td><td>136</td></tr><tr><td>Open area</td><td>1.9cm2</td><td>1.9cm2</td></tr></tbody></table><p>Mask/anti-mask procedure was applied to CARTOGAM and it can also base on a ninety degrees rotation of the coded mask (Fig. 5). Two acquisitions were required (one in mask position, the other in anti-mask position) and the raw image is obtained by decoding the subtraction of these two gamma images. A measurement carried out in the NPPs site illustrates the mask/anti-mask procedure is efficient in removing the background radiation.</p><p> <img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210320115729316.png" alt="image-20210320115729316"></p><p>Fig.5. Coded masks. On the left: mask position. On the right: anti-mask position (nighty degrees rotation of the mask)</p><h2 id="4-The-Compton-gamma-camera"><a href="#4-The-Compton-gamma-camera" class="headerlink" title="4 The Compton gamma camera"></a>4 The Compton gamma camera</h2><p>The pinhole and the coded mask cameras are supposed to give 2D radiation source distributions. To acquire the distance between the gamma camera and the radiation source, laser range finder is invoked.  Or measurements more than twice at different positions are performed (see Fig 6). The distance can be calculated by triangulation [42-44]. </p><p> <img src="../../../AppData/Roaming/Typora/typora-user-images/image-20210320115804200.png" alt="image-20210320115804200"></p><p>Fig. 6 The principle of locating the source position in three dimensions</p><p>In order to obtain the 3D radiation distribution more conveniently and effectively, a Compton camera has been was proposed. Compton camera is a device which can locate the incident direction of gamma rays based on the Compton kinetics by measuring the energy deposition and interaction positions in the scatter and absorber (Fig. 7). </p><p> <img src="../../../AppData/Roaming/Typora/typora-user-images/image-20210320115813859.png" alt="image-20210320115813859"></p><p>Fig. 7 The schematic diagram of the Compton gamma camera</p><p>The scatter and absorber scintillator are position sensitive. Actually, if the two interaction position of a gamma ray in the radiation sensor can be determined, the incident direction of the gamma ray can be calculated by equation (1). </p><p>​         <img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210320115830895.png" alt="image-20210320115830895">    (1)</p><p>In the equation (1), θe is the Compton scatter angle. E1 is the energy deposited in scatter and E2 is the energy deposited in the absorber. me is the energy mass of scattered photoelectron. The direction of each incident photon is on the surface of a cone with its vertex at the first interaction position. The line connecting the scattering point and absorption point is the axis of symmetry. The back-projection cone of each photon passes through the source position. Thus, the source direction can be reconstructed with the overlap of the cones.</p><p>A research team from Japan developed a handheld Compton camera for the catastrophe in the Fukushima Daiichi Nuclear Power Station [1, 2]. This device can be used to detect the depth of the radioactive sources embedded under the contaminated surface[1]. The Compton camera (14cmÍ15cmÍ 16cm, 2.5kg) uses Ce:GAGG (Ce doped Gd3Al2Ga3O12) crystal as the detector [1, 2, 26, 45]. The angular resolution is ~8 degree (FWHM) for a 137Cs source. The handheld Compton camera realizes a 180 degree FOV with sensitivity   1% for 662 keV gamma rays. The performance is satisfied in tests. </p><p>Dan Xu et al. from the University of Michigan also developed a compact Compton camera Polaris-H imaging spectrometer supported by DOE and DHS in 2004 [27, 28, 46, 47]. Polaris-H was designed to obtain the radiation distribution and identify isotopic composition of the sources on nuclear power plants premises. It integrates a 3D-position sensitive pixelated CdZnTe detector (20mmÍ20mmÍ15mm), associated with readout electronics, an embedded computer, a 5h battery, and an optical camera in a portable waterproof enclosure [9, 48-55]. The total mass is about 4 kg, and the system startup time is 2 min. The energy resolution is nearly 1.0% (FWHM) for 137Cs. </p><h2 id="5-The-visible-light-image"><a href="#5-The-visible-light-image" class="headerlink" title="5 The visible-light image"></a>5 The visible-light image</h2><p>In order to investigate the distribution of surface contamination and to locate the radioactive sources, a gamma camera is usually qualified with both radiation and vision imaging. The radiation detector is used to acquire radiation image and the optical camera is used to obtain optical image within the same detection direction and correlative FOV. Both ALADIN and Gamma Visor provide vision image in addition to the radiation image. The independent visible light imaging system of Gamma Visor performs better in the field testing in comparison with ALADIN. With separate imaging systems for radiation and visible light, the dual images usually are composited by the algorithm of maximum likelihood expectation maximization (MLEM) method or wavelet transform. </p><p> <img src="../../../AppData/Roaming/Typora/typora-user-images/image-20210320115858234.png" alt="image-20210320115858234"></p><p>(a)</p><p> <img src="../../../AppData/Roaming/Typora/typora-user-images/image-20210320115906581.png" alt="image-20210320115906581"></p><p>(b)</p><p>Fig. 8 Two principles of combining the FOV of gamma camera with optical camera</p><p>But the prerequisite is to make the detect direction and FOV of optical camera and radiation detector as consistent as possible (Fig.8) [56-58]. Usually the FOV of an optical camera is bigger than a radiation detector. It is feasible that we just make FOV of radiation detector central axis combine with that of optical camera as close as possible (Fig.8 (a)). Therefore, composited image will reflect the radioactive source contamination position in the scene precisely. This method has been most widely applied to gamma camera. It not only used in NPPs, but also used in medicine and astrophysical research.</p><p>There is another way to get the FOV of optical camera agreed with gamma detector by using a mirror to separate visible lights and gamma rays (Fig.8 (b)). It can improve the location accuracy of the radioactive source in the measuring site from the superimposed image. It can also protect the optical camera from the radiation damage and it reduces the influence of the electronics noise caused by the irradiation. However, the device is heavy shielded owing to the gamma detector and the optical camera both locating after the collimator and the shielding material. Using mirror to get the FOV of the optical camera and radiation detector consistent is usually applied to the gamma camera used in medicines for the low environment radiation level and no limited volume size. Actually, if the distance between gamma camera and the radiation source is far away, there is not much difference on the radiation location accuracy adopting measuring method Fig 8.</p><h2 id="6-The-radiation-sensor"><a href="#6-The-radiation-sensor" class="headerlink" title="6 The radiation sensor"></a>6 The radiation sensor</h2><p>The radiation sensor is the critical component of a gamma camera, which in some degree determines the sensitivity and the spatial resolution. </p><p>The inorganic scintillator, such as NaI(Tl), CsI(Tl), CdWO4 and LaBr3 are widely used to detect gamma rays. Comparing with other scintillators, NaI(Tl) scintillator crystal has the highest light response. Cesium having larger Z than sodium, CsI has higher detection efficiency than NaI. That is why the CsI is widely used in a gamma camera, for example, Gamma Visor and ALADIN. In comparison with other inorganic scintillator, the light response of CdWO4 crystal is more stable against temperature change. This is the reason it can be used in high radiation level premises. Its’ signal decay time is longer and the wavelength of the emission spectrum is in the range of 400-500nm, which make it fit for coupling with photodiode. The CdWO4 radiation sensor is used in the detection system of the MR and RTF research reactor decommission mission [16, 18, 21]. The recently appearing LaBr3 with an energy resolution of 2.5% to 3% is an excellent room-temperature working scintillator. It has been applied to RadSearch. The energy resolution of LaBr3 detector is much better than NaI detector.</p><p>However, Gamma Visor, ALADIN and RadSearch are still very heavy and the weight of each of them is more than 30 kg. Semiconductor radiation sensor is becoming a new research hotspot for its portable volume, high energy resolution and fast readout speed. The hybrid detector combining the Medipix/Timepix with semiconductor detector has also appeared. CEA and the Kurchatov Institute developed a new gamma camera GAMPIX using the hybrid detector (Fig. 9)[24, 59, 60]. GAMPIX has achieved technological breakthroughs in terms of sensitivity (energy range from 241Am to 60Co), portability (1 kg) and deployment time (a few minutes) in comparison with the existing industrial gamma camera [24, 25, 35-37, 41, 59-65]. When GAMPIX, ALADIN and CARTOGAM are equipped with a pinhole collimator with 50 degree aperture to image a 137Cs point source, GAMPIX achieves the best image quality, although its intrinsic detection efficiency is lower than that of the 4 mm CsI doped Thallium scintillator (4.5% vs. 13% at 662keV).</p><p> <img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210320115922630.png" alt="image-20210320115922630"></p><p>Fig. 9 The schematic diagram of the semiconductor combined with Medipix/Timepix gamma camera with the coded mask</p><h2 id="7-Future-perspectives"><a href="#7-Future-perspectives" class="headerlink" title="7 Future perspectives"></a>7 Future perspectives</h2><p>Gamma cameras have multi-applications in NPPs. It can be used to locate the primary source terms and to find discrete radioactive particles, helping to optimize the shielding of the individual working area by identifying the primary contribution to the dose from each isotope. It can also be used to locate isotopes in shipping containers, to locate and track crud in pipes and valves and to track sources through time. It can be applied to identify fuel failure, to verify clean-up work quality and to determine the spatial extent of contamination, too. Further, it can be used to characterize and qualify isotopes, to fill in blank areas of traditional survey maps and to help to respond to an emergency. Different application instances of the gamma camera are stated in the following. As mentioned above, the Gamma Visor was used in the Chernobyl nuclear accident and the advanced coded mask Gamma Visor was used in decommissioning of the Russia MR and RTF research reactors in 2008[17, 20, 21]. The RadSearch was applied to detect the radiation distribution of the NPPs waste container for optimizing the arrangement of the waste container [22, 32, 33]. The handy Compton camera and the Polaris-H are used in accident of the Fukushima Daiichi Nuclear Power Station to investigate the radiation distribution for reactor emergency response [1, 2, 9, 28, 48]. Gamma camera can be mounted on the tripod or mobile robot for remotely controlled measurements. Kinoshita H, Tayama R, Kometani E Y, et al developed a vehicle mounted Gamma Camera associating with plastic scintillator fiber to detect the gamma radiation of the premises of the Fukushima Daiichi Nuclear Power Station[13]. Japanese also developed many nuclear emergency robots, such as SMERT-M, SMERT-K and MARs, on which the gamma camera mounted [10-15]. Besides, the Canadian research team of University of Ontario Institute of Technology developed a semi-autonomous directional and spectroscopic radiation detection mobile platform, the gamma camera mounted on this platform just can detect the direction on which source located without other sensitive information[66]. </p><p>The different characters of the different gamma cameras are shown in Table 3. The main differences between pinhole and coded mask gamma camera are the collimator and the imaging process. Compared with the pinhole collimator, the coded mask camera has achieved a trade-off between sensitivity and spatial resolution[25, 67]. Their common ability is to obtain 2D images of the radiation source distribution. To get the radiation 3D distribution, one may employee a Compton camera [28, 45, 46]. The big detection FOV allows Compton gamma camera to scan a contaminated area more quickly. At the same time, there are some issues supposed to be improved for the structure, data acquisition, and imaging process in the future [26-28, 68]. For example, the angle resolution of the handy Compton camera is ~8 degree, which is poorer than that of (4 degree) the traditional pinhole gamma camera ALADIN.</p><p>Benefitting from the development of semiconductor industry and large scale integrated circuit technology the radiation sensor and electric readout system have been improved dramatically in recent decades. The weight of any one of ALADIN, CARTOGAM and Gamma-Visor is more than 15 kg. However, GAMPIX adopting semiconductor radiation sensor is only 2kg weight and can be arranged with pinhole collimator or coded mask. Further, the high angular resolution will make them more conveniently used in the investigation of contamination distribution. The negative parts are the semiconductor chip can not be manufactured with big size and it degenerates with the radiation dose increase. Because the semiconductor devices on the chip are highly integrated, heat dissipation auxiliary should be equipped, e.g. an air cooling fans is fixed for Polaris-H.</p><p>In addition to improve the working performance of the contents of a gamma camera, some innovations on design also appear in recent years. Shifeng Sun et al. from China developed a panorama coded-aperture gamma camera for radiation detection[69]. The overall dimensions of this device are about 42Í42Í80 cm3; the system is based on six typical coded-aperture gamma camera which arranged in a hexagonal shape with a 10 mm thick copper shield. Every detector module is isolated from its adjacent modules by a 12 mm thick rectangular lead for radiation shielding. Three masks and three anti-masks are placed in front of six detector module at intervals. These masks form a mask layer isolated from the detector modules. And mask layer can rotate 60 degree for mask and anti-mask acquisition and subtraction. It is convenient to get mask and anti-mask switching by once set, because of that the adjacent masks are the anti-mask to current module. This panorama gamma camera has a FOV of 360 degree in the horizontal direction and 60 degree in the vertical direction. Compared with the standard coded mask gamma cameras, this system has higher detection efficiency and suitably applies to more complicated radiation environment. </p><p>Pinhole and coded mask gamma cameras use mechanical collimation which relies on photon absorption with a FOV defined by the aperture size. While Compton gamma camera adopts electronic collimation to define the FOV, which based on the Compton scattering that relates the energy of a scattered photon to it direction. Because photo absorption is dominant in low energies, whereas Compton scattering prevails at higher energies, the effective energy range of a single gamma camera mentioned above is limited to either the low or the high energy ranges. Wonho Lee [43, 70] combined these two collimation models in one gamma camera. The scattering-layer scintillator detectors and the mask make up a coded mask gamma camera. At the same time the scattering-layer scintillator matrix and the absorbing-layer scintillator matrix constitutes a Compton gamma camera. So it can be seen as a hybrid of coded mask gamma camera and Compton gamma camera, simultaneously collecting information from both mechanical and electronic collimation to reconstruct a single composited image. The hybrid system performs better in a wide energy range. To improve the detection efficiency of this hybrid system and improve the image quality, some researchers replaced the convention collimator with scintillating crystals and called it an active collimation [71-73]. The scintillation crystals mask can not only shield the radiation, but also obtain position and energy deposition.</p><p><strong>Table3</strong> <strong>Different characteristics</strong> <strong>of</strong> <strong>multi-type</strong> <strong>gamma cameras</strong></p><table><thead><tr><th>Characters</th><th>Pinhole gamma camera</th><th>Coded mask gamma camera</th><th>Compton gamma camera</th></tr></thead><tbody><tr><td>Collimator</td><td>Two conical collimator</td><td>Coded multi aperture  collimator</td><td>Without collimator</td></tr><tr><td>Decoding Image process</td><td>No</td><td>Yes</td><td>No</td></tr><tr><td>3D positioning</td><td>No</td><td>No</td><td>Yes</td></tr><tr><td>Sensitivity</td><td>Low</td><td>Relative high</td><td>High</td></tr><tr><td>Measurement time</td><td>Hours to day</td><td>Several minutes to hours</td><td>Several minutes to hours</td></tr><tr><td>Angular resolution</td><td>High</td><td>High</td><td>Low</td></tr><tr><td>Operation</td><td>Remote</td><td>Remote</td><td>Remote</td></tr></tbody></table><h2 id="8-Summary"><a href="#8-Summary" class="headerlink" title="8 Summary"></a>8 Summary</h2><p>Gamma cameras used in NPPs are compact, modular and have high sensitivity and angular resolution. Efforts have been made to improve these performances. A gamma camera can be equipped with both pinhole collimator and coded mask collimator. A larger diameter of the collimator hole means higher sensitivity but lower angular resolution. One may balance the sensitivity and spatial resolution according to a concrete application. A Compton camera obtains images without a collimator, so that it gets rid of the limitation of sensitivity and angular resolution due to the collimator. However, the angle resolution of a Compton camera is not as good as a pinhole or a coded mask gamma camera. The radiation sensor also influences the detection efficiency, energy resolution and image quality. Scintillator (e.g. CsI(Tl) ) is widely used as the radiation sensor in a portable gamma camera. Semiconductor has superiorities in the compact volume and integration of the sensor and the electronic readout system. The spatial resolution can also be improved for semiconductor detectors for their high energy resolution. Besides the improvements on the performance of components of gamma camera, some innovate design of gamma cameras have also been proposed recent years. </p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1]   Y. IWAMOTO, J. KATAOKA, A. KISHIMOTO.: Novel methods for estimating 3D distributions of radioactive isotopes in materials, Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment, 831 (2016) 295-300.</p><p>[2]   J. KATAOKA, A. KISHIMOTO, T. NISHIYAMA.: Handy Compton camera using 3D position-sensitive scintillators coupled with large-area monolithic MPPC arrays, Nuclear Instruments &amp; Methods in Physics Research, 732 (2013) 403-407.</p><p>[3]   O.P. IVANOV, A.V. CHESNOKOV, V.E. STEPANOV.: Gamma-vision camera real-time system for creating images of gamma-radioactive objects, International Conference on Systems, Man and Cybernetics, 1993. &#39;systems Engineering in the Service of Humans&#39;, Conference Proceedings, 1993, pp. 1-6 vol.3.</p><p>[4]   A.N. SUDARKIN, O.P. IVANOV, V.E. STEPANOV.: Portable gamma-ray imager and its application for the inspection of the near-reactor premises contaminated by radioactive substances, Nuclear Instruments &amp; Methods in Physics Research, 414 (1998) 418-426.</p><p>[5]   A.G. VOLKOVICH, O.P. IVANOV, V.E. STEPANOV.: Application of a gamma viewer for examining reactors, Atomic Energy, 79 (1995) 772-775.</p><p>[6]   E. CAROLI, J.B. STEPHEN, G.D. COCCO.: Coded aperture imaging in X- and gamma-ray astronomy, Space Science Reviews, 45 (1987) 349-403.</p><p>[7]   R.H. DICKE.: Scatter-Hole Cameras for X-Rays and Gamma Rays, Astrophysical Journal, 153 (1968) L101.</p><p>[8]   K.A. HUGHES, J.A. LIGHTFOOT.: RadScan 600-a portable instrument for the remote imaging of gamma contamination: its design and use in aiding decommissioning strategy, Nuclear Science Symposium, 1996. Conference Record, 1996, pp. 930-933 vol.932.</p><p>[9]   C.G. WAHL, W.R. KAYE, W. WANG, F. ZHANG.: The Polaris-H imaging spectrometer, Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment, 784 (2015) 377-381.</p><p>[10]  J. ABOUAF.: Trial by fire: teleoperated robot targets chernobyl, IEEE Computer Graphics and Applications, 18 (1998) 10-14.</p><p>[11]  Y. HOSODA, H. YAMAMOTO, M. HATTORI.: &#39;SWAN&#39;: A robot for nuclear disaster prevention support, Advanced Robotics, 16 (2002) 485-488.</p><p>[12]  Y. ISOZAKI, K. NAKAI.: Development of a work robot with a manipulator and a transport robot for nuclear facility emergency preparedness, Advanced Robotics, 16 (2002) 489-492.</p><p>[13]  H. KINOSHITA, R. TAYAMA, E.Y. KOMETANI.: Development of new technology for Fukushima Daiichi nuclear power station reconstruction, Hitachi Review, 63 (2014) 183.</p><p>[14]  M. OTAKI.: Environmental monitoring robots for nuclear emergencies, Advanced Robotics, 16 (2002) 501-504.</p><p>[15]  Y. YUGUCHI, Y. SATOH.: Development of a robotic system for nuclear facility emergency preparedness—observing and work-assisting robot system, Advanced Robotics, 16 (2002) 481-484.</p><p>[16]  A. CHESNOKOV, O. IVANOV, V. KOLYADIN.: HLRW Management During MR Reactor Decommissioning in NRC “Kurchatov Institute”, ASME 2013 15th International Conference on Environmental Remediation and Radioactive Waste Management, American Society of Mechanical Engineers, 2013, pp. V001T002A008-V001T002A008.</p><p>[17]  A. DANILOVICH, O. IVANOV, A. LEMUS.: Radiological survey of contaminated installations of research reactor before dismantling in high dose conditions with complex for remote measurements of radioactivity. 2012, WM2012 Conference, February, 2012.</p><p>[18]  O. IVANOV, A. DANILOVICH, V. STEPANOV.: Remote Measurements of Radioactivity Distribution With BROKK Robotic System, ASME 2009 12th International Conference on Environmental Remediation and Radioactive Waste Management, American Society of Mechanical Engineers, 2009, pp. 157-159.</p><p>[19]  O. IVANOV, V. STEPANOV, V. VOLKOV.: Application of portable gamma camera during an extraction of the radioactive wastes from temporal storage at territory of RRC Kurchatov institute, ICEM, pp. 4-8.</p><p>[20]  V. STEPANOV, A. DANILOVICH, O. IVANOV.: Experience of application of new remote controlled instruments for scanning of distribution of radioactive contamination in rooms with high dose rate, ASME 2011 14th International Conference on Environmental Remediation and Radioactive Waste Management, American Society of Mechanical Engineers, 2011, pp. 89-93.</p><p>[21]  V. VOLKOV, A. VOLKOVICH, A. DANILOVICH.: RADIATION SURVEY AND PREPARING FOR THE DECOMMISSIONING OF RESEARCH REACTOR MR, RRC “KURCHATOV INSTITUTE”, 2010.</p><p>[22]  M.R. LOOMAN, J.A. MASON, ANTECH.: ANTECH Corporation 9050 Marshall Court, Westminster, Colorado, 80031, USA, DOI.</p><p>[23]  O. IVANOV, V. STEPANOV, A. DANILOVICH.: The remote methods for radwaste and SNF control, Journal of Physics: Conference Series, IOP Publishing, 2017, pp. 012014.</p><p>[24]  F. CARREL, R.A. KHALIL, S. COLAS.: GAMPIX: A new gamma imaging system for radiological safety and Homeland Security Purposes, 6963 (2011) 4739-4744.</p><p>[25]  O. GAL, M. GMAR, O.P. IVANOV.: Development of a portable gamma camera with coded aperture, Nuclear Instruments &amp; Methods in Physics Research, 563 (2006) 233-237.</p><p>[26]  T. NISHIYAMA, J. KATAOKA, A. KISHIMOTO.: Current status and optimization of handy compton camera using 3D position-sensitive scintillators, Nuclear Science Symposium and Medical Imaging Conference, 2013, pp. 1-5.</p><p>[27]  D. XU, Z. HE.: Gamma-ray energy-imaging integrated spectral deconvolution, Nuclear Instruments &amp; Methods in Physics Research, 574 (2007) 98-109.</p><p>[28]  D. XU, Z. HE, F. ZHANG.: 4-pi Compton imaging with single 3D position-sensitive CdZnTe detector, Proceedings of SPIE - The International Society for Optical Engineering, 5540 (2004) 144-155.</p><p>[29]  C.L. GOALLER, G. IMBARD, H. CARCREFF.: The development and improvement of the Aladin gamma camera to localise gamma activity in nuclear installations: final report, DOI (1998).</p><p>[30]  K.E. IVANOV, N.N. PONOMAREV-STEPNOI, B.S. STEPENNOV.: Remote measurement of the radiation dose rate on solid radwaste temporary storage site, Atomic Energy, 105 (2008) 133-137.</p><p>[31]  A.N. SUDARKIN, O.P. IVANOV, V.E. STEPANOV.: High-energy radiation visualizer (HERV): a new system for imaging in X-ray and gamma-ray emission regions, IEEE Transactions on Nuclear Science, 43 (1996) 2427-2433.</p><p>[32]  J.A. MASON, M.R. LOOMAN, A.J. POUNDALL.: Development and Testing of a Novel Gamma Ray Camera for Radiation Surveying, contamination measurement and radiation detection, Proceedings of INMM, DOI (2012).</p><p>[33]  J.A. MASON, M.R. LOOMAN, A.J. POUNDALL.: Testing and Performance Validation of a Sensitive Gamma Ray Camera Designed for Radiation Detection and Decommissioning Measurements in Nuclear Facilities-13044, WM Symposia, 1628 E. Southern Avenue, Suite 9-332, Tempe, AZ 85282 (United States), 2013.</p><p>[34]  L. ZHAO, C. CHENGSHENG.: Prototype Development of a Portable Radionuclide Identification System, Radiation Protection, China, 34 (2014) 381-385.</p><p>[35]  O. GAL, B. DESSUS, F. JEAN.: Operation of the CARTOGAM portable gamma camera in a photon-counting mode, IEEE Transactions on Nuclear Science, 48 (2001) 1198-1204.</p><p>[36]  O. GAL, C. IZAC, F. JEAN.: CARTOGAM – a portable gamma camera for remote localisation of radioactive sources in nuclear facilities ☆, Nuclear Instruments &amp; Methods in Physics Research, 460 (2001) 138-145.</p><p>[37]  O. GAL, F. JEAN, F. LAINE.: The CARTOGAM portable gamma imaging system, IEEE Transactions on Nuclear Science, 47 (2000) 952-956.</p><p>[38]  A.V. STEPANOV, O.P. IVANOV, V.E. STEPANOV.: Simulation of Safe Methods for Performing Decontamination Work, Atomic Energy, 90 (2001) 495-499.</p><p>[39]  A.N. SUDARKIN, O.P. IVANOV, V.E. STEPANOV.: Portable gamma-ray imager and its application for the inspection of the near-reactor premises contaminated by radioactive substances, Nuclear Instruments &amp; Methods in Physics Research, 414 (1998) 418-426.</p><p>[40]  A.G. VOLKOVICH, O.P. IVANOV, V.E. STEPANOV.: Application of a gamma viewer for examining reactors, Atomic Energy, 79 (1995) 772-775.</p><p>[41]  O.P. IVANOV, A.N. SUDARKIN, V.E. STEPANOV.: Portable X-ray and gamma-ray imager with coded mask: performance characteristics and methods of image reconstruction, Nuclear Instruments &amp; Methods in Physics Research, 422 (1999) 729-734.</p><p>[42]  W. LEE, D. WEHE.: 3D position of radiation sources using an automated gamma camera and ML algorithm with energy-dependent response functions, Nuclear Science Symposium Conference Record, 2004, pp. 737-741 Vol.732.</p><p>[43]  W. LEE, D. WEHE.: Hybrid gamma ray imaging—Model and results, Nuclear Inst &amp; Methods in Physics Research A, 579 (2007) 200-204.</p><p>[44]  W. LEE, D.K. WEHE.: 3-D isotropic imaging of environmental sources using a compact gamma camera, IEEE Transactions on Nuclear Science, 51 (2004) 2267-2272.</p><p>[45]  T. TAYA, J. KATAOKA, A. KISHIMOTO.: First demonstration of real-time gamma imaging by using a handheld Compton camera for particle therapy, Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment, 831 (2016) 355-361.</p><p>[46]  Z. HE, W. LI, G.F. KNOLL.: 3-D position sensitive CdZnTe gamma-ray spectrometers, Nuclear Instruments &amp; Methods in Physics Research, 422 (1999) 173-178.</p><p>[47]  L.J. MENG, Z. HE.: Exploring the limiting timing resolution for large volume CZT detectors with waveform analysis, Nuclear Instruments &amp; Methods in Physics Research, 550 (2011) págs. 435-445.</p><p>[48]  C.G. WAHL, W. KAYE, W. WANG.: Polaris-H measurements and performance, Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC), 2014 IEEE, IEEE, 2014, pp. 1-4.</p><p>[49]  Y. DU, Z. HE, G. KNOLL.: Evaluation of a Compton scattering camera using 3-D position sensitive CdZnTe detectors, Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment, 457 (2001) 203-211.</p><p>[50]  Z. HE, G. KNOLL, D. WEHE.: Coplanar grid patterns and their effect on energy resolution of CdZnTe detectors, Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment, 411 (1998) 107-113.</p><p>[51]  Z. HE, G. KNOLL, D. WEHE.: Position-sensitive single carrier CdZnTe detectors, Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment, 388 (1997) 180-185.</p><p>[52]  J.C. KIM, S.E. ANDERSON, W. KAYE.: Charge sharing in common-grid pixelated CdZnTe detectors, Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment, 654 (2011) 233-243.</p><p>[53]  J.C. KIM, W.R. KAYE, W. WANG.: Impact of drift time variation on the Compton image from large-volume CdZnTe crystals, Nuclear instruments and methods in physics research section A: Accelerators, spectrometers, detectors and associated equipment, 683 (2012) 53-62.</p><p>[54]  P. LUKE, M. AMMAN, J. LEE.: Coplanar-grid CdZnTe detector with three-dimensional position sensitivity, Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment, 439 (2000) 611-618.</p><p>[55]  F. ZHANG, Z. HE.: New readout electronics for 3-D position sensitive CdZnTe/HgI $ _2 $ detector arrays, IEEE Transactions on Nuclear Science, 53 (2006) 3021-3027.</p><p>[56]  H.I. KIM, J.A. SU, H.C. YONG.: Development of an all-in-one gamma camera/CCD system for safeguard verification, Journal of the Korean Physical Society, 65 (2014) 2013-2016.</p><p>[57]  J.E. LEES, D.J. BASSFORD, O.E. BLAKE.: A high resolution Small Field Of View (SFOV) gamma camera: a columnar scintillator coated CCD imager for medical applications, Journal of Instrumentation, 6 (2011) 570-582.</p><p>[58]  J.E. LEES, S.L. BUGBY, A.P. BARK.: A hybrid camera for locating sources of gamma radiation in the environment, Journal of Instrumentation, 8 (2013) P10021-P10021.</p><p>[59]  M. GMAR, M. AGELOU, F. CARREL.: GAMPIX: A new generation of gamma camera, Nuclear Instruments &amp; Methods in Physics Research, 652 (2011) 638-640.</p><p>[60]  H. LEMAIRE, K. AMGAROU, R.A. KHALIL.: Implementation of an imaging spectrometer for localization and identification of radioactive sources, International Conference on Advancements in Nuclear Instrumentation Measurement Methods and Their Applications, 2013, pp. 1-5.</p><p>[61]  M. GMAR, O. GAL, C.L. GOALLER.: Development of coded-aperture imaging with a compact gamma camera, Nuclear Science Symposium Conference Record, 2003, pp. 1052-1056 Vol.1052.</p><p>[62]  O.P. IVANOV.: Control and image decoding software for portable gamma-ray imaging system with coded aperture, Nuclear Science Symposium, 1999. Conference Record, 2002, pp. 459-463 vol.451.</p><p>[63]  X. LLOPART, M. CAMPBELL.: First test measurements of a 64k pixel readout chip working in single photon counting mode, Nuclear Instruments &amp; Methods in Physics Research, 509 (2003) 157-163.</p><p>[64]  G.A.D. VREE, A.H. WESTRA, I. MOODY.: Photon-counting gamma camera based on an electron-multiplying CCD, IEEE Transactions on Nuclear Science, 52 (2005) 580-588.</p><p>[65]  M. WOODRING, D. SOUZA, S. TIPNIS.: Advanced radiation imaging of low-intensity gamma-ray sources, Nuclear Instruments &amp; Methods in Physics Research, 422 (1999) 709-712.</p><p>[66]  A. MILLER, R. MACHRAFI, A. MOHANY.: Development of a semi-autonomous directional and spectroscopic radiation detection mobile platform, Radiation Measurements, 72 (2015) 53-59.</p><p>[67]  O. IVANOV, I. SEMIN, V. POTAPOV.: Ultra-Light Gamma-Camera for Security and Emergency Situation, DOI (2014).</p><p>[68]  W. WANG, W.R. KAYE, J. KIM.: Improvement of Compton imaging efficiency by using side-neighbor events, Nuclear Science Symposium Conference Record, 2010, pp. 1101-1103.</p><p>[69]  S. SUN, Z. ZHANG, L. SHUAI.: Development of a panorama coded-aperture gamma camera for radiation detection, Radiation Measurements, 77 (2015) 34-40.</p><p>[70]  T. LEE, W. LEE.: Compact hybrid gamma camera with a coded aperture for investigation of nuclear materials, Nuclear Inst &amp; Methods in Physics Research A, 767 (2014) 5-13.</p><p>[71]  M.F. CUNNINGHAM, E. BLAKEMAN, L. FABRIS.: Active-mask coded-aperture imaging, Nuclear Science Symposium Conference Record, 2007. NSS &#39;07. IEEE, 2007, pp. 1217-1221.</p><p>[72]  L.J. SCHULTZ, M.S. WALLACE, M.C. GALASSI.: Hybrid coded aperture and Compton imaging using an active mask, Nuclear Instruments &amp; Methods in Physics Research, 608 (2009) 267-274.</p><p>[73]  T. LEE, W. LEE.: A cubic gamma camera with an active collimator, Applied Radiation &amp; Isotopes Including Data Instrumentation &amp; Methods for Use in Agriculture Industry &amp; Medicine, 90 (2014) 102.</p><p> <img src="https://gitee.com/hubery_lee123/image-source/raw/master/Screenshot%202021-02-23%20120116%20(2).png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Portable-Gamma-Camera-for-Nuclear-Power-Plants&quot;&gt;&lt;a href=&quot;#Portable-Gamma-Camera-for-Nuclear-Power-Plants&quot; class=&quot;headerlink&quot; title=&quot;Portable Gamma Camera for Nuclear Power Plants&quot;&gt;&lt;/a&gt;Portable Gamma Camera for Nuclear Power Plants&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;SONG *&lt;em&gt;YuShou1, *&lt;/em&gt;LI&lt;/strong&gt; &lt;strong&gt;Hui&lt;/strong&gt; 1, &lt;strong&gt;HU Liyuan1,&lt;/strong&gt; &lt;strong&gt;HOU&lt;/strong&gt; &lt;strong&gt;Yingwei1&lt;/strong&gt;, LIU Huilan1 &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Gamma camera is a powerful tool to locate radioactive sources and contaminations in nuclear facilities. It is widely used in activities decommission, decontamination, maintenance and emergency response of nuclear power plants (NPPs). In recent decades, especially after the Fukushima nuclear accident a big progress has been made for this technique. A brief review of the principles and characteristics of three predominant imaging approaches are presented. The existing practical applications are summarized and potential application fields are discussed. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Keyword:&lt;/strong&gt; portable gamma camera; nuclear power plants; decommission; emergency response&lt;/p&gt;
    
    </summary>
    
    
      <category term="辐射成像" scheme="https://Hubery-Lee.github.io/categories/%E8%BE%90%E5%B0%84%E6%88%90%E5%83%8F/"/>
    
    
      <category term="gamma相机" scheme="https://Hubery-Lee.github.io/tags/gamma%E7%9B%B8%E6%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>提高文献阅读效率相关的工具</title>
    <link href="https://hubery-lee.github.io/2021/03/07/%E6%8F%90%E9%AB%98%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E6%95%88%E7%8E%87%E7%9B%B8%E5%85%B3%E7%9A%84%E5%B7%A5%E5%85%B7/"/>
    <id>https://hubery-lee.github.io/2021/03/07/%E6%8F%90%E9%AB%98%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E6%95%88%E7%8E%87%E7%9B%B8%E5%85%B3%E7%9A%84%E5%B7%A5%E5%85%B7/</id>
    <published>2021-03-07T13:58:13.000Z</published>
    <updated>2021-03-07T14:11:16.177Z</updated>
    
    <content type="html"><![CDATA[<h1 id="提高文献阅读效率相关的工具"><a href="#提高文献阅读效率相关的工具" class="headerlink" title="提高文献阅读效率相关的工具"></a>提高文献阅读效率相关的工具</h1><p>[toc]</p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/qrsearch2.png" alt="qrsearch2"></p><h2 id="1-文献管理工具"><a href="#1-文献管理工具" class="headerlink" title="1. 文献管理工具"></a>1. 文献管理工具</h2><h3 id="✏-Citavi"><a href="#✏-Citavi" class="headerlink" title="✏ Citavi"></a>✏ Citavi</h3><p>官网 <span class="exturl" data-url="aHR0cHM6Ly93d3cuY2l0YXZpLmNvbS9lbg==">https://www.citavi.com/en<i class="fa fa-external-link-alt"></i></span></p><p>中文官网 <span class="exturl" data-url="aHR0cHM6Ly93d3cuc29mdGhlYWQtY2l0YXZpLmNvbS8=">https://www.softhead-citavi.com/<i class="fa fa-external-link-alt"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuY2l0YXZpLmNvbS9lbg==">Citavi<i class="fa fa-external-link-alt"></i></span> 是瑞士学术软件公司开发、广受研究者欢迎的应用程序,它的功能主要可以分为五大项:收集及储存文献数据,查询及管理文献数据,以及帮助研究者快速地使用正确的论文格式撰写文章，知识组织整理，日常任务规划。我们可以将 Citavi 的设计概念理解为是在模拟一座属于自己的图书馆( Citavi Library),这座图书馆由原先空无一物开始,由我们将数据一笔一笔地或一次多笔地放进图书馆中,这些数据包含图书、期刊论文、影音媒体、法律文件、图片等。当图书馆内的数据多起来时,还可以通过群组将数据归类。检索的功能则可轻松调阅所需数据,方式与查询图书馆馆藏目录一样的便利。到了撰写论文的阶段,通过 Citavi 内建的论文模板和自动形成引用格式的功能可以大幅地减少各项文书工作的时间。</p><p><img src="https://www.softhead-citavi.com/wp-content/uploads/2017/07/c.png" alt="img"></p><p>citavi可谓是文献管理中的战斗机，功能最为强大，除了跨平台和启动慢外，暂时没有发现有什么 其他缺点。</p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210307204327760.png" alt="image-20210307204327760"></p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210307204359013.png" alt="image-20210307204359013"></p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210307204417703.png" alt="image-20210307204417703"></p><h3 id="🖌-Zotero"><a href="#🖌-Zotero" class="headerlink" title="🖌 Zotero"></a>🖌 Zotero</h3><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuem90ZXJvLm9yZy8=">https://www.zotero.org/<i class="fa fa-external-link-alt"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuem90ZXJvLm9yZy8=">Zotero<i class="fa fa-external-link-alt"></i></span>是一个开放源码的工具，可以轻松地收集、组织、引用和分享研究资源，可以使用网络浏览器扩展和电脑上的独立程序。由于此网站是开源的，因此是完全免费的。Zotero是一个很好的参考管理器，特别是对于学生来说，因为它可以在个人设备(笔记本电脑、iPad、手机等)上同时运行网络服务和离线服务。Zotero不仅可以存储和格式化书目信息，还可以组织、标记和搜索这些信息，自动、无缝地从书籍、期刊文章和其他在线资源中提取信息，使得创建参考列表的整个过程变得轻松。</p><p>特点是跨平台，对中文兼容性好</p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/screenshot-1.4.png" alt="Screenshot of the Zotero desktop application"></p><h3 id="🖍-Mendeley"><a href="#🖍-Mendeley" class="headerlink" title="🖍 Mendeley"></a>🖍 Mendeley</h3><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubWVuZGVsZXkuY29tLz9pbnRlcmFjdGlvbl9yZXF1aXJlZD10cnVl">https://www.mendeley.com/?interaction_required=true<i class="fa fa-external-link-alt"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubWVuZGVsZXkuY29tLz9pbnRlcmFjdGlvbl9yZXF1aXJlZD10cnVl">Mendeley<i class="fa fa-external-link-alt"></i></span>与前面两个的功能差不多，老用户比较多；Mendeley是一个免费的学术文献交流平台，所有人都可以在Mendeley上搜索到世界各地的学术文献，而这些学术文献都是由用户自己上传进Mendeley “图书馆(Library)”进行编辑管理。美国媒体2013年4月9日爆出消息，老牌科技出版巨头Elsevier将收购Mendeley ，收购价格将在6900 万美元到1 亿美元之间 [1] 。</p><p>Elsevier收购Mendeley之后，将能够把自己的线上渠道打通，也能够整合线上内容资源。Elsevier对外承诺，将会保持Mendeley开放的特性。</p><h3 id="🖋-EndNote"><a href="#🖋-EndNote" class="headerlink" title="🖋 EndNote"></a>🖋 EndNote</h3><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuZW5kbm90ZS5jb20v">EndNote<i class="fa fa-external-link-alt"></i></span>与前面几个的功能差不多，可以说是文献管理领域的元老了，以前大部分高校都用的是EndNote；<span class="exturl" data-url="aHR0cHM6Ly9iYWlrZS5iYWlkdS5jb20vaXRlbS9FbmRub3Rl">Endnote<i class="fa fa-external-link-alt"></i></span>由Thomson Corporation下属的Thomson ResearchSoft 开发。 Thomson ResearchSoft是以学术信息市场化和开发学术软件为宗旨的子公司。Thomson Corporation总部位于<span class="exturl" data-url="aHR0cHM6Ly9iYWlrZS5iYWlkdS5jb20vaXRlbS/nvo7lm70vMTI1NDg2">美国<i class="fa fa-external-link-alt"></i></span>康涅狄格州的Stanford。</p><h2 id="2-翻译工具"><a href="#2-翻译工具" class="headerlink" title="2. 翻译工具"></a>2. 翻译工具</h2><p>知名在线翻译工具主要有以下几个：</p><ul><li>百度翻译 <span class="exturl" data-url="aHR0cHM6Ly9mYW55aS5iYWlkdS5jb20vP2FsZHR5cGU9MTYwNDcjYXV0by96aA==">https://fanyi.baidu.com/?aldtype=16047#auto/zh<i class="fa fa-external-link-alt"></i></span></li><li>谷歌翻译 <span class="exturl" data-url="aHR0cHM6Ly90cmFuc2xhdGUuZ29vZ2xlLmNuLw==">https://translate.google.cn/<i class="fa fa-external-link-alt"></i></span></li><li>DeepL翻译  <span class="exturl" data-url="aHR0cHM6Ly93d3cuZGVlcGwuY29tL3RyYW5zbGF0b3I=">https://www.deepl.com/translator<i class="fa fa-external-link-alt"></i></span></li></ul><p>划词翻译工具推荐 <code>copytranslator和百度翻译电脑版</code>，我个人已经不用<code>知云翻译</code>,你们如果感兴趣可以用。</p><h3 id="🔰-CopyTranslator"><a href="#🔰-CopyTranslator" class="headerlink" title="🔰 CopyTranslator"></a>🔰 CopyTranslator</h3><p>有多种方式的翻译对比，复制立即翻译，但是翻译速度比较慢</p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210307212847273.png" alt="image-20210307212847273"></p><h3 id="🚀-百度翻译"><a href="#🚀-百度翻译" class="headerlink" title="🚀 百度翻译"></a>🚀 百度翻译</h3><p>也是复制翻译，特点是速度快</p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210307213811886.png" alt="image-20210307213811886"></p><h3 id="🏡-知云翻译阅读器"><a href="#🏡-知云翻译阅读器" class="headerlink" title="🏡 知云翻译阅读器"></a>🏡 知云翻译阅读器</h3><p>特点是ipdf阅读器集成划词翻译功能，但是窗口调节不方便，想用adobe pdf阅读器的话，就不要用这个了。</p><h2 id="3-笔记工具"><a href="#3-笔记工具" class="headerlink" title="3.  笔记工具"></a>3.  笔记工具</h2><ul><li>onenote</li><li>印象笔记</li><li>有道云笔记</li><li>或者直接自己用建文件夹，用typora写笔记，放到云盘里</li></ul><h2 id="4-云盘推荐"><a href="#4-云盘推荐" class="headerlink" title="4.云盘推荐"></a>4.云盘推荐</h2><ul><li>onedrive 微软自带，免费5G容量</li><li>坚果云 国内厂商，类似onedrive，比较好用</li><li>阿里云盘</li><li>百度网盘</li><li>华为云盘</li><li>蓝奏云</li><li>dropbox</li><li>google云盘</li><li>office 365云盘</li></ul><p>好了，今天的介绍就到这里，大家可以按自己的喜好挑选自己的顺手的工具，希望大家能提高工作效率呀！！！</p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/Screenshot%202021-02-23%20120116%20(2).png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;提高文献阅读效率相关的工具&quot;&gt;&lt;a href=&quot;#提高文献阅读效率相关的工具&quot; class=&quot;headerlink&quot; title=&quot;提高文献阅读效率相关的工具&quot;&gt;&lt;/a&gt;提高文献阅读效率相关的工具&lt;/h1&gt;&lt;p&gt;[toc]&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;htt
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>小样本学习研究综述</title>
    <link href="https://hubery-lee.github.io/2021/03/03/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0%E7%A0%94%E7%A9%B6%E7%BB%BC%E8%BF%B0/"/>
    <id>https://hubery-lee.github.io/2021/03/03/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0%E7%A0%94%E7%A9%B6%E7%BB%BC%E8%BF%B0/</id>
    <published>2021-03-03T13:57:27.000Z</published>
    <updated>2021-03-03T14:08:17.066Z</updated>
    
    <content type="html"><![CDATA[<p>近年来,在大数据训练模型的趋势下,机器学习和深度学习在许多领域中取得了成功.但是在现实世界中的很多应用场景中,样本量很少或者标注样本很少,而对大量无标签样本进行标注工作将会耗费很大的人力.所以,如何用少量样本进行学习就成为目前人们需要关注的问题.系统地梳理了当前小样本学习的相关工作,具体来说介绍了基于模型微调、基于数据增强和基于迁移学习这 3 大类小样本学习模型与算法的研究进展;将基于数据增强的方法细分为基于无标签数据、基于数据合成和基于特征增强这3 类,将基于迁移学习的方法细分为基于度量学习、基于元学习和基于图神经网络这 3 类</p><!-- more--><h2 id="1-基于模型微调的小样本学习"><a href="#1-基于模型微调的小样本学习" class="headerlink" title="1   基于模型微调的小样本学习"></a>1   基于模型微调的小样本学习</h2><p>基于模型微调的方法是小样本学习较为传统的方法,该方法通常在大规模数据上预训练模型,在目标小样本数据集上对神经网络模型的全连接层或者顶端几层进行参数微调,得到微调后的模型.若目标数据集和源数据集分布较类似,可采用模型微调的方法. </p><p>为了使微调后的小样本分类模型取得较好的效果,使用何种微调方法需要被考虑.Howard 等人在 2018年提出了一个通用微调语言模型(universal language model fine-tuning,简称ULMFit).与其他模型不同的是,此方法使用了语言模型而非深度神经网络.该模型分为3 个阶段:(1) 语言模型预训练;(2) 语言模型微调;(3) 分类器微调.该模型的创新点在于改变学习速率来微调语言模型,主要体现在两个方面. </p><p>1)    传统方法认为,模型每一层学习速率相同;而ULMFit 中,语言模型的每一层学习速率均不相同.模型底层表示普遍特征,这些特征不需要很大调整,所以学习速率较慢;而高层特征更具有独特性,更能体现出任务和数据的独有特征,于是高层特征需要用更大的学习速率学习.总体看来,模型底层到最高层学习速率不断加快.<br>2)    对于模型中的同一层,当迭代次数变化时,自身学习率也会相应地产生变化.作者提出了斜三角学习率的概念,当迭代次数从 0 开始增加时,学习速率逐渐变大;当迭代次数增长到某个固定值时,此时已经学习到了足够知识,固定值之后的学习率又开始逐步下降.</p><p>基于模型微调的方法较简单,但是在真实场景中,目标数据集和源数据集往往并不类似,采用模型微调的方法会导致模型在目标数据集上过拟合.为解决模型在目标数据集上过拟合的问题,两种解决思路被提出:基于数据增强和基于迁移学习的方法.</p><h2 id="2-基于数据增强的小样本学习"><a href="#2-基于数据增强的小样本学习" class="headerlink" title="2   基于数据增强的小样本学习"></a>2   基于数据增强的小样本学习</h2><p>小样本学习的根本问题在于样本量过少,从而导致样本多样性变低.在数据量有限的情况下,可以通过数据增强(data augmentation)来提高样本多样性.数据增强指借助辅助数据或辅助信息,对原有的小样本数据集进行数据扩充或特征增强.数据扩充是向原有数据集添加新的数据,可以是无标签数据或者合成的带标签数据;特征增强是在原样本的特征空间中添加便于分类的特征,增加特征多样性.基于上述概念,本文将基于数据增强的方法分为基于无标签数据、基于数据合成和基于特征增强的方法三种.</p><ul><li><p>基于无标签数据的方法是指利用无标签数据对小样本数据集进行扩充,常见的方法有半监督学习和直推式学习等.</p></li><li><p>基于数据合成的方法是指为小样本类别合成新的带标签数据来扩充训练数据,常用的算法有生成对抗网络(generative adversarial net)等</p></li><li><p>除了利用辅助数据来增强样本空间之外,还可通过增强样本特征空间来提高样本的多样性,因为小样本学习的一个关键是如何得到一个泛化性好的特征提取器.</p></li></ul><h2 id="3-基于迁移学习的小样本学习"><a href="#3-基于迁移学习的小样本学习" class="headerlink" title="3   基于迁移学习的小样本学习"></a>3   基于迁移学习的小样本学习</h2><p>迁移学习是指利用旧知识来学习新知识,主要目标是将已经学会的知识很快地迁移到一个新的领域中. .迁移学习主要解决的一个问题是小样本问题.基于模型微调的方法在源数据集和目标数据集分布大致相同时有效,分布不相似时会导致过拟合问题.迁移学习则解决了这个问题.迁移学习只需要源领域和目标领域存在一定关联,使得在源领域和数据中学习到的知识和特征能够帮助在目标领域训练分类模型,从而实现知识在不同领域之间的迁移.一般来说,源领域和目标领域之间的关联性越强,那么迁移学习的效果就会越好。</p><p>在迁移学习中,数据集被划分为 3 部分:训练集(training set)、支持集(support set)和查询集(query set).其中,训练集是指源数据集,一般包含大量的标注数据;支持集是指目标领域中的训练样本,包含少量标注数据;查询集是目标领域中的测试样本. </p><p>根据迁移学习的方法不同, 将其分为基于度量学习、基于元学习和基于图神经网络的方法这 3 类.</p><h3 id="3-1-度量学习"><a href="#3-1-度量学习" class="headerlink" title="3.1 度量学习"></a>3.1 度量学习</h3><p>在数学概念中，度量指衡量两个元素之间距离的函数，也叫做距离函数.度量学习也称为相似度学习，是指通过给定的距离函数计算两个样本之间的距离,从而度量它们的相似度。</p><p>在深度学习中，我们通常采用欧氏距离、马氏距离和余弦相似度等。作为距离函数，将度量学习的框架应用到小样本学习上，顾名思义，就是通过计算待分类样本和已知分类样本之间的距离，找到邻近类别来确定待分类样本的分类结果。</p><h3 id="3-2-元学习"><a href="#3-2-元学习" class="headerlink" title="3.2 元学习"></a>3.2 元学习</h3><p>元学习(meta-learning)也叫做学会学习(learning to learn)，是机器学习领域一个前沿的研究框架,针对于解决模型如何学习的问题.元学习的目的是让模型获得一种学习能力,这种学习能力可以让模型自动学习到一些元知识.元知识指在模型训练过程之外可以学习到的知识,比如模型的超参数、神经网络的初始参数、神经网络的结构和优化器等。</p><h3 id="3-3-基于图神经网络的方法"><a href="#3-3-基于图神经网络的方法" class="headerlink" title="3.3 基于图神经网络的方法"></a>3.3 基于图神经网络的方法</h3><p>在计算机科学中,图作为一种数据结构,由点和边构成.图这种数据结构,具有表现力强和展示直观的优点.随着近年来机器学习的兴起,机器学习逐渐被应用到图的分析上.图神经网络是一种基于深度学习的处理图领域信息的模型,由于其较好的性能和可解释性,它最近已成为一种广泛应用的图分析方法. 图神经网络有很多种变体,比较常用的有图卷积神经网络(graph convolutional network)、门控图神经网络(gated graph neural network)和图注意力网络(graph attention network)等. </p><h2 id="优缺点对比"><a href="#优缺点对比" class="headerlink" title="优缺点对比"></a>优缺点对比</h2><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210303215307264.png" alt="image-20210303215307264"></p><h2 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h2><p>赵凯琳,靳小龙,王元卓.小样本学习研究综述[J].软件学报,2021,32(02):349-369.</p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/Screenshot%202021-02-23%20120116%20(2).png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;近年来,在大数据训练模型的趋势下,机器学习和深度学习在许多领域中取得了成功.但是在现实世界中的很多应用场景中,样本量很少或者标注样本很少,而对大量无标签样本进行标注工作将会耗费很大的人力.所以,如何用少量样本进行学习就成为目前人们需要关注的问题.系统地梳理了当前小样本学习的
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>迁移学习基本概念</title>
    <link href="https://hubery-lee.github.io/2021/03/01/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    <id>https://hubery-lee.github.io/2021/03/01/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</id>
    <published>2021-03-01T15:26:47.000Z</published>
    <updated>2021-03-01T15:28:15.018Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/qrsearch2.png" alt="qrsearch2"></p><blockquote><p>机器学习是人工智能的一大类重要方法，也是目 前发展最迅速、效果最显著的方法。机器学习解决的是让机器自主地从数据中获取知识，从 而应用于新的问题中。迁移学习作为机器学习的一个重要分支，侧重于将已经学习过的知 识迁移应用于新的问题中。 迁移学习的核心问题是，找到新问题和原问题之间的相似性，才可以顺利地实现知识 的迁移。比如在我们一开始说的天气问题中，那些北半球的天气之所以相似，是因为它们的 地理位置相似；而南北半球的天气之所以有差异，也是因为地理位置有根本不同。</p></blockquote><h2 id="❓为什么需要迁移学习"><a href="#❓为什么需要迁移学习" class="headerlink" title="❓为什么需要迁移学习"></a>❓为什么需要迁移学习</h2><a id="more"></a><h3 id="❗传统机器学习面临的困境"><a href="#❗传统机器学习面临的困境" class="headerlink" title="❗传统机器学习面临的困境"></a>❗传统机器学习面临的困境</h3><ol><li>大数据与少标注之间的矛盾。</li></ol><p>机器学习模型的训练和更新，均依赖于数据的标注。然而，尽管我们可以获 取到海量的数据，这些数据往往是很初级的原始形态，很少有数据被加以正确的人工标注。 数据的标注是一个耗时且昂贵的操作，目前为止，尚未有行之有效的方式来解决这一问题。 这给机器学习和深度学习的模型训练和更新带来了挑战。反过来说，特定的领域，因为没有 足够的标定数据用来学习，使得这些领域一直不能很好的发展。</p><ol start="2"><li>大数据与弱计算之间的矛盾</li></ol><p>大数据，就需要大设备、强计算能力的设备来进行存储和计算。然而，大数据的大计算 能力，是” 有钱人” 才能玩得起的游戏。比如 Google，Facebook，Microsoft，这些巨无霸 公司有着雄厚的计算能力去利用这些数据训练模型。例如，ResNet 需要很长的时间进行训 练。Google TPU 也都是有钱人的才可以用得起的。 绝大多数普通用户是不可能具有这些强计算能力的。这就引发了大数据和弱计算之间 的矛盾。在这种情况下，普通人想要利用这些海量的大数据去训练模型完成自己的任务，基 本上不太可能。那么如何让普通人也能利用这些数据和模型？</p><ol start="3"><li>普适化模型与个性化需求之间的矛盾</li></ol><p>机器学习的目标是构建一个尽可能通用的模型，使得这个模型对于不同用户、不同设 备、不同环境、不同需求，都可以很好地进行满足。这是我们的美好愿景。这就是要尽可能地提高机器学习模型的泛化能力，使之适应不同的数据情形。基于这样的愿望，我们构建了 多种多样的普适化模型，来服务于现实应用。然而，这只能是我们竭尽全力想要做的，目前 却始终无法彻底解决的问题。人们的个性化需求五花八门，短期内根本无法用一个通用的 模型去满足。比如导航模型，可以定位及导航所有的路线。但是不同的人有不同的需求。比 如有的人喜欢走高速，有的人喜欢走偏僻小路，这就是个性化需求。并且，不同的用户，通 常都有不同的隐私需求。这也是构建应用需要着重考虑的。<br>所以目前的情况是，我们对于每一个通用的任务都构建了一个通用的模型。这个模型 可以解决绝大多数的公共问题。但是具体到每个个体、每个需求，都存在其唯一性和特异 性，一个普适化的通用模型根本无法满足。那么，能否将这个通用的模型加以改造和适配， 使其更好地服务于人们的个性化需求？</p><ol start="4"><li>特定应用的需求</li></ol><p>机器学习已经被广泛应用于现实生活中。在这些应用中，也存在着一些特定的应用，它 们面临着一些现实存在的问题。比如推荐系统的冷启动问题。一个新的推荐系统，没有足够 的用户数据，如何进行精准的推荐? 一个崭新的图片标注系统，没有足够的标签，如何进行 精准的服务？现实世界中的应用驱动着我们去开发更加便捷更加高效的机器学习方法来加 以解决。</p><h3 id="👁‍🗨迁移学习是如何进行解决的呢"><a href="#👁‍🗨迁移学习是如何进行解决的呢" class="headerlink" title="👁‍🗨迁移学习是如何进行解决的呢?"></a>👁‍🗨迁移学习是如何进行解决的呢?</h3><ol><li>大数据与少标注：迁移数据标注<br>单纯地凭借少量的标注数据，无法准确地训练高可用度的模型。为了解决这个问题，我 们直观的想法是：多增加一些标注数据不就行了？但是不依赖于人工，如何增加标注数据？<br>利用迁移学习的思想，我们可以寻找一些与目标数据相近的有标注的数据，从而利用 这些数据来构建模型，增加我们目标数据的标注。</li><li>大数据与弱计算：模型迁移<br>不可能所有人都有能力利用大数据快速进行模型的训练。利用迁移学习的思想，我们 可以将那些大公司在大数据上训练好的模型，迁移到我们的任务中。针对于我们的任务进 行微调，从而我们也可以拥有在大数据上训练好的模型。更进一步，我们可以将这些模型针 对我们的任务进行自适应更新，从而取得更好的效果。</li><li>普适化模型与个性化需求：自适应学习<br>为了解决个性化需求的挑战，我们利用迁移学习的思想，进行自适应的学习。考虑到不 同用户之间的相似性和差异性，我们对普适化模型进行灵活的调整，以便完成我们的任务。</li><li>特定应用的需求：相似领域知识迁移<br>为了满足特定领域应用的需求，我们可以利用上述介绍过的手段，从数据和模型方法 上进行迁移学习。<br><img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210301223124770.png" alt="image-20210301223124770"></li></ol><h2 id="✅与已有概念的区别与联系"><a href="#✅与已有概念的区别与联系" class="headerlink" title="✅与已有概念的区别与联系"></a>✅与已有概念的区别与联系</h2><ol><li><p>迁移学习 VS 传统机器学习：<br>迁移学习属于机器学习的一类，但它在如下几个方面有别于传统的机器学习</p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210301230620912.png" alt="image-20210301230620912"></p></li><li><p>迁移学习 VS 多任务学习：<br>多任务学习指多个相关的任务一起协同学习；迁移学习则强调知识由一个领域迁移到 另一个领域的过程。迁移是思想，多任务是其中的一个具体形式。</p></li><li><p>迁移学习 VS 终身学习：<br>终身学习可以认为是序列化的多任务学习，在已经学习好若干个任务之后，面对新的 任务可以继续学习而不遗忘之前学习的任务。迁移学习则侧重于模型的迁移和共同学习。</p></li><li><p>迁移学习 VS 领域自适应：<br>领域自适应问题是迁移学习的研究内容之一，它侧重于解决特征空间一致、类别空间 一致，仅特征分布不一致的问题。而迁移学习也可以解决上述内容不一致的情况。</p></li><li><p>迁移学习 VS 增量学习：<br>增量学习侧重解决数据不断到来，模型不断更新的问题。迁移学习显然和其有着不同 之处。</p></li><li><p>迁移学习 VS 自我学习：<br>自我学习指的是模型不断地从自身处进行更新，而迁移学习强调知识在不同的领域间 进行迁移。</p></li><li><p>迁移学习 VS 协方差漂移<br>协方差漂移指数据的边缘概率分布发生变化。领域自适应研究问题解决的就是协方差 漂移现象。</p></li></ol><h2 id="💌负迁移"><a href="#💌负迁移" class="headerlink" title="💌负迁移"></a>💌负迁移</h2><p>我们都希望迁移学习能够比较顺利地进行，我们得到的结果也是满足我们要求的，皆 大欢喜。然而，事情却并不总是那么顺利。这就引入了迁移学习中的一个负面现象，也就是 所谓的负迁移。</p><p>用我们熟悉的成语来描述：如果说成功的迁移学习是“举一反三”、“照猫画虎”，那么 负迁移则是“东施效颦”。东施已经模仿西施捂着胸口皱着眉头，为什么她还是那么丑?</p><p>要理解负迁移，首先要理解什么是迁移学习。迁移学习指的是，利用数据和领域之间存 在的相似性关系，把之前学习到的知识，应用于新的未知领域。迁移学习的核心问题是，找 到两个领域的相似性。找到了这个相似性，就可以合理地利用，从而很好地完成迁移学习任 务。比如，之前会骑自行车，要学习骑摩托车，这种相似性指的就是自行车和摩托车之间的 相似性以及骑车体验的相似性。这种相似性在我们人类看来是可以接受的。</p><p>所以，如果这个相似性找的不合理，也就是说，两个领域之间不存在相似性，或者基本 不相似，那么，就会大大损害迁移学习的效果。还是拿骑自行车来说，你要拿骑自行车的经 验来学习开汽车，这显然是不太可能的。因为自行车和汽车之间基本不存在什么相似性。所 以，这个任务基本上完不成。这时候，我们可以说出现了负迁移 (Negative Transfer)。</p><p>所以，为什么东施和西施做了一样的动作，反而变得更丑了？因为东施和西施之间压根 就不存在相似性。</p><p>负迁移指的是，在源域上学习到的知识，对于目标域上的学习产生负面作用。</p><p>产生负迁移的原因主要有：</p><ul><li>数据问题：源域和目标域压根不相似，谈何迁移？</li><li>方法问题：源域和目标域是相似的，但是，迁移学习方法不够好，没找到可迁移的成 分。<br>负迁移给迁移学习的研究和应用带来了负面影响。在实际应用中，找到合理的相似性， 并且选择或开发合理的迁移学习方法，能够避免负迁移现象。</li></ul><h3 id="最新研究成果"><a href="#最新研究成果" class="headerlink" title="最新研究成果"></a>最新研究成果</h3><p>随着研究的深入，已经有新的研究成果在逐渐克服负迁移的影响。杨强教授团队 2015 在 数据挖掘领域顶级会议KDD上发表了传递迁移学习文章Transitive transfer learning ， 提出了传递迁移学习的思想。传统迁移学习就好比是踩着一块石头过河，传递迁移学习就 好比是踩着连续的两块石头。 更进一步，杨强教授团队在 2017 年人工智能领域顶级会议 AAAI 上发表了远领域迁 移学习的文章 Distant domain transfer learning ，可以用人脸来识别飞机！ 这就好比是踩着一连串石头过河。这些研究的意义在于，传统迁移学习只有两个领域足够 相似才可以完成，而当两个领域不相似时，传递迁移学习却可以利用处于这两个领域之间 的若干领域，将知识传递式的完成迁移。这个是很有意义的工作，可以视为解决负迁移的有 效思想和方法。可以预见在未来会有更多的应用前景。</p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210301231518157.png" alt="image-20210301231518157"></p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/Screenshot%202021-02-23%20120116%20(2).png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://gitee.com/hubery_lee123/image-source/raw/master/qrsearch2.png&quot; alt=&quot;qrsearch2&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;机器学习是人工智能的一大类重要方法，也是目 前发展最迅速、效果最显著的方法。机器学习解决的是让机器自主地从数据中获取知识，从 而应用于新的问题中。迁移学习作为机器学习的一个重要分支，侧重于将已经学习过的知 识迁移应用于新的问题中。 迁移学习的核心问题是，找到新问题和原问题之间的相似性，才可以顺利地实现知识 的迁移。比如在我们一开始说的天气问题中，那些北半球的天气之所以相似，是因为它们的 地理位置相似；而南北半球的天气之所以有差异，也是因为地理位置有根本不同。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;❓为什么需要迁移学习&quot;&gt;&lt;a href=&quot;#❓为什么需要迁移学习&quot; class=&quot;headerlink&quot; title=&quot;❓为什么需要迁移学习&quot;&gt;&lt;/a&gt;❓为什么需要迁移学习&lt;/h2&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>辐射场源项反演方法</title>
    <link href="https://hubery-lee.github.io/2021/02/27/%E8%BE%90%E5%B0%84%E5%9C%BA%E6%BA%90%E9%A1%B9%E5%8F%8D%E6%BC%94%E6%96%B9%E6%B3%95/"/>
    <id>https://hubery-lee.github.io/2021/02/27/%E8%BE%90%E5%B0%84%E5%9C%BA%E6%BA%90%E9%A1%B9%E5%8F%8D%E6%BC%94%E6%96%B9%E6%B3%95/</id>
    <published>2021-02-27T14:57:38.000Z</published>
    <updated>2021-02-27T14:58:59.824Z</updated>
    
    <content type="html"><![CDATA[<h1 id="辐射场源项反演方法"><a href="#辐射场源项反演方法" class="headerlink" title="辐射场源项反演方法"></a>辐射场源项反演方法</h1><blockquote><p>若能在现场人员进行作业之前，通过软件的方式来对作业过程进行模拟，并给出作业剂量信息，同时进行分析并优化作业方案，这样就可以进一步有效地降低作业人员的受照剂量，而这一切工作的前提是必须建立人员作业区域内的辐射场。因此，利用多学科前沿交叉技术和辐射防护新技术，在已有相关技术研究的基础上，开展辐射场快速计算方法研究，可以为辐射防护最优化提供先进的、更具操作性的技术支持手段，从而较大幅度提升核设施现场辐射防护的安全水平，在核设施运行、检修、退役等辐射领域，有广阔的应用前景</p></blockquote><a id="more"></a><h2 id="辐射场重建的常用方法"><a href="#辐射场重建的常用方法" class="headerlink" title="辐射场重建的常用方法"></a>辐射场重建的常用方法</h2><p>纵观各个国家在作业剂量模拟与方案优化方面的工作，其中涉及六个方面的关键点，如下图所示。 </p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210227222639564.png" alt="image-20210227222639564"></p><p>目前对于复杂几何空间中的辐射剂量计算，实际上是对辐射传输方程(Boltzmann 方程)的求解，常用的方法有蒙特卡罗方法、离散纵标法和点核积分方法，如下图所示。 </p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210227222732488.png" alt="image-20210227222732488"></p><h2 id="源项反演的目的及意义"><a href="#源项反演的目的及意义" class="headerlink" title="源项反演的目的及意义"></a>源项反演的目的及意义</h2><p>在辐射场的计算中，源项的信息作为输入量，是计算的前提，但在实际应用中，源项往往是未知的，尤其是源的活度信息。然而源项的其他信息往往是被现场辐射技术人员所熟知的，比如源的位置、数量及核素种类等，这就使得利用已知条件，结合某些位置处的剂量率的实测值等，对源项活度进行估算成为了可能。同时利用估算出的源的活度信息再计算出感兴趣区域的辐射场，比利用现有辐射场数据进行简单插值计算得到的结果要准确得多。</p><h2 id="带权重和约束的源项活度反演计算"><a href="#带权重和约束的源项活度反演计算" class="headerlink" title="带权重和约束的源项活度反演计算"></a>带权重和约束的源项活度反演计算</h2><p>在核设施现场进行剂量率测量时，某些测量位置由于周围存在的干扰因素较多，其测量结果会有较大的误差，而有些测量位置处存在的干扰因素少，其测量值较为准确。研究可知，在利用这些测量值进行源活度反演计算时，误差较大的测量值会对那些在该位置处剂量率贡献成分较小的源项的活度计算结果影响很大，此时需要引入权重机制，来降低误差较大的测量值对源活度计算的影响，从而提高源活度反演结果的准确性。<br>另一方面，对于含有多个源项的活度反演计算，若其中某些源项的活度值是已知的，只需要对其他未知源项的活度进行计算，这是一个带约束的源活度反演计算问题，在实际计算中也经常遇到。 </p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210227222137063.png" alt="image-20210227222137063"></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>李华. γ辐射场快速计算与源项反演方法研究及其初步应用[D]. 清华大学，2017.12</p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/Screenshot%202021-02-23%20120116%20(2).png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;辐射场源项反演方法&quot;&gt;&lt;a href=&quot;#辐射场源项反演方法&quot; class=&quot;headerlink&quot; title=&quot;辐射场源项反演方法&quot;&gt;&lt;/a&gt;辐射场源项反演方法&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;若能在现场人员进行作业之前，通过软件的方式来对作业过程进行模拟，并给出作业剂量信息，同时进行分析并优化作业方案，这样就可以进一步有效地降低作业人员的受照剂量，而这一切工作的前提是必须建立人员作业区域内的辐射场。因此，利用多学科前沿交叉技术和辐射防护新技术，在已有相关技术研究的基础上，开展辐射场快速计算方法研究，可以为辐射防护最优化提供先进的、更具操作性的技术支持手段，从而较大幅度提升核设施现场辐射防护的安全水平，在核设施运行、检修、退役等辐射领域，有广阔的应用前景&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="辐射防护最优化" scheme="https://Hubery-Lee.github.io/categories/%E8%BE%90%E5%B0%84%E9%98%B2%E6%8A%A4%E6%9C%80%E4%BC%98%E5%8C%96/"/>
    
    
      <category term="辐射防护" scheme="https://Hubery-Lee.github.io/tags/%E8%BE%90%E5%B0%84%E9%98%B2%E6%8A%A4/"/>
    
  </entry>
  
  <entry>
    <title>医学影像物理</title>
    <link href="https://hubery-lee.github.io/2021/02/27/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E7%89%A9%E7%90%86/"/>
    <id>https://hubery-lee.github.io/2021/02/27/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E7%89%A9%E7%90%86/</id>
    <published>2021-02-27T14:53:49.000Z</published>
    <updated>2021-02-27T14:56:00.155Z</updated>
    
    <content type="html"><![CDATA[<h1 id="医学影像物理（MIP）"><a href="#医学影像物理（MIP）" class="headerlink" title="医学影像物理（MIP）"></a>医学影像物理（MIP）</h1><p>医学影像物理涵盖的范围较广，包括X射线诊断学和临床核医学诊断以及超声成像和核磁共振成像MR(Magnetic Resonance Imaging)等。主要目的是获取生物组织结构信息以及生物功能、代谢和生理状况，为临床治疗提供信息。就核物理和核技术角度而言，主要关注的是X射线诊断和临床核医学诊断。</p><p><strong>以减少生物照射剂量及快速、高效和准确的获取诊断信息为目的，医学影像物理正朝着多模复合成像方向不断更新进步</strong>，且还存在一些可以研究工作值得进一步推进，具体如图3所示。</p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E5%AD%A6%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B.png" alt></p><a id="more"></a><h2 id="X射线诊断技术"><a href="#X射线诊断技术" class="headerlink" title="X射线诊断技术"></a>X射线诊断技术</h2><p>X射线诊断不同于临床核医学诊断，不需要在生物体内注射放射性核素，而是通过生物体外的X射线源发射X射线对生物组织结构进行精细成像。</p><p><strong>常用的成像手段有CR(Computer Radiography)计算机摄影、DR(Digital Radiography)数字摄影和CT(Computer Tomography)计算机断层成像等。</strong></p><p>1981年日本富士公司首先推出了商业CR设备。DR成像系统也几乎是在同一时期被提出，甚至早于CR。由于DR较昂贵，价格约为CR的3倍，CR得以率先推广。CR采用的存储荧光体（IP板）成像，也称为间接数学化X射线成像技术，类似于胶片成像过程需要洗片。而DR采用平板探测器或荧光板CCD摄像机直接将X射线光子转换成数字信号。成像转换环节少，减少了噪声、图像质量高，曝光剂量较低，甚至可以动态成像（DR采集一幅2kx2k的图像约10ms，5s成像；DR 的拍片速度快于 CR，拍片间隔为 5s，直接出片。CR 拍片间隔1 min 以上，从摄影到胶片显像需3 min。）。目前DR设备正朝着小型化、高分辨方向发展，故而半导体探测器的应用是其必然选择。随着半导体探测器技术的发展，DR设备越来越轻便可为不可移动病人进行检测。目前全国DR厂商130~150家，年新增整机总量达15000台。</p><p>CR和DR均只能获取二维图像。为获取生物组织三维信息，CT得以提出并迅速发展。X射线CT经历了40多年的发展, 从早期的单排往复式CT发展到螺旋CT, 直到目前最先进的多层螺旋CT。现今的亚秒（&lt;0.2s）螺旋CT能达到640排；低剂量条件下的投影域能谱数据分解方法，能够进行单能量成像和物质化学组成鉴别，能够实现高速大容积 CT 的空间分辨率 14lp/cm，重建速度大于30 帧 /s。为克服CT技术对生物软组织成像不佳问题，采用多能X射线以获得更佳组织结构区分能力。图像重建方法由解析重建方法、迭代重建方法发展到基于深度学习的图像重建方法。<strong>低剂量、多能**</strong>CT<strong>**和基于深度学习的智能图像识别算法是目前的研究热点。</strong>目前国内CT设备保有量为2万多台，每百万人口CT设备拥有量约14.9台。国内的联影、东软公司和安科高科技公司等制作的多排螺旋CT设备已经达到国际先进水平并且远销海外，但国内主要市场大半仍被西门子、通用和东芝等的外国公司所垄断。</p><h2 id="临床核医学诊断"><a href="#临床核医学诊断" class="headerlink" title="临床核医学诊断"></a>临床核医学诊断</h2><p>临床核医学诊断以放射性核素(药物)在体内的分布作为成像依据反映人体代谢、组织功能和结构形态。上世纪50 年代初问世的直线型扫描机开创了核医学影像的历史，经历了半个多世纪的发展，<strong>伽玛相机(γ相机)</strong>、单光子发射计算机断层成像<strong>(SPECT，Single-photon Emission Tomography)</strong>和正电子发射计算机断层成像<strong>(PET，Positron Emission Tomography)</strong>等设备相继问世并在各大医院得到普及。</p><p>γ相机采用像素级的γ探测器对生物体内的核素分布进行成像，像素灰度值的大小反映探测到的γ射线的强度。γ相机的类型较多，可分为Anger相机、针孔相机、编码孔相机和康普顿相机等，分别基于电子准直技术和机械准直技术。编码孔相机成像速度比针孔相机成像速度快数十倍。<strong>由于采用机械准直技术的γ相机射线利用率低成像速度慢，目前研究热点集中在两个方面，一方面改进编码孔成像技术，另一方面研发高性能电子准直的康普顿成像技术。</strong></p><p>二维成像的γ相机无法实现人体内三维核素分布的成像。SPECT和PET是核医学的两种CT技术，都是对人体内发射的γ射线进行成像，也统称为发射型计算机断层成像（ECT，Emission Computed Tomography）。只是SPECT和PET注射的核药种类不同。SPECT注射发射单个光子的核药（如，99Tc），而PET基于正电子湮灭原理，注射11C、13N、15O、18F等缺中子核素。由于11C、13N、15O、18F是生物有机组成的主要元素，故而PET可以检测人体的各种生理变化。单光子成像设备（SPECT和γ相机）全国装机总量625台左右。PET设备昂贵，检测费用高昂。一台PET设备价格1000~3000万不等，在享有医保的条件下一次检测费用8000元左右。目前，PET国内医院装机总量300台左右。PET采用符合采样方式，全身检测时间约2分钟。<strong>引起PET成像误差的因素较多：药物活度的快速衰变、高计数率造成的随机符合、人体吸收衰减和散射等。PET衰变、散射和随机符合等的校正方法均值得深入研究。</strong></p><p>随着医学对疾病认识的深入，一个全面的临床诊断通常需要了解以下问题：（1）病变的形态学情况；（2）病变的生理功能情况；（3）病变的组织定征，如心肌组织是坏死还是冬眠；（4）病变组织的定性，如肺部阴影是否是肿瘤；（5）病变的分子生物学特征。要回答以上问题，不是一种显像设备能够解决，各种影像设备均有不足。CT能够对生物组织进行精细成像，但无法反映病人生理、代谢方面的情况。MR具有很高的软组织对比度分辨率，擅长脑、神经、血管等器官组织成像，能提供解剖学信息。PET能够观察病人的代谢和功能情况，然而图像空间分辨率比CT和MR均要差，解剖定位困难。故而，<strong>多模式复合成像系统是发展趋势，如PET-CT、PET-MR、SPECT-CT等。</strong></p><p>核医学影像数字化和多模复合成像系统是必然趋势，主要研究内容包括：①低剂量成像方法；②稀疏采样图像重建算法；③基于深度学习的智能图像识别算法；④多模成像图像融合方法；⑤射线衰减校正和散射校正方法；⑥成像系统/设备/部件的研制等。</p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/Screenshot%202021-02-23%20120116%20(2).png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;医学影像物理（MIP）&quot;&gt;&lt;a href=&quot;#医学影像物理（MIP）&quot; class=&quot;headerlink&quot; title=&quot;医学影像物理（MIP）&quot;&gt;&lt;/a&gt;医学影像物理（MIP）&lt;/h1&gt;&lt;p&gt;医学影像物理涵盖的范围较广，包括X射线诊断学和临床核医学诊断以及超声成像和核磁共振成像MR(Magnetic Resonance Imaging)等。主要目的是获取生物组织结构信息以及生物功能、代谢和生理状况，为临床治疗提供信息。就核物理和核技术角度而言，主要关注的是X射线诊断和临床核医学诊断。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;以减少生物照射剂量及快速、高效和准确的获取诊断信息为目的，医学影像物理正朝着多模复合成像方向不断更新进步&lt;/strong&gt;，且还存在一些可以研究工作值得进一步推进，具体如图3所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://gitee.com/hubery_lee123/image-source/raw/master/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E5%AD%A6%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B.png&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="核医学" scheme="https://Hubery-Lee.github.io/categories/%E6%A0%B8%E5%8C%BB%E5%AD%A6/"/>
    
    
      <category term="核医学诊断" scheme="https://Hubery-Lee.github.io/tags/%E6%A0%B8%E5%8C%BB%E5%AD%A6%E8%AF%8A%E6%96%AD/"/>
    
  </entry>
  
  <entry>
    <title>肿瘤放射物理</title>
    <link href="https://hubery-lee.github.io/2021/02/27/%E8%82%BF%E7%98%A4%E6%94%BE%E5%B0%84%E7%89%A9%E7%90%86/"/>
    <id>https://hubery-lee.github.io/2021/02/27/%E8%82%BF%E7%98%A4%E6%94%BE%E5%B0%84%E7%89%A9%E7%90%86/</id>
    <published>2021-02-27T14:52:22.000Z</published>
    <updated>2021-02-27T14:56:02.845Z</updated>
    
    <content type="html"><![CDATA[<h1 id="肿瘤放射物理（ROP）"><a href="#肿瘤放射物理（ROP）" class="headerlink" title="肿瘤放射物理（ROP）"></a><strong>肿瘤放射物理（</strong>ROP）</h1><p>以放射物理的基本原理和概念为基础的放射治疗，与手术、化学药物治疗共同组成了目前恶性肿瘤的三大治疗手段。据世界卫生组织（WHO）的统计，肿瘤治疗后45%左右的五年生存率中，22%为手术治疗、18%为放射治疗、5%为药物和其它方法治疗；随着技术发展，放射治疗的应用更加广泛，相关统计表明50%~70%的肿瘤病人需要进行放射治疗。</p><a id="more"></a><p>以最大限度提高肿瘤的控制概率（TCP）、减少正常组织/器官的并发症概率（NTCP）为根本目标，肿瘤放射治疗的照射方式在不断进步，<strong>推动放疗技术向精准治疗发展</strong>。</p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/clip_image002.png" alt="img"></p><h2 id="肿瘤照射方式"><a href="#肿瘤照射方式" class="headerlink" title="肿瘤照射方式"></a><strong>肿瘤照射方式</strong></h2><p>以加速器技术发展为前提，肿瘤照射方式在传统光子（X/γ射线）、电子放疗的基础上，<strong>发展了粒子放疗（质子、重离子）、硼中子俘获治疗（**</strong>BNCT<strong>**）、闪光放疗等技术</strong>。</p><p>由于质子和重离子穿过物质形成布拉格峰的物理特性以及重离子（主要是C离子）优越的放射生物学特性，相对于光子可以增强靶区剂量并降低正常组织损害，特别适合于眼黑色素瘤等不可切除或不完全切除的局部侵犯性肿瘤、儿科恶性肿瘤等辐射耐受性差的肿瘤。随着对粒子治疗的需求不断增加以及加速器技术的日趋成熟，粒子治疗技术发展迅速；根据粒子治疗合作机构（PTCOG）截止2020年8月的统计：全球在运粒子治疗设施104座（质子92、C离子12），在建41座（质子35、C离子5、质子+C离子1），计划建设28座（质子26、质子+C离子2）。但<strong>粒子放射物理学和生物学的优势是否能转化为患者的治疗获益需要在临床中证实，还需要进一步的技术探索和临床研究</strong>，例如：器官运动造成的剂量波动、穿过不同密度组织的靶程不确定问题、剂量分布的均匀性控制、C离子生物效应、离子治疗在线监测成像等。</p><p>BNCT利用含硼（10B）药物在癌细胞内选择性富集的特点，在中子照射时发生硼俘获反应，释放α粒子和7Li粒子来杀死肿瘤细胞，是具有靶向治疗、低毒高效的一种放疗技术，适合于脑胶质瘤、黑色素瘤等肿瘤。近年来随着加速器强流中子源的技术发展，是BNCT大规模临床应用成为可能；例如，日本政府就规划每百万人口配置0.55套BNCT设备。目前BNCT的临床应用还面临诸多问题，如具有特异亲和力的高效含硼药物研发、高精度的硼剂量测量系统等，需要开展大量的技术研发及细胞和动物实验研究工作。</p><p>极高剂量率的射线照射生物体时，会出现肿瘤组织对射线依然敏感但正常组织敏感性降低的“闪光效应”；闪光放疗基于闪光效应的一种具有治疗前景的放疗方式，具有治疗时间极短（50ms）的优点，可避免治疗过程中的移动误差。闪光放疗在2014年从体外研究阶段转向动物体内研究阶段，并于2019年开展了首例人类皮肤淋巴瘤临床试验。目前，闪光放疗尚处于探索阶段，还需要深入开展放射生物学机制、剂量精确控制等方面的探索研究。</p><h2 id="放疗技术"><a href="#放疗技术" class="headerlink" title="放疗技术"></a><strong>放疗技术</strong></h2><p>随着与计算机和影像学技术的有机结合，放射治疗从常规放疗向精准放疗发展，<strong>在**</strong>2<strong><strong>维放疗的基础上实现了</strong></strong>3<strong><strong>维适形放疗和</strong></strong>4<strong><strong>维动态放疗技术，正在探索自适应放疗技术，并提出了基于生物靶向的</strong></strong>5<strong>**维放疗概念</strong>。</p><p>二维放疗是通过遮挡方式实现不规则形状射野进行均匀剂量照射。三维适形放疗（3D-CRT）以三维解剖影像为基础，通过多叶准直器自动控制和正向三维治疗计划，提高射线剂量体积和靶体积在三维形状上的适形指数；调强适形放疗（IMRT）通过逆向三维治疗计划、细分射束子野并动态调强的方式，使靶体积内各点的剂量分布高度适形。影像引导放疗（IGRT）在三维放疗的基础上引入时间因素，通过图像引导来降低摆位误差、器官运动、解剖结构变化对剂量分布的影响；自适应放疗（ART）则是通过影像信息的动态变化修正治疗计划，实施个体化治疗。生物靶向放疗（BIMRT/BIGRT）通过获取代谢、功能、生理和基因表型等生物影像信息，将肿瘤的放射敏感性差异引入放疗计划，是一种将物理适形和生物适形相结合的5维适形放疗概念。</p><p>综上所示，粒子放疗、硼中子俘获治疗、闪光放疗等在未来具有临床前景，与此同时放疗技术也在向精确治疗发展；<strong>但从一种技术手段发展为常规临床治疗手段还需要深入开展以下方面的工作</strong>：①放疗设备/部件国产化研制；②放射生物学机制的基础探索；③多维影像重建/多模式影像融合技术研究；④照射野参数的正向/逆向确定技术研究；⑤图像引导及自适应修正方法；⑥三维剂量仿真及模型验证技术研究；⑦放疗在线监测成像技术研究等。</p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/Screenshot%202021-02-23%20120116%20(2).png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;肿瘤放射物理（ROP）&quot;&gt;&lt;a href=&quot;#肿瘤放射物理（ROP）&quot; class=&quot;headerlink&quot; title=&quot;肿瘤放射物理（ROP）&quot;&gt;&lt;/a&gt;&lt;strong&gt;肿瘤放射物理（&lt;/strong&gt;ROP）&lt;/h1&gt;&lt;p&gt;以放射物理的基本原理和概念为基础的放射治疗，与手术、化学药物治疗共同组成了目前恶性肿瘤的三大治疗手段。据世界卫生组织（WHO）的统计，肿瘤治疗后45%左右的五年生存率中，22%为手术治疗、18%为放射治疗、5%为药物和其它方法治疗；随着技术发展，放射治疗的应用更加广泛，相关统计表明50%~70%的肿瘤病人需要进行放射治疗。&lt;/p&gt;
    
    </summary>
    
    
      <category term="核医学" scheme="https://Hubery-Lee.github.io/categories/%E6%A0%B8%E5%8C%BB%E5%AD%A6/"/>
    
    
      <category term="放疗" scheme="https://Hubery-Lee.github.io/tags/%E6%94%BE%E7%96%97/"/>
    
  </entry>
  
  <entry>
    <title>核医学物理范畴</title>
    <link href="https://hubery-lee.github.io/2021/02/27/%E6%A0%B8%E5%8C%BB%E5%AD%A6%E7%89%A9%E7%90%86%E8%8C%83%E7%95%B4/"/>
    <id>https://hubery-lee.github.io/2021/02/27/%E6%A0%B8%E5%8C%BB%E5%AD%A6%E7%89%A9%E7%90%86%E8%8C%83%E7%95%B4/</id>
    <published>2021-02-27T14:50:06.000Z</published>
    <updated>2021-02-27T14:56:05.900Z</updated>
    
    <content type="html"><![CDATA[<h1 id="核医学物理的范畴"><a href="#核医学物理的范畴" class="headerlink" title="核医学物理的范畴"></a>核医学物理的范畴</h1><p>医学物理（Medical Physics）是把物理学的原理和方法应用于人类疾病的预防、诊断、 治疗和保健的一门交叉学科，主要研究人类疾病诊/治过程中的物理现象、并用物理方法对其进行表达，涉及热、力、声、光、电、磁、核等各种物理因子。</p><a id="more"></a><p>以伦琴发现X射线并用于人体透射、居里夫人发现放射性核素镭并用于肿瘤治疗2项开创性研究为起点，以1974年国际医学物理组织（IOMP）成立为成熟标志，医学物理发展逐步为物理学与医学实践相结合的独立分支学科，涵盖<strong>放射肿瘤物理（ROP）、医学影像物理（MIP）、核医学物理（NMP）、核磁/超声/微波/射频/激光等非电离辐射物理因子的医学应用、保健物理（辐射防护）</strong>等方向。</p><p>医学物理技术贯穿于电离辐射医学应用（即由放射肿瘤学、放射学、核医学三大方向组成的放射诊疗）的各个方面，如图1所示。</p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/F7iJcxXW5T8VQP6.jpg" alt="img"></p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/Screenshot%202021-02-23%20120116%20(2).png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;核医学物理的范畴&quot;&gt;&lt;a href=&quot;#核医学物理的范畴&quot; class=&quot;headerlink&quot; title=&quot;核医学物理的范畴&quot;&gt;&lt;/a&gt;核医学物理的范畴&lt;/h1&gt;&lt;p&gt;医学物理（Medical Physics）是把物理学的原理和方法应用于人类疾病的预防、诊断、 治疗和保健的一门交叉学科，主要研究人类疾病诊/治过程中的物理现象、并用物理方法对其进行表达，涉及热、力、声、光、电、磁、核等各种物理因子。&lt;/p&gt;
    
    </summary>
    
    
      <category term="核医学物理" scheme="https://Hubery-Lee.github.io/categories/%E6%A0%B8%E5%8C%BB%E5%AD%A6%E7%89%A9%E7%90%86/"/>
    
    
      <category term="综述" scheme="https://Hubery-Lee.github.io/tags/%E7%BB%BC%E8%BF%B0/"/>
    
  </entry>
  
  <entry>
    <title>辐射探测与成像相关研究组</title>
    <link href="https://hubery-lee.github.io/2021/02/25/%E8%BE%90%E5%B0%84%E6%8E%A2%E6%B5%8B%E4%B8%8E%E6%88%90%E5%83%8F%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%E7%BB%84/"/>
    <id>https://hubery-lee.github.io/2021/02/25/%E8%BE%90%E5%B0%84%E6%8E%A2%E6%B5%8B%E4%B8%8E%E6%88%90%E5%83%8F%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%E7%BB%84/</id>
    <published>2021-02-25T01:30:42.000Z</published>
    <updated>2021-02-27T04:02:32.055Z</updated>
    
    <content type="html"><![CDATA[<h1 id="辐射探测与成像相关知名研究组"><a href="#辐射探测与成像相关知名研究组" class="headerlink" title="辐射探测与成像相关知名研究组"></a>辐射探测与成像相关知名研究组</h1><blockquote><p>核工程师和放射学家对开发更先进的电离辐射测量和探测系统以及利用这些系统改进成像技术感兴趣。这包括探测器的设计、制造和分析、基本原子和核参数的测量、探测器系统的方法开发、中子活化分析、辐射成像系统、使用穿透辐射对部件进行无损检测和评估，放射卫生工程与医学物理应用。</p></blockquote><a id="more"></a><h2 id="密西根大学-核工程与辐射科学"><a href="#密西根大学-核工程与辐射科学" class="headerlink" title="密西根大学 核工程与辐射科学"></a>密西根大学 核工程与辐射科学</h2><h3 id="辐射成像组"><a href="#辐射成像组" class="headerlink" title="辐射成像组"></a>辐射成像组</h3><p>由镉、锌和碲组成的透明、半导体立方体，通过识别核材料发出的伽马射线的能量和方向，可以揭示核材料的身份和下落。钟和教授的实验室开发了基于CdZnTe的探测器，用于国家安全和天文学等领域。探测器可以定位脏弹和其他核武器，也可以揭示月球或火星的成分。他的团队正在开发成像技术、数据采集系统和替代性的、更便宜的半导体，可能取代CdZnTe。</p><p><span class="exturl" data-url="aHR0cHM6Ly9jenRsYWIuZW5naW4udW1pY2guZWR1Lw==">MIT He Zhong 团队<i class="fa fa-external-link-alt"></i></span></p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210224110453854.png" alt="image-20210224110453854"></p><h3 id="探测方法组"><a href="#探测方法组" class="headerlink" title="探测方法组"></a>探测方法组</h3><p>由大卫·韦赫教授领导的探测方法小组探索半导体辐射探测器材料、处理探测器信号的集成电路以及伽马射线辐射成像。这项研究的主要目标是在广泛的应用中增强辐射检测的可用选项：国土安全、医疗和工业用途以及科学研究。</p><p><span class="exturl" data-url="aHR0cHM6Ly9yYWRtZWFzLmVuZ2luLnVtaWNoLmVkdS8=">David Wehe 团队<i class="fa fa-external-link-alt"></i></span></p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210224110406931.png" alt="image-20210224110406931"></p><h3 id="核不扩散组"><a href="#核不扩散组" class="headerlink" title="核不扩散组"></a>核不扩散组</h3><p>萨拉·波齐教授的研究小组致力于开发新的工具和技术，以探测和识别可制成核武器的铀和钚等材料。他们的研究包括建立既能测量中子又能测量光子的探测器阵列，开发解释探测器数据的算法，以及使用可测量的特征来评估核材料的成分。这些类型的探测器可用于边境口岸和海港扫描行李和海运集装箱。它们还可以监测核燃料的生产，并测量与裂变物理有关的核数据。</p><p><span class="exturl" data-url="aHR0cHM6Ly9kbm5nLmVuZ2luLnVtaWNoLmVkdS8=">Sara Pozzi 团队<i class="fa fa-external-link-alt"></i></span></p><h3 id="应用核科学组"><a href="#应用核科学组" class="headerlink" title="应用核科学组"></a>应用核科学组</h3><p>伊戈尔·约万诺维奇教授领导的应用核科学小组利用电离辐射和激光与物质相互作用的物理学来解决核安全、能源和基础科学的新应用。他的小组开发了中子探测器和主动询问方法，以及用于核不扩散应用的各种规模的反中微子探测器。在Gérard Mourou超快光学科学中心，他开发了新的超快光源和方法，用于通过激光光谱进行远程和痕量材料检测，以及用于高场科学和核光子学的强激光科学和技术。</p><p><span class="exturl" data-url="aHR0cHM6Ly9hbnNnLmVuZ2luLnVtaWNoLmVkdS8=">Igor Jovanovic 团队<i class="fa fa-external-link-alt"></i></span></p><h3 id="辐射剂量机理组"><a href="#辐射剂量机理组" class="headerlink" title="辐射剂量机理组"></a>辐射剂量机理组</h3><p>Alex Bielajew教授及其同事建立了电子和光子如何在物质中移动的数学和计算机模型，以精确预测人体中的剂量沉积，并更准确地解释辐射剂量计读数，从而减少了通过放射疗法治疗癌症所需的总辐射剂量。</p><p><span class="exturl" data-url="aHR0cHM6Ly9uZXJzLmVuZ2luLnVtaWNoLmVkdS9wZW9wbGUvYWxleC1iaWVsYWpldy8=">Alex Bielajew 团队<i class="fa fa-external-link-alt"></i></span></p><h3 id="放射卫生工程组"><a href="#放射卫生工程组" class="headerlink" title="放射卫生工程组"></a>放射卫生工程组</h3><p>Kimberlee Kearfott教授的实验室正在开发新颖的探测器和剂量计设计，并改进了用于医疗，工业，实验室和核电辐射安全应用的测量方法。 该小组将精力集中在可在不久的将来部署的实用系统和辐射测量方法上。</p><p><a href>Kimberlee Kearfott</a></p><p>正在认证成为医学物理培训资格，密歇根大学具备这种资格</p><h2 id="麻省理工大学-核科学与工程"><a href="#麻省理工大学-核科学与工程" class="headerlink" title="麻省理工大学 核科学与工程"></a>麻省理工大学 核科学与工程</h2><p><span class="exturl" data-url="aHR0cHM6Ly93ZWIubWl0LmVkdS9uc2UvaW5kZXguaHRtbA==">麻省理工大学核科学与工程<i class="fa fa-external-link-alt"></i></span> 主要研究领域包括：裂变、聚变、核安全、【辐射源、探测与测量】、建模与仿真、极端环境下的材料特性分析</p><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/image-20210224113237602.png" alt="image-20210224113237602"></p><p>其中，有关【辐射源、探测与测量】相关的研究方向介绍如下：</p><blockquote><p>核科学与工程系的主要目标是提高实现辐射科学与技术的新有益应用所需的核心学科。 这些学科包括辐射的产生和控制以及辐射与物质相互作用的研究和应用。</p><p>我们研究新颖的辐射源，这些辐射源将在医学成像，基于辐射的治疗，违禁品检测以及纳米和介观系统的化学和物理性质研究中找到应用，还使用新的辐射源，例如Oak实验室的散列中子源使推动探索化学和物理学的距离和时间维度成为可能。</p><p>我们还对非电离辐射的精确控制和表征感兴趣。 这些辐射场的完整量子力学描述将允许它们应用于量子系统的相干控制。 实现这种精致的控制将使量子信息处理（QIP）概念的实际实现成为可能。</p></blockquote><p>【建模与仿真】</p><blockquote><p>在多尺度和多物理场建模方面令人振奋的新发展，再加上高性能计算机以及相关算法和仿真方法的迅速发展，使人们有可能以比以往更高的保真度来模拟核系统。 该部门所有主要应用领域均以对高级计算建模和仿真研究的综合关注为基础。 NSE的教师和学生在许多重要领域从事前沿研究，包括反应堆中子学和热力学，等离子体湍流建模以及原子分辨率，核环境中的长期材料模拟。 在这些领域中的每一个领域，研究都与实验计划紧密结合，以进行模型验证以及促进对科学的理解和新机制模型的开发。</p></blockquote><p>【极端环境下材料特性】</p><blockquote><p>对材料性能的限制是提高核能系统安全性和经济性的最大技术障碍之一。确保结构和其他材料在老化的商用轻水堆动力反应堆群中的生存能力，对于目前将这些核电站的寿命延长到60年以上的努力至关重要。下一代快裂变反应堆和未来的聚变装置将需要克服更严峻的材料挑战，包括高原子位移率以及快中子谱中质子/氦的产生。安全处置高放射性废物需要将放射性核素控制在工程屏障内，这些屏障必须能承受数千年的高温、应力和辐射场，还可能承受腐蚀性液体的渗透。</p><p>开发能在这些恶劣工作环境中发挥良好性能的材料是材料科学面临的一个重大挑战，需要对辐射通量、温度和应力等极端条件下的材料响应有基本的了解。化学和物理过程必须在从原子到宏观的多个物理尺度上理解和控制，时间尺度从不到一纳秒到几十年（对于核废料来说，时间更长）。令人兴奋的新的科学工具的集合正在出现，这将使这一点成为可能，包括先进的紧凑适用于大学规模实验室的辐射源；纳米尺度的材料探针和表征；以及具有大规模计算能力的最先进数值模型。</p></blockquote><h2 id="田纳西大学核工程部"><a href="#田纳西大学核工程部" class="headerlink" title="田纳西大学核工程部"></a>田纳西大学核工程部</h2><p> <span class="exturl" data-url="aHR0cHM6Ly9uZS51dGsuZWR1Lw==">核工程系<i class="fa fa-external-link-alt"></i></span> 成立于1957年，是美国历史最悠久，最负盛名的计划之一。<br>师资力量以卓越的研究和教学能力而享誉国际，并且通过与橡树岭国家实验室，Y-12核安保综合体，UCOR，东田纳西州技术园（ETTP）等的紧密联系来加强我们的高级研究计划。 位于诺克斯维尔五十英里范围内的一百多家核相关公司。<br>田纳西州东部可能是世界上核工业最集中的地区，因此是进行核教育的理想之地。</p><p>与八个大学研究中心（包括核安全研究所，先进材料联合研究所，中子科学联合研究所，可靠性和可维护性中心，闪烁材料研究中心）一起在八个不同的研究领域中探索和提出了思想和概念。 ，以及本地合作者，例如Oak Ridge国家实验室。</p><p>主要研究方向先进建模与仿真、核聚变技术、【核设施控制、可靠性与安全】、核反应堆燃料与材料、辐射探测与测量、放射科学与保健物理</p><p>其中，辐射探测与测量主要研究方向包括：</p><h3 id="闪烁体探测器材料与应用工程"><a href="#闪烁体探测器材料与应用工程" class="headerlink" title="闪烁体探测器材料与应用工程"></a>闪烁体探测器材料与应用工程</h3><p>对闪烁材料的研究范围从新化合物的发现到独特性能的表征，再到在创新的探测和成像系统中引入新材料。研究生们经常种植以前未知成分的晶体，研究辐射与新材料的相互作用，有时与国家实验室的研究人员合作。达到更发达阶段的闪烁材料可用于在核安全和/或医学成像中具有重要应用的新型探测系统。具有精确测量吸收伽马辐射能量能力的特殊闪烁体对于识别放射性物质非法来源至关重要，而具有更快时间响应的闪烁探测器最终可能使癌症和阿尔茨海默病等疾病的诊断更早、更准确</p><h3 id="半导体探测器的研发"><a href="#半导体探测器的研发" class="headerlink" title="半导体探测器的研发"></a>半导体探测器的研发</h3><p>在这个领域中有几个正在进行的项目，它们跨越了许多应用空间。 当前的半导体开发项目包括氮化硼，二硒化锂铟，金刚石和三溴化甲基铵铅，其应用范围从第四代反应堆中的先进多模式传感器到冷中子成像。</p><h3 id="用于中子科学设施的中子仪器"><a href="#用于中子科学设施的中子仪器" class="headerlink" title="用于中子科学设施的中子仪器"></a>用于中子科学设施的中子仪器</h3><p>我们的闪烁体和半导体系统开发的一个重要重点是在全球的中子科学设施中启用新的仪器功能。 其中有数十个正在运行，还有更多正在建设中，包括欧洲散裂源。 一个特别关注的是用于中子成像的高分辨率传感器，朝着1微米空间分辨率的目标努力。 一项用于反射测定法和He-3替代技术的高速率仪器正在进行或已完成其他工作。 我们与ORNL中子科学和Paul Scherrer研究所有着紧密的合作关系。  ORNL是散裂中子源和高通量同位素反应堆之间的许多光束线，是中子科学领域的全球领导者。  Paul Scherrer研究所是高分辨率中子成像领域的全球领导者。</p><h3 id="核材料辐射成像系统"><a href="#核材料辐射成像系统" class="headerlink" title="核材料辐射成像系统"></a>核材料辐射成像系统</h3><p>正在进行的工作或最近完成的工作涉及对伽马，X射线，快中子，慢中子或μ子成像的系统。 许多工作与核材料或核材料组件的成像有关，旨在检测，定位和表征它们。 辐射的被动和主动传感都在研究中，其中主动传感需要询问源，例如X射线线性加速器或氘-中子发生器。 在许多工作中，ORNL都是重要的合作伙伴。 该领域的另一个合作伙伴是Varex Imaging。</p><h3 id="辐射探测器数据处理与算法开发"><a href="#辐射探测器数据处理与算法开发" class="headerlink" title="辐射探测器数据处理与算法开发"></a>辐射探测器数据处理与算法开发</h3><p>小组还研究了从所述材料和系统生成的数据的处理，以及与核材料和放射材料的检测，定位和表征相关的算法开发。</p><h3 id="🏡实验设施"><a href="#🏡实验设施" class="headerlink" title="🏡实验设施"></a>🏡实验设施</h3><h4 id="微处理研究设施"><a href="#微处理研究设施" class="headerlink" title="微处理研究设施"></a>微处理研究设施</h4><p>田纳西大学的微处理研究设施（MPRF）是UT的核心设施，位于先进材料联合研究所（JIAM）内。 MPRF使研究人员能够进行微处理制造过程。服务包括光刻，薄膜沉积，电容耦合反应性离子蚀刻以及基于硅的等离子体增强化学气相沉积工艺。该设备位于具有所有必要设施和辅助处理设备的100级无尘室中。结合其他JIAM设施，MPRF为研究人员提供了进行材料科学和工程学前沿研究的方法。</p><h4 id="散射体材料研究中心-SMRC"><a href="#散射体材料研究中心-SMRC" class="headerlink" title="散射体材料研究中心(SMRC)"></a>散射体材料研究中心<strong><span class="exturl" data-url="aHR0cHM6Ly90aWNrbGUudXRrLmVkdS9zbXJjLg==">(SMRC)<i class="fa fa-external-link-alt"></i></span></strong></h4><p>该中心位于大学科学与工程研究设施的主校区，结合了包括核工程在内的多个部门的资源，用于研究项目，这些研究项目致力于为最先进的辐射传感器和成像系统开发创新材料。 SMRC为核工程，材料科学与工程，能源科学与工程和化学领域的研究生和本科生提供了支持。它具有广泛的晶体生长设备，以及用于研究基本材料特性和新型材料对辐射的响应的众多仪器。 SMRC积极研究各种物理形式的闪烁材料，包括无机单晶，多晶陶瓷和有机塑料。</p><h4 id="辐射成像，检测，算法和系统（Rad-IDEAS）实验室"><a href="#辐射成像，检测，算法和系统（Rad-IDEAS）实验室" class="headerlink" title="辐射成像，检测，算法和系统（Rad IDEAS）实验室"></a>辐射成像，检测，算法和系统（Rad IDEAS）实验室</h4><p>在Rad IDEAS实验室中，我们拥有大量的伽马，中子和阿尔法源。辐射传感器和光学组件；单通道和多通道核电子模块；数据采集电子设备；示波器;高性能的多核工作站，用于数据采集，处理和仿真。该实验室主要用于辐射检测和成像中新的概念验证水平实验，或用于准备在现场进行测量的实验系统。</p><h4 id="双重混合检测定位成像（双重混合DLI）系统"><a href="#双重混合检测定位成像（双重混合DLI）系统" class="headerlink" title="双重混合检测定位成像（双重混合DLI）系统"></a>双重混合检测定位成像（双重混合DLI）系统</h4><p>双混合检测定位成像（DLI）拖车包含内置于一维编码孔径成像阵列中的大量NaI检测器和有机闪烁体。它可用于移动伽马成像和检测，移动或固定背景测量或伽马或中子或研究生实验室练习。</p><h4 id="ORNL相关实验设备"><a href="#ORNL相关实验设备" class="headerlink" title="ORNL相关实验设备"></a>ORNL相关实验设备</h4><p>其他相关设备和设施包括：伴随粒子成像（API）（D-T）中子发生器； Cf-252电离室;核材料识别系统（NMIS），包括实验室和现场版本；便携式中子编码孔径成像系统；其他伽马射线编码孔径成像系统；进入储存铀标准的核保障实验室；和门户监视工具。</p><h4 id="Varex影像设备"><a href="#Varex影像设备" class="headerlink" title="Varex影像设备"></a>Varex影像设备</h4><p>UT在芝加哥奥黑尔（ORD）机场附近的Varex Imaging设施拥有并运营着6/9 MV线性加速器。 该直线加速器可用于与安全，工业或医疗应用中的货物扫描有关的实验。</p><h2 id="橡树岭实验室"><a href="#橡树岭实验室" class="headerlink" title="橡树岭实验室"></a>橡树岭实验室</h2><p><span class="exturl" data-url="aHR0cHM6Ly93d3cub3JubC5nb3YvZ3JvdXAvYWR2YW5jZWQtcmFkaWF0aW9uLWRldGVjdGlvbi1pbWFnaW5nLWRhdGEtc2NpZW5jZS1hbmQtYXBwbGljYXRpb25z">辐射探测、成像、数据科学和应用研究组<i class="fa fa-external-link-alt"></i></span></p><p>进行研究和开发是为了了解和利用辐射衰减，射线照相/断层扫描，系统建模和检测网络的组合特征，这些特征可用于一系列基础物理学，下一代高级概念系统以及当前的实际应用中</p><h2 id="伊利诺伊大学香槟分校-辐射探测与成像研究组"><a href="#伊利诺伊大学香槟分校-辐射探测与成像研究组" class="headerlink" title="伊利诺伊大学香槟分校 辐射探测与成像研究组"></a>伊利诺伊大学香槟分校 辐射探测与成像研究组</h2><p><span class="exturl" data-url="aHR0cDovL3JhZGltZy5ucHJlLmlsbGlub2lzLmVkdS9pbmRleC5odG1s">伊利诺伊大学香槟分校 辐射探测与成像研究组<i class="fa fa-external-link-alt"></i></span></p><p>采用系统的方法来开发先进的放射成像技术，以帮助解决当今我们面临的一些最具挑战性的疾病，例如脑癌，心脏病和神经退行性疾病。我们的工作重点是探索各种技术前沿，以开发能够以更高的效率，空间，能量和定时精度检测入射粒子的辐射传感器。</p><p>1）我们为要求苛刻的SPECT和PET应用开发和应用超高性能伽马射线成像传感器。</p><p>2）我们研究了先进的图像形成技术，例如人工复眼伽马相机和自适应光圈设计，以改善空间分辨率和灵敏度之间的权衡。</p><p>3）我们开发了统计技术，例如改进的统一Cramer-Rao边界（M-UCRB），以设计和优化复杂的放射成像系统，从而可以提供最佳效率来获得有用的成像信息和</p><p>4）我们探索利用广泛的EM辐射（从射频，可见照片，软X射线到高能伽马射线）的成像技术，以及多种物理和化学原理来生成断层图像，以可视化生物样品内部的生理过程，活体动物和患者。</p><h2 id="其他国内外其他知名研究机构"><a href="#其他国内外其他知名研究机构" class="headerlink" title="其他国内外其他知名研究机构"></a>其他国内外其他知名研究机构</h2><ul><li><span class="exturl" data-url="aHR0cHM6Ly9ob21lLmNlcm4v">欧洲核子中心<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cDovL3d3dy5paGVwLmNhcy5jbi8=">中科院高能物理研究所<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cDovL3d3dy5pbXBjYXMuYWMuY24v">中科院近代物理研究所<i class="fa fa-external-link-alt"></i></span></li></ul><h2 id="主要杂志"><a href="#主要杂志" class="headerlink" title="主要杂志"></a>主要杂志</h2><p><strong>英文期刊</strong></p><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuam91cm5hbHMuZWxzZXZpZXIuY29tL251Y2xlYXItaW5zdHJ1bWVudHMtYW5kLW1ldGhvZHMtaW4tcGh5c2ljcy1yZXNlYXJjaC1zZWN0aW9uLWEtYWNjZWxlcmF0b3JzLXNwZWN0cm9tZXRlcnMtZGV0ZWN0b3JzLWFuZC1hc3NvY2lhdGVkLWVxdWlwbWVudA==">Nuclear Instruments and Methods in Physics Research Section A : Accelerators, Spectrometers, Detectors and Associated Equipment<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuam91cm5hbHMuZWxzZXZpZXIuY29tL251Y2xlYXItaW5zdHJ1bWVudHMtYW5kLW1ldGhvZHMtaW4tcGh5c2ljcy1yZXNlYXJjaC1zZWN0aW9uLWItYmVhbS1pbnRlcmFjdGlvbnMtd2l0aC1tYXRlcmlhbHMtYW5kLWF0b21z">Nuclear Instruments and Methods in Physics Research Section B: Beam Interactions with Materials and Atoms<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuam91cm5hbHMuZWxzZXZpZXIuY29tL3Byb2dyZXNzLWluLXBhcnRpY2xlLWFuZC1udWNsZWFyLXBoeXNpY3M=">Progress in Particle and Nuclear Physics<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuam91cm5hbHMuZWxzZXZpZXIuY29tL251Y2xlYXItYW5kLXBhcnRpY2xlLXBoeXNpY3MtcHJvY2VlZGluZ3M=">Nuclear and Particle Physics Proceedings<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuam91cm5hbHMuZWxzZXZpZXIuY29tL2FwcGxpZWQtcmFkaWF0aW9uLWFuZC1pc290b3Blcw==">Applied Radiation and Isotopes<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuam91cm5hbHMuZWxzZXZpZXIuY29tL251Y2xlYXItcGh5c2ljcy1h">Nuclear Physics A<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuam91cm5hbHMuZWxzZXZpZXIuY29tL251Y2xlYXItcGh5c2ljcy1i">Nuclear Physics B<i class="fa fa-external-link-alt"></i></span></li></ul><p><strong>中文期刊</strong></p><ul><li><span class="exturl" data-url="aHR0cDovL3d3dy5hZXN0Lm9yZy5jbi9DTi92b2x1bW4vY3VycmVudC5zaHRtbA==">原子能科学技术<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cDovL3d3dy5qLnNpbmFwLmFjLmNuL2hqcy9DTi8wMjUzLTMyMTkvaG9tZS5zaHRtbA==">核技术<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cDovL3d3dy5ucHIuYWMuY24v">原子核物理评论<i class="fa fa-external-link-alt"></i></span></li><li><a href>各大学学报</a></li></ul><p><img src="https://gitee.com/hubery_lee123/image-source/raw/master/Screenshot%202021-02-23%20120116%20(2).png" alt="Screenshot 2021-02-23 120116 (2)"></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;辐射探测与成像相关知名研究组&quot;&gt;&lt;a href=&quot;#辐射探测与成像相关知名研究组&quot; class=&quot;headerlink&quot; title=&quot;辐射探测与成像相关知名研究组&quot;&gt;&lt;/a&gt;辐射探测与成像相关知名研究组&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;核工程师和放射学家对开发更先进的电离辐射测量和探测系统以及利用这些系统改进成像技术感兴趣。这包括探测器的设计、制造和分析、基本原子和核参数的测量、探测器系统的方法开发、中子活化分析、辐射成像系统、使用穿透辐射对部件进行无损检测和评估，放射卫生工程与医学物理应用。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="综述" scheme="https://Hubery-Lee.github.io/categories/%E7%BB%BC%E8%BF%B0/"/>
    
    
      <category term="辐射探测与成像" scheme="https://Hubery-Lee.github.io/tags/%E8%BE%90%E5%B0%84%E6%8E%A2%E6%B5%8B%E4%B8%8E%E6%88%90%E5%83%8F/"/>
    
  </entry>
  
  <entry>
    <title>opencv-python哔哩哔哩视频解说代码</title>
    <link href="https://hubery-lee.github.io/2020/07/28/opencv-python%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E8%A7%86%E9%A2%91%E4%BB%A3%E7%A0%81/"/>
    <id>https://hubery-lee.github.io/2020/07/28/opencv-python%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E8%A7%86%E9%A2%91%E4%BB%A3%E7%A0%81/</id>
    <published>2020-07-28T02:38:27.000Z</published>
    <updated>2021-02-27T08:43:04.129Z</updated>
    
    <content type="html"><![CDATA[<p>参考：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL211cnRhemFoYXNzYW4vTGVhcm4tT3BlbkNWLWluLTMtaG91cnM=">https://github.com/murtazahassan/Learn-OpenCV-in-3-hours<i class="fa fa-external-link-alt"></i></span></p><a id="more"></a><h1 id="文档说明"><a href="#文档说明" class="headerlink" title="文档说明"></a>文档说明</h1><p>其中，<code>chapter 11~17</code> 待更新</p><ul><li><p>chapter 1  <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0h1YmVyeS1MZWUvb3BlbmN2LXB5dGhvbi9jaGFwdGVyMS5weQ==">资源读取：图片、视频、摄像头<i class="fa fa-external-link-alt"></i></span></p></li><li><p>chapter 2  <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0h1YmVyeS1MZWUvb3BlbmN2LXB5dGhvbi9jaGFwdGVyMi5weQ==">二值化、滤波模糊、膨胀、腐蚀<i class="fa fa-external-link-alt"></i></span></p></li><li><p>chapter 3  <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0h1YmVyeS1MZWUvb3BlbmN2LXB5dGhvbi9jaGFwdGVyMy5weQ==">画图、形状、文字<i class="fa fa-external-link-alt"></i></span></p></li><li><p>chapter 4 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0h1YmVyeS1MZWUvb3BlbmN2LXB5dGhvbi9jaGFwdGVyNC5weQ==">图像的旋转与仿生变换<i class="fa fa-external-link-alt"></i></span></p></li><li><p>chapter 5 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0h1YmVyeS1MZWUvb3BlbmN2LXB5dGhvbi9jaGFwdGVyNS5weQ==">拼图<i class="fa fa-external-link-alt"></i></span></p></li><li><p>chapter 6 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0h1YmVyeS1MZWUvb3BlbmN2LXB5dGhvbi9jaGFwdGVyNi5weQ==">全景图像拼接<i class="fa fa-external-link-alt"></i></span></p></li><li><p>chapter 7 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0h1YmVyeS1MZWUvb3BlbmN2LXB5dGhvbi9jaGFwdGVyNy5weQ==">检测颜色<i class="fa fa-external-link-alt"></i></span></p></li><li><p>chapter 8 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0h1YmVyeS1MZWUvb3BlbmN2LXB5dGhvbi9jaGFwdGVyOC5weQ==">检测形状<i class="fa fa-external-link-alt"></i></span></p></li><li><p>chapter 9 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0h1YmVyeS1MZWUvb3BlbmN2LXB5dGhvbi9jaGFwdGVyOS5weQ==">人脸检测<i class="fa fa-external-link-alt"></i></span></p></li><li><p>chapter 10 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0h1YmVyeS1MZWUvb3BlbmN2LXB5dGhvbi9jaGFwdGVyMTAucHk=">虚拟油画<i class="fa fa-external-link-alt"></i></span></p></li><li><p>chapter 11 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0h1YmVyeS1MZWUvb3BlbmN2LXB5dGhvbi9jaGFwdGVyMTEucHk=">文档识别<i class="fa fa-external-link-alt"></i></span></p></li><li><p>chapter 12 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0h1YmVyeS1MZWUvb3BlbmN2LXB5dGhvbi9jaGFwdGVyMTIucHk=">车牌识别、信用卡号识别<i class="fa fa-external-link-alt"></i></span></p></li><li><p>chapter 13 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0h1YmVyeS1MZWUvb3BlbmN2LXB5dGhvbi9jaGFwdGVyMTMucHk=">答题卡识别<i class="fa fa-external-link-alt"></i></span></p></li><li><p>chapter 14 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0h1YmVyeS1MZWUvb3BlbmN2LXB5dGhvbi9jaGFwdGVyMTQucHk=">目标追踪<i class="fa fa-external-link-alt"></i></span></p></li><li><p>chapter 15 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0h1YmVyeS1MZWUvb3BlbmN2LXB5dGhvbi9jaGFwdGVyMTUucHk=">人脸疲劳检测<i class="fa fa-external-link-alt"></i></span></p></li><li><p>chapter 16 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0h1YmVyeS1MZWUvb3BlbmN2LXB5dGhvbi9jaGFwdGVyMTYucHk=">dnn 神经网络识别<i class="fa fa-external-link-alt"></i></span></p></li><li><p>chapter 17 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0h1YmVyeS1MZWUvb3BlbmN2LXB5dGhvbi9jaGFwdGVyMTcucHk=">光流估计和背景建模<i class="fa fa-external-link-alt"></i></span></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考：&lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM6Ly9naXRodWIuY29tL211cnRhemFoYXNzYW4vTGVhcm4tT3BlbkNWLWluLTMtaG91cnM=&quot;&gt;https://github.com/murtazahassan/Learn-OpenCV-in-3-hours&lt;i class=&quot;fa fa-external-link-alt&quot;&gt;&lt;/i&gt;&lt;/span&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="openCV" scheme="https://Hubery-Lee.github.io/categories/openCV/"/>
    
    
      <category term="python" scheme="https://Hubery-Lee.github.io/tags/python/"/>
    
      <category term="openCV" scheme="https://Hubery-Lee.github.io/tags/openCV/"/>
    
  </entry>
  
  <entry>
    <title>Django如何搭建web应用</title>
    <link href="https://hubery-lee.github.io/2020/07/12/Django%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAweb%E5%BA%94%E7%94%A8/"/>
    <id>https://hubery-lee.github.io/2020/07/12/Django%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAweb%E5%BA%94%E7%94%A8/</id>
    <published>2020-07-12T13:40:31.000Z</published>
    <updated>2020-07-12T16:33:40.593Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Django如何搭建web应用"><a href="#Django如何搭建web应用" class="headerlink" title="Django如何搭建web应用"></a>Django如何搭建web应用</h1><h2 id="🛒Django的特点"><a href="#🛒Django的特点" class="headerlink" title="🛒Django的特点"></a>🛒Django的特点</h2><p>Django 最初被设计用于具有快速开发需求的新闻类站点，目的是要实现简单快捷的网站开发。以下内容简要介绍了如何使用 Django 实现一个数据库驱动的 Web 应用。</p><p><span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmRqYW5nb3Byb2plY3QuY29tL3poLWhhbnMvMy4wL2ludHJvL292ZXJ2aWV3Lw==">https://docs.djangoproject.com/zh-hans/3.0/intro/overview/<i class="fa fa-external-link-alt"></i></span></p><ul><li><p><strong><span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvT2JqZWN0LXJlbGF0aW9uYWxfbWFwcGluZw==">对象关系映射器<i class="fa fa-external-link-alt"></i></span></strong> </p><p>可以使用强大的 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmRqYW5nb3Byb2plY3QuY29tL3poLWhhbnMvMy4wL3RvcGljcy9kYi9tb2RlbHMv">数据-模型语句<i class="fa fa-external-link-alt"></i></span> 来描述你的数据模型，这解决了数年以来在数据库模式中的难题。</p></li><li><p><strong>享用便捷的 API</strong></p><p>可以使用一套便捷而丰富的 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmRqYW5nb3Byb2plY3QuY29tL3poLWhhbnMvMy4wL3RvcGljcy9kYi9xdWVyaWVzLw==">Python API<i class="fa fa-external-link-alt"></i></span> 访问你的数据。API是动态创建的，不需要代码生成</p></li><li><p><strong>动态管理接口</strong></p><p>当你的模型完成定义，Django 就会自动生成一个专业的生产级 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmRqYW5nb3Byb2plY3QuY29tL3poLWhhbnMvMy4wL3JlZi9jb250cmliL2FkbWluLw==">管理接口<i class="fa fa-external-link-alt"></i></span> ——一个允许认证用户添加、更改和删除对象的 Web 站点。你只需在 admin 站点上注册你的模型即可：</p></li><li><p><strong>规划 URLs</strong></p><p>Django 推崇优美的 URL 设计，所以不要把诸如 <code>.php</code> 和 <code>.asp</code> 之类的冗余的后缀放到 URL 里。</p><p>需要创建一个叫做 URLconf 的 Python 模块。这是网站的目录，它包含了一张 URL 和 Python 回调函数之间的映射表。URLconf 也有利于将 Python 代码与 URL 进行解耦（译注：使各个模块分离，独立）</p></li><li><p><strong>编写视图</strong></p><p>视图函数的执行结果只可能有两种：返回一个包含请求页面元素的 <a href="https://docs.djangoproject.com/zh-hans/3.0/ref/request-response/#django.http.HttpResponse"><code>HttpResponse</code></a> 对象，或者是抛出 <a href="https://docs.djangoproject.com/zh-hans/3.0/topics/http/views/#django.http.Http404"><code>Http404</code></a> 这类异常。至于执行过程中的其它的动作则由你决定。</p></li><li><p><strong>设计模板</strong><br>Django 允许设置搜索模板路径，这样可以最小化模板之间的冗余。在 Django 设置中，你可以通过 DIRS 参数指定一个路径列表用于检索模板。如果第一个路径中不包含任何模板，就继续检查第二个，以此类推。</p></li></ul><h2 id="🎈项目框架"><a href="#🎈项目框架" class="headerlink" title="🎈项目框架"></a>🎈项目框架</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysite&#x2F;</span><br><span class="line">    manage.py</span><br><span class="line">    mysite&#x2F;</span><br><span class="line">        __init__.py</span><br><span class="line">        settings.py</span><br><span class="line">        urls.py</span><br><span class="line">        asgi.py</span><br><span class="line">        wsgi.py</span><br></pre></td></tr></table></figure><p>这些目录和文件的用处是：</p><ul><li><p>最外层的 <code>mysite/</code> 根目录只是你项目的容器， 根目录名称对Django没有影响，你可以将它重命名为任何你喜欢的名称。</p></li><li><p><code>manage.py</code>: 一个让你用各种方式管理 Django 项目的命令行工具。你可以阅读 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmRqYW5nb3Byb2plY3QuY29tL3poLWhhbnMvMy4wL3JlZi9kamFuZ28tYWRtaW4v">django-admin and manage.py<i class="fa fa-external-link-alt"></i></span> 获取所有 <code>manage.py</code> 的细节。</p></li><li><p>里面一层的 <code>mysite/</code> 目录包含你的项目，它是一个纯 Python 包。它的名字就是当你引用它内部任何东西时需要用到的 Python 包名。 (比如 <code>mysite.urls</code>).</p></li><li><p><code>mysite/__init__.py</code>：一个空文件，告诉 Python 这个目录应该被认为是一个 Python 包。如果你是 Python 初学者，阅读官方文档中的 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnB5dGhvbi5vcmcvMy90dXRvcmlhbC9tb2R1bGVzLmh0bWwjdHV0LXBhY2thZ2Vz">更多关于包的知识<i class="fa fa-external-link-alt"></i></span>。</p></li><li><p><code>mysite/settings.py</code>：Django 项目的配置文件。如果你想知道这个文件是如何工作的，请查看 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmRqYW5nb3Byb2plY3QuY29tL3poLWhhbnMvMy4wL3RvcGljcy9zZXR0aW5ncy8=">Django 配置<i class="fa fa-external-link-alt"></i></span> 了解细节。</p></li><li><p><code>mysite/urls.py</code>：Django 项目的 URL 声明，就像你网站的“目录”。阅读 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmRqYW5nb3Byb2plY3QuY29tL3poLWhhbnMvMy4wL3RvcGljcy9odHRwL3VybHMv">URL调度器<i class="fa fa-external-link-alt"></i></span> 文档来获取更多关于 URL 的内容。</p></li><li><p><code>mysite/asgi.py</code>：作为你的项目的运行在 ASGI 兼容的Web服务器上的入口。阅读 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmRqYW5nb3Byb2plY3QuY29tL3poLWhhbnMvMy4wL2hvd3RvL2RlcGxveW1lbnQvd3NnaS8=">如何使用 WSGI 进行部署<i class="fa fa-external-link-alt"></i></span> 了解更多细节。</p></li><li><p><code>mysite/wsgi.py</code>：作为你的项目的运行在 WSGI 兼容的Web服务器上的入口。阅读 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmRqYW5nb3Byb2plY3QuY29tL3poLWhhbnMvMy4wL2hvd3RvL2RlcGxveW1lbnQvd3NnaS8=">如何使用 WSGI 进行部署<i class="fa fa-external-link-alt"></i></span> 了解更多细节。</p></li></ul><h2 id="🍎应用框架"><a href="#🍎应用框架" class="headerlink" title="🍎应用框架"></a>🍎应用框架</h2><h3 id="🍏应用与项目的关系"><a href="#🍏应用与项目的关系" class="headerlink" title="🍏应用与项目的关系"></a>🍏应用与项目的关系</h3><p><img src="/2020/07/12/Django%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAweb%E5%BA%94%E7%94%A8/%E6%A0%B9%E7%9B%AE%E5%BD%95.png" alt></p><h3 id="🔱创建应用的框架"><a href="#🔱创建应用的框架" class="headerlink" title="🔱创建应用的框架"></a>🔱创建应用的框架</h3><p>创建一个 <code>polls</code> 目录，它的目录结构大致如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">polls&#x2F;</span><br><span class="line">    __init__.py</span><br><span class="line">    admin.py</span><br><span class="line">    apps.py</span><br><span class="line">    migrations&#x2F;</span><br><span class="line">        __init__.py</span><br><span class="line">    models.py</span><br><span class="line">    tests.py</span><br><span class="line">    views.py</span><br></pre></td></tr></table></figure><p>这个目录结构包括了投票应用的全部内容。</p><h3 id="❗应用的调试模块"><a href="#❗应用的调试模块" class="headerlink" title="❗应用的调试模块"></a>❗应用的调试模块</h3><p><strong><code>为什么要进行调试？</code><span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmRqYW5nb3Byb2plY3QuY29tL3poLWhhbnMvMy4wL2ludHJvL3R1dG9yaWFsMDUv">参考<i class="fa fa-external-link-alt"></i></span></strong></p><ul><li><h4 id="测试将节约你的时间"><a href="#测试将节约你的时间" class="headerlink" title="测试将节约你的时间"></a>测试将节约你的时间</h4><p>当某人写出错误的代码时，自动化测试还能帮助你定位错误代码的位置。</p></li><li><h4 id="测试不仅能发现错误，而且能预防错误"><a href="#测试不仅能发现错误，而且能预防错误" class="headerlink" title="测试不仅能发现错误，而且能预防错误"></a>测试不仅能发现错误，而且能预防错误</h4><p>测试就好像是从内部仔细检查你的代码，当有些地方出错时，这些地方将会变得很显眼——<em>就算你自己没有意识到那里写错了</em>。</p></li><li><h4 id="测试使你的代码更有吸引力"><a href="#测试使你的代码更有吸引力" class="headerlink" title="测试使你的代码更有吸引力"></a>测试使你的代码更有吸引力</h4><p>复杂的应用可能由团队维护。测试的存在保证了协作者不会不小心破坏了了你的代码（也保证你不会不小心弄坏他们的）。</p></li></ul><p><strong>unittest 和django.test   TestCase 类似</strong></p><h2 id="❓如何编写可重用程序"><a href="#❓如何编写可重用程序" class="headerlink" title="❓如何编写可重用程序"></a>❓如何编写可重用程序</h2><h3 id="☯可重用很重要"><a href="#☯可重用很重要" class="headerlink" title="☯可重用很重要"></a>☯可重用很重要</h3><p>可重用性是 Python 的根本。<span class="exturl" data-url="aHR0cHM6Ly9weXBpLnB5dGhvbi5vcmcvcHlwaQ==">The Python Package Index (PyPI)<i class="fa fa-external-link-alt"></i></span> 有许大量的包，都可被用在你自己的 Python 项目中。同样可以在 <span class="exturl" data-url="aHR0cHM6Ly9kamFuZ29wYWNrYWdlcy5vcmcv">Django Packages<i class="fa fa-external-link-alt"></i></span> 中查找已发布的可重用应用，也可将其引入到你的项目中。Django 本身也是一个 Python 包，也就是说你可以将已有的 Python 包或 Django 应用并入你的项目。你只需要编写属于你的那部分即可。</p><h3 id="🚀​你的项目和可复用应用¶"><a href="#🚀​你的项目和可复用应用¶" class="headerlink" title="🚀​你的项目和可复用应用¶"></a>🚀​你的项目和可复用应用<span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmRqYW5nb3Byb2plY3QuY29tL3poLWhhbnMvMy4wL2ludHJvL3JldXNhYmxlLWFwcHMvI3lvdXItcHJvamVjdC1hbmQteW91ci1yZXVzYWJsZS1hcHA=">¶<i class="fa fa-external-link-alt"></i></span></h3><p>通过前面的教程，我们的工程应该看起来像这样:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">mysite&#x2F;</span><br><span class="line">    manage.py</span><br><span class="line">    mysite&#x2F;</span><br><span class="line">        __init__.py</span><br><span class="line">        settings.py</span><br><span class="line">        urls.py</span><br><span class="line">        asgi.py</span><br><span class="line">        wsgi.py</span><br><span class="line">    polls&#x2F;</span><br><span class="line">        __init__.py</span><br><span class="line">        admin.py</span><br><span class="line">        apps.py</span><br><span class="line">        migrations&#x2F;</span><br><span class="line">            __init__.py</span><br><span class="line">            0001_initial.py</span><br><span class="line">        models.py</span><br><span class="line">        static&#x2F;</span><br><span class="line">            polls&#x2F;</span><br><span class="line">                images&#x2F;</span><br><span class="line">                    background.gif</span><br><span class="line">                style.css</span><br><span class="line">        templates&#x2F;</span><br><span class="line">            polls&#x2F;</span><br><span class="line">                detail.html</span><br><span class="line">                index.html</span><br><span class="line">                results.html</span><br><span class="line">        tests.py</span><br><span class="line">        urls.py</span><br><span class="line">        views.py</span><br><span class="line">    templates&#x2F;</span><br><span class="line">        admin&#x2F;</span><br><span class="line">            base_site.html</span><br></pre></td></tr></table></figure><p>目录 <code>polls</code> 现在可以被拷贝至一个新的 Django 工程，且立刻被复用。不过现在还不是发布它的时候。为了这样做，我们需要打包这个应用，便于其他人安装它。</p><h3 id="💯打包你的应用"><a href="#💯打包你的应用" class="headerlink" title="💯打包你的应用"></a>💯打包你的应用</h3><p>目前，打包 Python 程序需要工具，有许多工具可以完成此项工作。在此教程中，我们将使用 <span class="exturl" data-url="aHR0cHM6Ly9weXBpLm9yZy9wcm9qZWN0L3NldHVwdG9vbHMv">setuptools<i class="fa fa-external-link-alt"></i></span> 来打包我们的程序。</p><p><strong><code>具体</code><span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmRqYW5nb3Byb2plY3QuY29tL3poLWhhbnMvMy4wL2ludHJvL3JldXNhYmxlLWFwcHMv">参考链接<i class="fa fa-external-link-alt"></i></span></strong></p>]]></content>
    
    <summary type="html">
    
      利用python和django搭建web应用
    
    </summary>
    
    
      <category term="Web应用" scheme="https://Hubery-Lee.github.io/categories/Web%E5%BA%94%E7%94%A8/"/>
    
    
      <category term="web" scheme="https://Hubery-Lee.github.io/tags/web/"/>
    
      <category term="django" scheme="https://Hubery-Lee.github.io/tags/django/"/>
    
      <category term="数据库sqlite" scheme="https://Hubery-Lee.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93sqlite/"/>
    
  </entry>
  
  <entry>
    <title>数据拟合</title>
    <link href="https://hubery-lee.github.io/2020/06/07/%E6%95%B0%E6%8D%AE%E6%8B%9F%E5%90%88/"/>
    <id>https://hubery-lee.github.io/2020/06/07/%E6%95%B0%E6%8D%AE%E6%8B%9F%E5%90%88/</id>
    <published>2020-06-06T16:34:13.000Z</published>
    <updated>2020-06-06T16:39:49.904Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据拟合"><a href="#数据拟合" class="headerlink" title="数据拟合"></a>数据拟合</h1><p>[toc]</p><h2 id="1-问题描述"><a href="#1-问题描述" class="headerlink" title="1.问题描述"></a>1.问题描述</h2><p>手里有三组数据，用来分析探测器散射体材料厚度与探测器效率之间的关系。需要对三组数据进行画散点图，并进行拟合。拟合函数采用如下形式<br>$$<br>\eta = 1- exp(-\mu x)<br>$$<br>准备采用三种方法进行数据拟合，数据分析软件root、matlab和python.</p><h2 id="2-三种数据分析软件的数据拟合实现"><a href="#2-三种数据分析软件的数据拟合实现" class="headerlink" title="2.三种数据分析软件的数据拟合实现"></a>2.三种数据分析软件的数据拟合实现</h2><h3 id="2-1-matlab的数据拟合实现"><a href="#2-1-matlab的数据拟合实现" class="headerlink" title="2.1 matlab的数据拟合实现"></a>2.1 matlab的数据拟合实现</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% 读入数据x,y</span></span><br><span class="line">x=<span class="number">5</span>:<span class="number">5</span>:<span class="number">100</span>;</span><br><span class="line">y1=textread(&#x27;dataout1.txt&#x27;); //textread读入数据</span><br><span class="line">y2=textread(<span class="string">&#x27;dataout2.txt&#x27;</span>);</span><br><span class="line">y3=textread(<span class="string">&#x27;dataout3.txt&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">%% 自定义函数形式数据拟合</span></span><br><span class="line">myfittype = fittype(<span class="string">&#x27;1. - exp(a*x)&#x27;</span>,...</span><br><span class="line">    <span class="string">&#x27;dependent&#x27;</span>,&#123;<span class="string">&#x27;y&#x27;</span>&#125;,<span class="string">&#x27;independent&#x27;</span>,&#123;<span class="string">&#x27;x&#x27;</span>&#125;,...</span><br><span class="line">    <span class="string">&#x27;coefficients&#x27;</span>,&#123;<span class="string">&#x27;a&#x27;</span>&#125;);</span><br><span class="line"></span><br><span class="line">myfit1 = fit(x&#x27;,y1,myfittype);</span><br><span class="line"><span class="built_in">plot</span>(myfit1,<span class="string">&#x27;r-&#x27;</span>,x,y1,<span class="string">&#x27;r*&#x27;</span>);</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line">myfit2 = fit(x&#x27;,y2,myfittype);</span><br><span class="line"><span class="built_in">plot</span>(myfit2,<span class="string">&#x27;b-&#x27;</span>,x,y2,<span class="string">&#x27;bo&#x27;</span>);</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line">myfit3 = fit(x&#x27;,y3,myfittype);</span><br><span class="line"><span class="built_in">plot</span>(myfit3,<span class="string">&#x27;g-&#x27;</span>,x,y3,<span class="string">&#x27;gx&#x27;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/2020/06/07/%E6%95%B0%E6%8D%AE%E6%8B%9F%E5%90%88/fittedData.png" alt="fittedData"></p><h3 id="2-2-root中的数据拟合实现"><a href="#2-2-root中的数据拟合实现" class="headerlink" title="2.2 root中的数据拟合实现"></a>2.2 root中的数据拟合实现</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//参考 root tutorial/graphs/zdemo.C  /fit/FittingDemo.C</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;iostream&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;fstream&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;vector&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;cstring&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;string.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> NMAX=<span class="number">20</span>;</span><br><span class="line"><span class="keyword">double</span> xx[NMAX],yy[NMAX];</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReadData</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"> </span><br><span class="line">  ReadData(<span class="built_in">string</span> fname)</span><br><span class="line">  &#123;</span><br><span class="line">    filename=fname;</span><br><span class="line">  &#125;;</span><br><span class="line">  ~ReadData()&#123;&#125;;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">GetData</span><span class="params">()</span></span>;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="built_in">string</span> filename;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ReadData::GetData</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="function">ifstream <span class="title">input</span><span class="params">(filename)</span></span>;</span><br><span class="line">  <span class="keyword">double</span> a,b;</span><br><span class="line">  <span class="built_in">vector</span>&lt;<span class="keyword">double</span>&gt; x,y;</span><br><span class="line">  <span class="keyword">int</span> i=<span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span>(!input.eof())</span><br><span class="line">    &#123;</span><br><span class="line">      i++;</span><br><span class="line">      a=i*<span class="number">5</span>;</span><br><span class="line">      input&gt;&gt;b;</span><br><span class="line">      x.push_back(a);</span><br><span class="line">      y.push_back(<span class="number">1.0</span>-(b/<span class="number">1.e6</span>));</span><br><span class="line">    &#125;</span><br><span class="line">  input.close();</span><br><span class="line">  i=i<span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;i&amp;&amp;j&lt;NMAX;j++)</span><br><span class="line">    &#123;</span><br><span class="line">      xx[j]=x[j],yy[j]=y[j];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">plot</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">ReadData <span class="title">a1</span><span class="params">(<span class="string">&quot;./EJ200-100/data.txt&quot;</span>)</span></span>;</span><br><span class="line">  a1.GetData();</span><br><span class="line"></span><br><span class="line">  TGraph *g1 =<span class="keyword">new</span> TGraph(NMAX,xx,yy);</span><br><span class="line">  g1-&gt;SetLineColor(<span class="number">38</span>);</span><br><span class="line">  g1-&gt;SetMarkerColor(kBlue);</span><br><span class="line">  g1-&gt;SetMarkerStyle(<span class="number">21</span>);</span><br><span class="line">  g1-&gt;SetMarkerSize(<span class="number">1.1</span>);</span><br><span class="line">  g1-&gt;Draw(<span class="string">&quot;AP&quot;</span>);</span><br><span class="line">  </span><br><span class="line">  <span class="function">ReadData <span class="title">a2</span><span class="params">(<span class="string">&quot;./EJ200-140/data.txt&quot;</span>)</span></span>;</span><br><span class="line">  a2.GetData();</span><br><span class="line"></span><br><span class="line">  TGraph *gr2 = <span class="keyword">new</span> TGraph(NMAX,xx,yy);</span><br><span class="line">  gr2-&gt;SetLineColor(<span class="number">38</span>);</span><br><span class="line">  gr2-&gt;SetMarkerColor(kRed);</span><br><span class="line">  gr2-&gt;SetMarkerStyle(<span class="number">29</span>);</span><br><span class="line">  gr2-&gt;SetMarkerSize(<span class="number">1.5</span>);</span><br><span class="line">  gr2-&gt;Draw(<span class="string">&quot;P&quot;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="function">ReadData <span class="title">a3</span><span class="params">(<span class="string">&quot;./EJ200-180/data.txt&quot;</span>)</span></span>;</span><br><span class="line">  a3.GetData();</span><br><span class="line"></span><br><span class="line">  TGraph *gr3 = <span class="keyword">new</span> TGraph(NMAX,xx,yy);</span><br><span class="line"></span><br><span class="line">  gr3-&gt;SetLineColor(<span class="number">38</span>);</span><br><span class="line">  gr3-&gt;SetMarkerColor(<span class="number">6</span>);</span><br><span class="line">  gr3-&gt;SetMarkerStyle(<span class="number">8</span>);</span><br><span class="line">  gr3-&gt;SetMarkerSize(<span class="number">1.1</span>);</span><br><span class="line">  gr3-&gt;Draw(<span class="string">&quot;P&quot;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//////////////////</span></span><br><span class="line">  <span class="comment">////</span></span><br><span class="line">  <span class="comment">//      elta = 1-exp(a*x) //拟合函数形式</span></span><br><span class="line"></span><br><span class="line">  TF1 *fun =<span class="keyword">new</span> TF1(<span class="string">&quot;#elta = 1-exp(A*x)&quot;</span>,<span class="string">&quot;1.-exp([0]*x)&quot;</span>,<span class="number">0</span>,<span class="number">100</span>);</span><br><span class="line">  fun-&gt;SetLineColor(kBlue);fun-&gt;SetLineStyle(<span class="number">2</span>);</span><br><span class="line">  g1-&gt;Fit(fun);</span><br><span class="line"></span><br><span class="line">  fun-&gt;SetLineColor(kRed);fun-&gt;SetLineStyle(<span class="number">2</span>);</span><br><span class="line">  gr2-&gt;Fit(fun);</span><br><span class="line"></span><br><span class="line">  fun-&gt;SetLineColor(<span class="number">6</span>);fun-&gt;SetLineStyle(<span class="number">2</span>);</span><br><span class="line">  gr3-&gt;Fit(fun);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//////////////////</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">//  legend</span></span><br><span class="line">  TLegend *lg=<span class="keyword">new</span> TLegend(<span class="number">0.6</span>,<span class="number">0.65</span>,<span class="number">0.88</span>,<span class="number">0.85</span>);</span><br><span class="line">  lg-&gt;SetTextFont(<span class="number">62</span>);</span><br><span class="line">  lg-&gt;SetTextAlign(<span class="number">12</span>);</span><br><span class="line">  lg-&gt;SetTextSize(<span class="number">0.04</span>);</span><br><span class="line">  lg-&gt;AddEntry(g1,<span class="string">&quot;100keV&quot;</span>,<span class="string">&quot;p&quot;</span>);</span><br><span class="line">  lg-&gt;AddEntry(gr2,<span class="string">&quot;140keV&quot;</span>,<span class="string">&quot;p&quot;</span>);</span><br><span class="line">  lg-&gt;AddEntry(gr3,<span class="string">&quot;180keV&quot;</span>,<span class="string">&quot;p&quot;</span>);</span><br><span class="line">  lg-&gt;AddEntry(fun,<span class="string">&quot; #eta = 1-exp(#mu *x)&quot;</span>,<span class="string">&quot;l&quot;</span>);</span><br><span class="line">  lg-&gt;Draw();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/2020/06/07/%E6%95%B0%E6%8D%AE%E6%8B%9F%E5%90%88/c1.png" alt="c1"></p><h3 id="2-3-python中的数据拟合实现"><a href="#2-3-python中的数据拟合实现" class="headerlink" title="2.3 python中的数据拟合实现"></a>2.3 python中的数据拟合实现</h3><p>python 中做数据分析常用的几个包<code>matplotlib,numpy,scipy,pandas</code></p><ul><li>scipy中的curve_fit函数</li><li>lmfit中的fit函数</li></ul><p>下面从这两种包来拟合这两组数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time    : 2020/6/6 17:52</span></span><br><span class="line"><span class="comment"># @Author  : Hubery-Lee  </span></span><br><span class="line"><span class="comment"># @Email   : hrbeulh@126.com</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##   case 1: curve_fit</span></span><br><span class="line"><span class="comment">##   case 2: lmfit</span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"><span class="comment"># Header</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> curve_fit</span><br><span class="line"><span class="keyword">from</span> lmfit <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span>(<span class="params">x, a</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.</span> - np.exp(a * x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Read data from text</span></span><br><span class="line">x = np.linspace(<span class="number">5</span>, <span class="number">100</span>, <span class="number">20</span>)</span><br><span class="line">y1 = np.loadtxt(<span class="string">&#x27;dataout1.txt&#x27;</span>)</span><br><span class="line">y2 = np.loadtxt(<span class="string">&#x27;dataout2.txt&#x27;</span>)</span><br><span class="line">y3 = np.loadtxt(<span class="string">&#x27;dataout3.txt&#x27;</span>)</span><br><span class="line"><span class="comment">#  plot data</span></span><br><span class="line">plt.plot(x, y1, <span class="string">&#x27;bo&#x27;</span>, label=<span class="string">&#x27;100 keV&#x27;</span>)</span><br><span class="line">plt.plot(x, y2, <span class="string">&#x27;r*&#x27;</span>, label=<span class="string">&#x27;140 keV&#x27;</span>)</span><br><span class="line">plt.plot(x, y3, <span class="string">&#x27;gx&#x27;</span>, label=<span class="string">&#x27;180 keV&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## case 1:</span></span><br><span class="line"><span class="comment">## https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html</span></span><br><span class="line"><span class="comment"># Fit for the parameters a of the function func:</span></span><br><span class="line">popt1, pcov1 = curve_fit(func, x, y1)</span><br><span class="line"><span class="comment"># popt  # output: array([ 2.55423706, 1.35190947, 0.47450618])</span></span><br><span class="line">plt.plot(x, func(x, *popt1), <span class="string">&#x27;b-&#x27;</span>,</span><br><span class="line">         label=<span class="string">&#x27;100 keV fit: a=%5.3f&#x27;</span> % <span class="built_in">tuple</span>(popt1))</span><br><span class="line"></span><br><span class="line">popt2, pcov2 = curve_fit(func, x, y2)</span><br><span class="line"><span class="comment"># popt  # output: array([ 2.55423706, 1.35190947, 0.47450618])</span></span><br><span class="line">plt.plot(x, func(x, *popt2), <span class="string">&#x27;r-&#x27;</span>,</span><br><span class="line">         label=<span class="string">&#x27;140 keV fit: a=%5.3f&#x27;</span> % <span class="built_in">tuple</span>(popt2))</span><br><span class="line"></span><br><span class="line">popt3, pcov3 = curve_fit(func, x, y3)</span><br><span class="line"><span class="comment"># popt  # output: array([ 2.55423706, 1.35190947, 0.47450618])</span></span><br><span class="line">plt.plot(x, func(x, *popt3), <span class="string">&#x27;g-&#x27;</span>,</span><br><span class="line">         label=<span class="string">&#x27;180 keV fit: a=%5.3f&#x27;</span> % <span class="built_in">tuple</span>(popt3))</span><br><span class="line"></span><br><span class="line"><span class="comment"># # In the case of parameters a need be constrainted</span></span><br><span class="line"><span class="comment"># # Constrain the optimization to the region of</span></span><br><span class="line"><span class="comment"># # 0 &lt;= a &lt;= 3, 0 &lt;= b &lt;= 1 and 0 &lt;= c &lt;= 0.5</span></span><br><span class="line"><span class="comment"># popt, pcov = curve_fit(func, xdata, ydata, bounds=(0, [3., 1., 0.5]))</span></span><br><span class="line"><span class="comment"># popt  # output: array([ 2.43708906, 1. , 0.35015434])</span></span><br><span class="line"><span class="comment"># plt.plot(xdata, func(xdata, *popt), &#x27;g--&#x27;,</span></span><br><span class="line"><span class="comment">#          label=&#x27;fit: a=%5.3f, b=%5.3f, c=%5.3f&#x27; % tuple(popt))</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## case 2:</span></span><br><span class="line"><span class="comment">## https://lmfit.github.io/lmfit-py/model.html</span></span><br><span class="line"><span class="comment"># Fitting</span></span><br><span class="line">gmodel = Model(func)</span><br><span class="line">result = gmodel.fit(y1, x=x, a=-<span class="number">0.02</span>)  <span class="comment"># Fit from initial values (5,5,1)</span></span><br><span class="line">print(result.fit_report())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot</span></span><br><span class="line"><span class="comment">#plt.plot(x, y1, &#x27;bo&#x27;, label=&#x27;raw data&#x27;)</span></span><br><span class="line"><span class="comment">#plt.plot(x, result.init_fit, &#x27;b--&#x27;, label=&#x27;init_fit&#x27;)</span></span><br><span class="line"><span class="comment">#plt.plot(x, result.best_fit, &#x27;k--&#x27;, label=&#x27;best_fit&#x27;)</span></span><br><span class="line">plt.plot(x, result.best_fit, <span class="string">&#x27;k--&#x27;</span>, label=<span class="string">&#x27;100 keV lmfit&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># draw option</span></span><br><span class="line"><span class="comment"># Labels</span></span><br><span class="line">plt.title(<span class="string">r&#x27;Fitting Function $\eta = 1.0-exp(a*x)$&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x/mm&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">r&#x27;$\eta$&#x27;</span>)  <span class="comment"># 公式的添加 latex风格 https://matplotlib.org/tutorials/text/mathtext.html</span></span><br><span class="line">plt.legend()</span><br><span class="line">leg = plt.legend()  <span class="comment"># remove the frame of Legend, personal choice</span></span><br><span class="line">leg.get_frame().set_linewidth(<span class="number">0.0</span>)  <span class="comment"># remove the frame of Legend, personal choice</span></span><br><span class="line"><span class="comment"># leg.get_frame().set_edgecolor(&#x27;b&#x27;)  # change the color of Legend frame</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Export figurey</span></span><br><span class="line"><span class="comment"># plt.savefig(&#x27;fit1.eps&#x27;, format=&#x27;eps&#x27;, dpi=1000)</span></span><br><span class="line"><span class="comment"># plt.savefig(&#x27;fit1.pdf&#x27;, format=&#x27;pdf&#x27;, dpi=1000, figsize=(8, 6), facecolor=&#x27;w&#x27;, edgecolor=&#x27;k&#x27;)</span></span><br><span class="line">plt.savefig(<span class="string">&#x27;myfit.jpg&#x27;</span>, <span class="built_in">format</span>=<span class="string">&#x27;jpg&#x27;</span>, dpi=<span class="number">1000</span>, figsize=(<span class="number">8</span>, <span class="number">6</span>), facecolor=<span class="string">&#x27;w&#x27;</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="/2020/06/07/%E6%95%B0%E6%8D%AE%E6%8B%9F%E5%90%88/myfit.jpg" alt="myfit"></p>]]></content>
    
    <summary type="html">
    
      介绍matlab,root,python如何使用进行自定义函数进行数据拟合
    
    </summary>
    
    
      <category term="数据拟合" scheme="https://Hubery-Lee.github.io/categories/%E6%95%B0%E6%8D%AE%E6%8B%9F%E5%90%88/"/>
    
    
      <category term="root" scheme="https://Hubery-Lee.github.io/tags/root/"/>
    
      <category term="matlab" scheme="https://Hubery-Lee.github.io/tags/matlab/"/>
    
      <category term="python" scheme="https://Hubery-Lee.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Geant4中如何添加复杂组件</title>
    <link href="https://hubery-lee.github.io/2020/06/05/Geant4%E4%B8%AD%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0%E5%A4%8D%E6%9D%82%E7%BB%84%E4%BB%B6/"/>
    <id>https://hubery-lee.github.io/2020/06/05/Geant4%E4%B8%AD%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0%E5%A4%8D%E6%9D%82%E7%BB%84%E4%BB%B6/</id>
    <published>2020-06-05T00:12:15.000Z</published>
    <updated>2020-06-07T14:38:01.130Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Geant4中如何添加复杂组件"><a href="#Geant4中如何添加复杂组件" class="headerlink" title="Geant4中如何添加复杂组件"></a>Geant4中如何添加复杂组件</h1><h2 id="1-bool-运算"><a href="#1-bool-运算" class="headerlink" title="1. bool 运算"></a>1. bool 运算</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;G4SubtractionSolid.hh&quot;</span></span></span><br><span class="line"></span><br><span class="line"> G4SubtractionSolid*Tsubtraction = <span class="keyword">new</span> G4SubtractionSolid(<span class="string">&quot;PipeWall-Strips&quot;</span>,solidPWall,solidStrips,rotz0,G4ThreeVector());</span><br></pre></td></tr></table></figure><p>用例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//=====================================</span></span><br><span class="line"> <span class="comment">// 圆柱形准直器</span></span><br><span class="line"> <span class="comment">//</span></span><br><span class="line"> <span class="keyword">double</span> I_R1=<span class="number">90.0</span>*mm;<span class="comment">//,I_R2=100.0*mm;</span></span><br><span class="line"> <span class="comment">//double O_R1=97.1*mm,O_R2=107.1*mm;</span></span><br><span class="line"> <span class="keyword">double</span> O_R1=<span class="number">140.0</span>*mm;<span class="comment">//,O_R2=135.4*mm;</span></span><br><span class="line"> <span class="keyword">double</span> C_z =<span class="number">150.0</span>*mm;</span><br><span class="line"></span><br><span class="line"> pSPhi= <span class="number">0.</span>*degree;</span><br><span class="line"> pDPhi= <span class="number">360.</span>*degree;</span><br><span class="line"></span><br><span class="line"> G4Tubs* solidCol =   </span><br><span class="line">   <span class="keyword">new</span> G4Tubs(<span class="string">&quot;Collimator&quot;</span>,     I_R1, O_R1,C_z,pSPhi,pDPhi);     <span class="comment">//its size</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="comment">//====================================</span></span><br><span class="line"> <span class="comment">// void in collimator</span></span><br><span class="line"> pSPhi = <span class="number">0.</span>;</span><br><span class="line"> pDPhi = <span class="number">2.0</span>*pi/(<span class="number">90.0</span>*pi);</span><br><span class="line"></span><br><span class="line"> G4Tubs* solidVoidC = <span class="keyword">new</span> G4Tubs(<span class="string">&quot;VCollimator&quot;</span>,I_R1<span class="number">-0.1</span>*mm, O_R1+<span class="number">0.1</span>*mm,C_z+<span class="number">0.1</span>*mm,pSPhi,pDPhi);</span><br><span class="line"></span><br><span class="line"> <span class="comment">// G4SubtractionSolid* subtraction[94];</span></span><br><span class="line"> G4SubtractionSolid* subtraction[<span class="number">141</span>];</span><br><span class="line"></span><br><span class="line"> <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=<span class="number">141</span>;i++)&#123;</span><br><span class="line">   G4RotationMatrix* rotz= <span class="keyword">new</span> G4RotationMatrix;</span><br><span class="line">   rotz-&gt;rotateZ(<span class="number">-2</span>*i*<span class="number">2.0</span>*pi/(<span class="number">90.0</span>*pi));</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span>(i==<span class="number">1</span>)</span><br><span class="line">     subtraction[<span class="number">0</span>]=</span><br><span class="line"> <span class="keyword">new</span> G4SubtractionSolid(<span class="string">&quot;Collimator-Void&quot;</span>, solidCol, solidVoidC,rotz,G4ThreeVector(<span class="number">0.0</span>*mm,<span class="number">0.0</span>*mm,<span class="number">10.0</span>*mm));</span><br><span class="line">   <span class="keyword">else</span></span><br><span class="line">     subtraction[i<span class="number">-1</span>]=</span><br><span class="line"> <span class="keyword">new</span> G4SubtractionSolid(<span class="string">&quot;Collimator-Void&quot;</span>, subtraction[i<span class="number">-2</span>], solidVoidC,rotz,G4ThreeVector(<span class="number">0.0</span>*mm,<span class="number">0.0</span>*mm,<span class="number">10.0</span>*mm));</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> G4LogicalVolume* logicCol =                         </span><br><span class="line">   <span class="keyword">new</span> G4LogicalVolume(subtraction[<span class="number">140</span>],          <span class="comment">//its solid</span></span><br><span class="line">                       col_mat,           <span class="comment">//its material</span></span><br><span class="line">                       <span class="string">&quot;Collimator&quot;</span>);            <span class="comment">//its name</span></span><br><span class="line"></span><br><span class="line"> G4PVPlacement* physCol = </span><br><span class="line">   <span class="keyword">new</span> G4PVPlacement(<span class="number">0</span>,                     <span class="comment">//no rotation</span></span><br><span class="line">                     G4ThreeVector(<span class="number">0.</span>*mm,<span class="number">0.</span>*mm,<span class="number">160.0</span>*mm),<span class="comment">//65.0*mm),       //at (0,0,0)</span></span><br><span class="line">                     logicCol,              <span class="comment">//its logical volume</span></span><br><span class="line">                     <span class="string">&quot;Collimator&quot;</span>,                 <span class="comment">//its name</span></span><br><span class="line">                     logicWorld,            <span class="comment">//its mother  volume</span></span><br><span class="line">                     <span class="literal">false</span>,                 <span class="comment">//no boolean operation</span></span><br><span class="line">                     <span class="number">0</span>,                     <span class="comment">//copy number</span></span><br><span class="line">                     checkOverlaps);        <span class="comment">//overlaps checking</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>建出来的结果：圆柱形准直器</p><p><img src="/2020/06/05/Geant4%E4%B8%AD%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0%E5%A4%8D%E6%9D%82%E7%BB%84%E4%BB%B6/11-37-25.png" alt></p><h2 id="2-Assemble组件"><a href="#2-Assemble组件" class="headerlink" title="2. Assemble组件"></a>2. Assemble组件</h2><p>闪烁体pixel阵列构建代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">//*************************************************     </span></span><br><span class="line"> <span class="comment">// AssembleNBD World</span></span><br><span class="line"> <span class="comment">//*************************************************</span></span><br><span class="line"> G4double sizeXY = <span class="number">100.77</span>*mm+<span class="number">2.</span>*mm;</span><br><span class="line"> G4double sizeZ  = <span class="number">100.14</span>*mm;</span><br><span class="line"></span><br><span class="line"> G4Box* solidAssembleNBD =   </span><br><span class="line">   <span class="keyword">new</span> G4Box(<span class="string">&quot;AssembleNBD&quot;</span>,     <span class="number">0.5</span>*sizeXY, <span class="number">0.5</span>*sizeXY, <span class="number">0.5</span>*sizeZ);     <span class="comment">//its size</span></span><br><span class="line"> </span><br><span class="line"> logicAssembleNBD =                         </span><br><span class="line">   <span class="keyword">new</span> G4LogicalVolume(solidAssembleNBD,          <span class="comment">//its solid</span></span><br><span class="line">                       world_mat,           <span class="comment">//its material</span></span><br><span class="line">                       <span class="string">&quot;AssembleNBD&quot;</span>);            <span class="comment">//its name</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="comment">//***************</span></span><br><span class="line"> <span class="comment">//test for one NBD</span></span><br><span class="line"></span><br><span class="line"> physAssembleNBD = </span><br><span class="line">   <span class="keyword">new</span> G4PVPlacement(<span class="number">0</span>,                     <span class="comment">//no rotation</span></span><br><span class="line">                     G4ThreeVector(<span class="number">0.0</span>*cm,<span class="number">0.0</span>*cm,<span class="number">-85.007</span>*cm),       <span class="comment">//at (0,0,0)</span></span><br><span class="line">                     logicAssembleNBD,      <span class="comment">//its logical volume</span></span><br><span class="line">                     <span class="string">&quot;physAssembleNBD&quot;</span>,         <span class="comment">//its name</span></span><br><span class="line">                     expHall_logV,          <span class="comment">//its mother  volume</span></span><br><span class="line">                     <span class="literal">false</span>,                 <span class="comment">//no boolean operation</span></span><br><span class="line">                     <span class="number">0</span>,                     <span class="comment">//copy number</span></span><br><span class="line">       checkOverlaps);        <span class="comment">//overlaps checking</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">//*************************************************</span></span><br><span class="line"> <span class="comment">// EJ200 scintillator</span></span><br><span class="line"> <span class="comment">//*************************************************</span></span><br><span class="line"> <span class="comment">//</span></span><br><span class="line"> <span class="comment">//      ------------- Volumes --------------</span></span><br><span class="line"> <span class="comment">//  10X10X50 mm3 EJ-200/BC408</span></span><br><span class="line"> <span class="comment">//  spacing is 65 um between two EJ-200 with reflector</span></span><br><span class="line"> <span class="comment">//  </span></span><br><span class="line"></span><br><span class="line"> <span class="comment">//  </span></span><br><span class="line"> <span class="comment">// EJ200 reflector box</span></span><br><span class="line"> <span class="comment">//----------------------------------</span></span><br><span class="line"> <span class="comment">// 100.770X100.770X50.070 mm3</span></span><br><span class="line"> <span class="comment">// 10X10+0.07*11; 50 + 0.07</span></span><br><span class="line"></span><br><span class="line"> G4double ej200_x=<span class="number">10</span>*mm, ej200_y=<span class="number">10</span>*mm, ej200_z=<span class="number">50</span>*mm; <span class="comment">//full size of ej200</span></span><br><span class="line"> G4double rowNb_ej200=<span class="number">10</span>, colNb_ej200=<span class="number">10</span>; <span class="comment">// 10X10 ej200</span></span><br><span class="line"> G4double gap=<span class="number">0.070</span>*mm; <span class="comment">// gap between two ej200</span></span><br><span class="line"></span><br><span class="line"> G4double EJ200_Box_x = ej200_x*rowNb_ej200/<span class="number">2</span>+gap*(rowNb_ej200+<span class="number">1</span>)/<span class="number">2</span>;</span><br><span class="line"> G4double EJ200_Box_y = ej200_y*colNb_ej200/<span class="number">2</span>+gap*(colNb_ej200+<span class="number">1</span>)/<span class="number">2</span>;</span><br><span class="line"> G4double EJ200_Box_z = (ej200_z+gap)/<span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"> <span class="comment">//  mother volume of 10 X 10  EJ200  </span></span><br><span class="line"> G4double Assemble_x = EJ200_Box_x; </span><br><span class="line"> G4double Assemble_y = EJ200_Box_y;</span><br><span class="line"> G4double Assemble_z = EJ200_Box_z;</span><br><span class="line"></span><br><span class="line"> G4Box* Assemble_solidV = <span class="keyword">new</span> G4Box(<span class="string">&quot;Assemble_solidV&quot;</span>, </span><br><span class="line"> Assemble_x, Assemble_y, Assemble_z);</span><br><span class="line"> Assemble_logV  = <span class="keyword">new</span> G4LogicalVolume(Assemble_solidV, ESR, <span class="string">&quot;Assemble_logV&quot;</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">G4double Assemble_px = <span class="number">0</span>;  <span class="comment">// put it at (0,0, EJ200_Box_z)</span></span><br><span class="line"> G4double Assemble_py = <span class="number">0</span>;</span><br><span class="line"> G4double Assemble_pz = EJ200_Box_z;  </span><br><span class="line"> Assemble_physV = <span class="keyword">new</span> G4PVPlacement(<span class="number">0</span>,</span><br><span class="line">                            G4ThreeVector(Assemble_px, Assemble_py, Assemble_pz),</span><br><span class="line">                            Assemble_logV,</span><br><span class="line">                            <span class="string">&quot;Assemble_physV&quot;</span>,</span><br><span class="line">                            logicAssembleNBD,</span><br><span class="line">                            <span class="literal">false</span>,</span><br><span class="line">                            <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"> <span class="comment">//</span></span><br><span class="line"> <span class="comment">// each EJ-200</span></span><br><span class="line"> <span class="comment">//-------------------------------</span></span><br><span class="line"></span><br><span class="line"> G4double EJ200_x = ej200_x/<span class="number">2</span>;  <span class="comment">// half size</span></span><br><span class="line"> G4double EJ200_y = ej200_y/<span class="number">2</span>;</span><br><span class="line"> G4double EJ200_z = ej200_z/<span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"> G4Box* EJ200_solidV = <span class="keyword">new</span> G4Box(<span class="string">&quot;EJ200_solidV&quot;</span>, EJ200_x, EJ200_y, EJ200_z);</span><br><span class="line"> EJ200_logV = <span class="keyword">new</span> G4LogicalVolume(EJ200_solidV, EJ200, <span class="string">&quot;EJ200_logV&quot;</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="comment">// create Assembly of EJ200 array Box</span></span><br><span class="line"> <span class="comment">//</span></span><br><span class="line"> G4AssemblyVolume* assemblyEJ200 = <span class="keyword">new</span> G4AssemblyVolume();</span><br><span class="line"></span><br><span class="line"> <span class="comment">// Rotation and translation of the logical volume</span></span><br><span class="line"> G4RotationMatrix rotationMatrixEJ200; </span><br><span class="line"> <span class="function">G4ThreeVector <span class="title">positionEJ200</span><span class="params">(<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>)</span></span>;</span><br><span class="line"> G4Transform3D transform3DEJ200;</span><br><span class="line"></span><br><span class="line"> <span class="comment">// Fill the assembly by EJ200</span></span><br><span class="line"> <span class="comment">//</span></span><br><span class="line"> G4int max_x = rowNb_ej200; </span><br><span class="line"> G4int max_y = colNb_ej200;</span><br><span class="line"> <span class="keyword">for</span>(G4int x_row_num = <span class="number">0</span>; x_row_num &lt; max_x; x_row_num++ )&#123;</span><br><span class="line">   <span class="keyword">for</span>(G4int y_col_num = <span class="number">0</span>; y_col_num &lt; max_y; y_col_num++ )&#123;  </span><br><span class="line">     positionEJ200.setX( -EJ200_Box_x + (x_row_num+<span class="number">1</span>)*gap + (<span class="number">2</span>*x_row_num+<span class="number">1</span>)*EJ200_x );</span><br><span class="line">     positionEJ200.setY( -EJ200_Box_y + (y_col_num+<span class="number">1</span>)*gap + (<span class="number">2</span>*y_col_num+<span class="number">1</span>)*EJ200_y );</span><br><span class="line">     positionEJ200.setZ( <span class="number">0.0</span>*mm );</span><br><span class="line">     transform3DEJ200 = G4Transform3D(rotationMatrixEJ200, positionEJ200);</span><br><span class="line">     assemblyEJ200-&gt;AddPlacedVolume(EJ200_logV, transform3DEJ200);</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;  </span><br><span class="line"></span><br><span class="line"> <span class="comment">// Place the Assembly</span></span><br><span class="line"> <span class="comment">//</span></span><br><span class="line"> positionEJ200.setX(<span class="number">0.0</span> ); positionEJ200.setY(<span class="number">0.0</span> ); positionEJ200.setZ(<span class="number">-0.5</span>*gap);</span><br><span class="line"> transform3DEJ200 = G4Transform3D(rotationMatrixEJ200, positionEJ200);</span><br><span class="line"> assemblyEJ200-&gt;MakeImprint(Assemble_logV, transform3DEJ200);</span><br></pre></td></tr></table></figure><p>闪烁体探测器芯块阵列：</p><p><img src="/2020/06/05/Geant4%E4%B8%AD%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0%E5%A4%8D%E6%9D%82%E7%BB%84%E4%BB%B6/15-21-17.png" alt></p><h2 id="3-Parameterised"><a href="#3-Parameterised" class="headerlink" title="3. Parameterised"></a>3. Parameterised</h2><p>光导构建代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;G4PVParameterised.hh&quot;</span> <span class="comment">//得包含G4PVParameterised头文件</span></span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Light Guide top mother volume</span></span><br><span class="line">  <span class="comment">//-------------------------------------</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// The defination of light guide</span></span><br><span class="line">  <span class="comment">// define mother volume of light guide</span></span><br><span class="line">  <span class="comment">// half size of volume</span></span><br><span class="line">  G4double LightGuide_x = ej200_x*rowNb_ej200/<span class="number">2</span>+gap*(rowNb_ej200+<span class="number">1</span>)/<span class="number">2</span>; </span><br><span class="line">  G4double LightGuide_y = ej200_y*colNb_ej200/<span class="number">2</span>+gap*(colNb_ej200+<span class="number">1</span>)/<span class="number">2</span>;</span><br><span class="line">  G4double LightGuide_z = <span class="number">3</span>*mm/<span class="number">2</span>;</span><br><span class="line">  gap = <span class="number">0.07</span>*mm; <span class="comment">// gap between the boxes which is used to put</span></span><br><span class="line">            <span class="comment">// the reflector </span></span><br><span class="line">  G4Box* LightGuide_top_motherV = <span class="keyword">new</span> G4Box(<span class="string">&quot;LightGuide_top_motherV&quot;</span>,</span><br><span class="line">                                LightGuide_x, LightGuide_y, LightGuide_z);</span><br><span class="line">  LightGuide_top_mother_logV = <span class="keyword">new</span> G4LogicalVolume(LightGuide_top_motherV,</span><br><span class="line">                                ESR, <span class="comment">// ESR reflector</span></span><br><span class="line">                                <span class="string">&quot;LightGuide_top_mother_logV&quot;</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">  LightGuide_top_mother_physV = <span class="keyword">new</span> G4PVPlacement(<span class="number">0</span>,</span><br><span class="line">        G4ThreeVector(<span class="number">0</span>, <span class="number">0</span>, (grease_pz-grease_z)-LightGuide_z),</span><br><span class="line">        LightGuide_top_mother_logV,</span><br><span class="line">        <span class="string">&quot;LightGuide_top_mother_physV&quot;</span>,</span><br><span class="line">        logicAssembleNBD,</span><br><span class="line">        <span class="literal">false</span>,</span><br><span class="line">        <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Light Guide top </span></span><br><span class="line">  <span class="comment">//-------------------------------------------</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// top part of light guide</span></span><br><span class="line">  <span class="comment">// it consists of 5X5 boxes with same height</span></span><br><span class="line">  <span class="comment">// TopX =&gt; x of each box in the top part, </span></span><br><span class="line">  <span class="comment">// TopY =&gt; y of each box in the top part,</span></span><br><span class="line">  <span class="comment">// TopHeight =&gt; height of each box, they are same.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// here, the value is the full size of box</span></span><br><span class="line">  G4double TopX[<span class="number">5</span>] = &#123;<span class="number">12.3</span>*mm, <span class="number">22.3</span>*mm, <span class="number">31.15</span>*mm, <span class="number">22.3</span>*mm, <span class="number">12.3</span>*mm&#125;;</span><br><span class="line">  G4double TopY[<span class="number">5</span>] = &#123;<span class="number">12.3</span>*mm, <span class="number">22.3</span>*mm, <span class="number">31.15</span>*mm, <span class="number">22.3</span>*mm, <span class="number">12.3</span>*mm&#125;;</span><br><span class="line">  G4double TopHeight = <span class="number">3.0</span>*mm;</span><br><span class="line"></span><br><span class="line">  G4int rowNb = <span class="number">5</span>;</span><br><span class="line">  G4int colNb = <span class="number">5</span>;</span><br><span class="line"></span><br><span class="line">  G4double TopGap = gap; <span class="comment">// ESR materials</span></span><br><span class="line">  G4double x0, y0; <span class="comment">// coordinate of the left bottom corner</span></span><br><span class="line">  x0 = -LightGuide_x;</span><br><span class="line">  y0 = -LightGuide_y;</span><br><span class="line">  <span class="comment">// left bottom conner of X-Y plane (-A, -A)</span></span><br><span class="line">  <span class="comment">// this box is a seed of other boxes</span></span><br><span class="line">  G4Box* LightGuide_top_solidV = <span class="keyword">new</span> G4Box(<span class="string">&quot;LightGuide_top_solidV&quot;</span>,</span><br><span class="line">           TopX[<span class="number">0</span>]/<span class="number">2</span>, TopY[<span class="number">0</span>]/<span class="number">2</span>, TopHeight/<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">  LightGuide_top_logV = <span class="keyword">new</span> G4LogicalVolume(LightGuide_top_solidV,</span><br><span class="line">                                        BC800, <span class="comment">// light guide material</span></span><br><span class="line">                                        <span class="string">&quot;LightGuide_top_logV&quot;</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// all the coordinates are relative to the coordinate system of LightGuide_mother_logV </span></span><br><span class="line">  G4double LightGuide_top_px = x0;</span><br><span class="line">  G4double LightGuide_top_py = y0;</span><br><span class="line">  G4double LightGuide_top_pz = <span class="number">0</span>*mm;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//G4VPVParameterisation </span></span><br><span class="line">  APNISLGParameterisation *lightGuide_para_top = </span><br><span class="line">  <span class="keyword">new</span> APNISLGParameterisation(</span><br><span class="line">  rowNb, colNb, <span class="comment">// number of row and column</span></span><br><span class="line">   TopX, TopY,</span><br><span class="line">  TopGap, TopHeight,</span><br><span class="line">  LightGuide_top_px, LightGuide_top_py, LightGuide_top_pz,</span><br><span class="line">  BC800, ESR);</span><br><span class="line"></span><br><span class="line">  LightGuide_top_physV = <span class="keyword">new</span> G4PVParameterised(<span class="string">&quot;LightGuide_top_physV&quot;</span>,</span><br><span class="line">  LightGuide_top_logV, LightGuide_top_mother_logV,</span><br><span class="line">  kUndefined, rowNb*colNb, lightGuide_para_top);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Light Guide bottom mother volume</span></span><br><span class="line">  <span class="comment">//-------------------------------------------</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Bottom part of light guide, half size</span></span><br><span class="line">  G4double LightGuide_z_ = <span class="number">18</span>*mm/<span class="number">2</span>;</span><br><span class="line">  G4Box* LightGuide_bottom_motherV = <span class="keyword">new</span> G4Box(<span class="string">&quot;LightGuide_bottom_motherV&quot;</span>,</span><br><span class="line">                                LightGuide_x, LightGuide_y, LightGuide_z_);</span><br><span class="line">  LightGuide_bottom_mother_logV = <span class="keyword">new</span> G4LogicalVolume(LightGuide_bottom_motherV,</span><br><span class="line">                                ESR, <span class="comment">// ESR reflector</span></span><br><span class="line">                                <span class="string">&quot;LightGuide_bottom_mother_logV&quot;</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">  LightGuide_bottom_mother_physV = <span class="keyword">new</span> G4PVPlacement(<span class="number">0</span>,</span><br><span class="line">        G4ThreeVector(<span class="number">0</span>, <span class="number">0</span>, (grease_pz-grease_z)-LightGuide_z*<span class="number">2</span>-LightGuide_z_),</span><br><span class="line">        LightGuide_bottom_mother_logV,</span><br><span class="line">        <span class="string">&quot;LightGuide_bottom_mother_physV&quot;</span>,</span><br><span class="line">        logicAssembleNBD,</span><br><span class="line">        <span class="literal">false</span>,</span><br><span class="line">        <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Light Guide bottom</span></span><br><span class="line">  <span class="comment">//---------------------------------------------</span></span><br><span class="line"></span><br><span class="line">  G4double BottomX[<span class="number">3</span>] = &#123;<span class="number">12.3</span>*mm, <span class="number">75.89</span>*mm, <span class="number">12.3</span>*mm&#125;;</span><br><span class="line">  G4double BottomY[<span class="number">3</span>] = &#123;<span class="number">12.3</span>*mm, <span class="number">75.89</span>*mm, <span class="number">12.3</span>*mm&#125;;</span><br><span class="line">  G4double BottomHeight = LightGuide_z_*<span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">  G4int rowNb_ = <span class="number">3</span>;</span><br><span class="line">  G4int colNb_ = <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line">  G4double BottomGap = gap; <span class="comment">// ESR materials</span></span><br><span class="line">  <span class="comment">// left bottom conner of X-Y plane (-A, -A)</span></span><br><span class="line">  <span class="comment">// this box is a seed of other boxes</span></span><br><span class="line">  G4Box* LightGuide_bottom_solidV = <span class="keyword">new</span> G4Box(<span class="string">&quot;LightGuide_bottom_solidV&quot;</span>,</span><br><span class="line">                        BottomX[<span class="number">0</span>]/<span class="number">2</span>, BottomY[<span class="number">0</span>]/<span class="number">2</span>, BottomHeight/<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">  LightGuide_bottom_logV = <span class="keyword">new</span> G4LogicalVolume(LightGuide_bottom_solidV,</span><br><span class="line">                                        BC800, <span class="comment">// light guide material</span></span><br><span class="line">                                        <span class="string">&quot;LightGuide_bottom_logV&quot;</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">// all the coordinates are relative to the coordinate system of LightGuide_mother_logV </span></span><br><span class="line">  G4double LightGuide_bottom_px = x0;</span><br><span class="line">  G4double LightGuide_bottom_py = y0;</span><br><span class="line">  G4double LightGuide_bottom_pz = <span class="number">0</span>*mm;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//G4VPVParameterisation </span></span><br><span class="line">  APNISLGParameterisation *lightGuide_para_bottom =</span><br><span class="line">                <span class="keyword">new</span> APNISLGParameterisation(</span><br><span class="line">                                rowNb_, colNb_, <span class="comment">// number of row and column</span></span><br><span class="line">                                BottomX, BottomY,</span><br><span class="line">                                BottomGap, BottomHeight,</span><br><span class="line">                                LightGuide_bottom_px, LightGuide_bottom_py, LightGuide_bottom_pz,</span><br><span class="line">                                BC800, ESR);</span><br><span class="line">  LightGuide_bottom_physV = <span class="keyword">new</span> G4PVParameterised(<span class="string">&quot;LightGuide_bottom_physV&quot;</span>,</span><br><span class="line">                                LightGuide_bottom_logV, LightGuide_bottom_mother_logV,</span><br><span class="line">                                kUndefined, rowNb_*colNb_, lightGuide_para_bottom);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>光导构建图：</p><p><img src="/2020/06/05/Geant4%E4%B8%AD%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0%E5%A4%8D%E6%9D%82%E7%BB%84%E4%BB%B6/15-00-25.png" alt></p>]]></content>
    
    <summary type="html">
    
      Geant4构建复杂组件，bool运算，assemble,parameterised
    
    </summary>
    
    
      <category term="Geant4" scheme="https://Hubery-Lee.github.io/categories/Geant4/"/>
    
    
      <category term="geant4" scheme="https://Hubery-Lee.github.io/tags/geant4/"/>
    
  </entry>
  
  <entry>
    <title>迭代重建算法的基本思想</title>
    <link href="https://hubery-lee.github.io/2020/06/05/%E8%BF%AD%E4%BB%A3%E9%87%8D%E5%BB%BA%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3/"/>
    <id>https://hubery-lee.github.io/2020/06/05/%E8%BF%AD%E4%BB%A3%E9%87%8D%E5%BB%BA%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3/</id>
    <published>2020-06-04T16:15:12.000Z</published>
    <updated>2020-06-09T08:35:36.095Z</updated>
    
    <content type="html"><![CDATA[<h1 id="迭代重建算法的基本思想"><a href="#迭代重建算法的基本思想" class="headerlink" title="迭代重建算法的基本思想"></a>迭代重建算法的基本思想</h1><h2 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h2><p>图像重建除了通过中心切片定理来实现外，还可以通过解线性方程组来得到。对于二维图像就是像素，对于三维图像就是体素。</p><p><img src="/2020/06/05/%E8%BF%AD%E4%BB%A3%E9%87%8D%E5%BB%BA%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3/image-20200604225353193.png" alt="image-20200604225353193"></p><p>$\left{\begin{array}{c}x_{1}+x_{2}+x_{3}=p_{1} \ x_{4}+x_{5}+x_{6}=p_{2} \ x_{7}+x_{8}+x_{9}=p_{3} \ x_{3}+x_{6}+x_{9}=p_{4} \ x_{2}+x_{5}+x_{8}=p_{5} \ x_{1}+x_{4}+x_{7}=p_{6} \ 2(\sqrt{2}-1) x_{4}+(2-\sqrt{2}) x_{7}+2(\sqrt{2}-1) x_{8}=p_{7} \ \sqrt{2} x_{1}+\sqrt{2} x_{5}+\sqrt{2} x_{9}=p_{8} \ 2(\sqrt{2}-1) x_{2}+(2-\sqrt{2}) x_{3}+2(\sqrt{2}-1) x_{6}=p_{9}\end{array}\right.$</p><p>这个方程组也可以用矩阵的形式写出<br>$$<br>AX=p<br>$$<br>其中，$X=\left[x_{1}, x_{2}, \ldots, x_{9}\right]^{T}, \quad P=\left[p_{1}, p_{2}, \ldots, p_{9}\right]^{T}$迭代算法的思想使将$AX=p$变换成，迭代形式<br>$$<br>X^{(i+1)}=GX^{(i)}+b<br>$$<br>通过不同的变换方式变成迭代格式，就长生了不同的的迭代算法。比如：</p><h2 id="常用迭代算法"><a href="#常用迭代算法" class="headerlink" title="常用迭代算法"></a>常用迭代算法</h2><h3 id="代数迭代重建技术（ARO，algebraic-reconstruction-technique"><a href="#代数迭代重建技术（ARO，algebraic-reconstruction-technique" class="headerlink" title="代数迭代重建技术（ARO，algebraic reconstruction technique)"></a>代数迭代重建技术（ARO，algebraic reconstruction technique)</h3><p>ART 算法是个“行运算”算法。它每次考虑一条射线就更新一次图像。ART 算法的表达式是 </p><p>$$<br>X^{下一个}=X^{\text {当前}}-\frac{A_{i} X^{\text {当前}}-p_{i}}{\left|A_{i}\right|^{2}} A_{i}^{T}<br>$$<br>$A_iX$ 执行的是沿着第$i$条射线的投影运算，$p_i$ 是在第 $i $个探测像元上测到的投影数据，$\left|A_{i}\right|^{2}=\sum_{j} a_{i j}^{2}$是沿着第 $i$ 条射线上各“贡献”因子的平方和，$cA^{T}<em>{i}$ 是把数值 $c $沿着第$ i$ 条射线做反投影。如果我们把上面的算法改写成下面的形式 .<br>$$<br>X^{\text {next }}=X^{\text {current }}-\left(\frac{A</em>{i} X^{\text {current }}}{\left|A_{i}\right|}-\frac{p_{i}}{\left|A_{i}\right|}\right) \frac{A_{i}^{T}}{\left|A_{i}\right|}<br>$$<br>该算法的几何意义就比较明显了:</p><p><img src="/2020/06/05/%E8%BF%AD%E4%BB%A3%E9%87%8D%E5%BB%BA%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3/image-20200604233955301.png" alt="image-20200604233955301"></p><h3 id="最大期望极大似然算法（ML-EM，Maximum-Likelihood-Expectation-Maximization）"><a href="#最大期望极大似然算法（ML-EM，Maximum-Likelihood-Expectation-Maximization）" class="headerlink" title="最大期望极大似然算法（ML-EM，Maximum-Likelihood Expectation-Maximization）"></a>最大期望极大似然算法（ML-EM，Maximum-Likelihood Expectation-Maximization）</h3><p><img src="/2020/06/05/%E8%BF%AD%E4%BB%A3%E9%87%8D%E5%BB%BA%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3/image-20200604234408677.png" alt="image-20200604234408677"></p><p><img src="/2020/06/05/%E8%BF%AD%E4%BB%A3%E9%87%8D%E5%BB%BA%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3/image-20200604234429947.png" alt="image-20200604234429947"></p><p><img src="/2020/06/05/%E8%BF%AD%E4%BB%A3%E9%87%8D%E5%BB%BA%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3/image-20200604234506653.png" alt="image-20200604234506653"></p><p><img src="/2020/06/05/%E8%BF%AD%E4%BB%A3%E9%87%8D%E5%BB%BA%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3/image-20200604234525715.png" alt="image-20200604234525715"></p><p><img src="/2020/06/05/%E8%BF%AD%E4%BB%A3%E9%87%8D%E5%BB%BA%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3/image-20200604234558326.png" alt="image-20200604234558326"></p><p><img src="/2020/06/05/%E8%BF%AD%E4%BB%A3%E9%87%8D%E5%BB%BA%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3/image-20200604234618809.png" alt="image-20200604234618809"></p><p><img src="/2020/06/05/%E8%BF%AD%E4%BB%A3%E9%87%8D%E5%BB%BA%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3/image-20200604234633400.png" alt="image-20200604234633400"></p><p><strong>参考文献：</strong></p><p>[1] 曾更生，医学图像重建</p>]]></content>
    
    <summary type="html">
    
      迭代重建的基本思想
    
    </summary>
    
    
      <category term="图像重建" scheme="https://Hubery-Lee.github.io/categories/%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA/"/>
    
    
      <category term="迭代重建" scheme="https://Hubery-Lee.github.io/tags/%E8%BF%AD%E4%BB%A3%E9%87%8D%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>PET_SPECT成像与CT成像的区别</title>
    <link href="https://hubery-lee.github.io/2020/06/03/PET-SPECT%E6%88%90%E5%83%8F%E4%B8%8ECT%E6%88%90%E5%83%8F%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>https://hubery-lee.github.io/2020/06/03/PET-SPECT%E6%88%90%E5%83%8F%E4%B8%8ECT%E6%88%90%E5%83%8F%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2020-06-03T12:38:26.000Z</published>
    <updated>2020-06-04T16:25:51.276Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PET-SPECT成像与CT成像的区别"><a href="#PET-SPECT成像与CT成像的区别" class="headerlink" title="PET/SPECT成像与CT成像的区别"></a>PET/SPECT成像与CT成像的区别</h1><h2 id="成像原理的区别"><a href="#成像原理的区别" class="headerlink" title="成像原理的区别"></a>成像原理的区别</h2><p>PET和SPECT是属于发射成像，CT属于透射成像。</p><p>所谓发射型成像就是把放射源放在病人身体的内部，放射线从病人身体内部射出，最后被探测器接收。 具有短半衰期的放射性的原子可以由回旋加速器或核反应堆生产出来。这些放射性元素再用来制造放射性药物。 通常放射性药物是通过手臂静脉血管注射而进入体内的。放射性药物进入人体后会跟踪病理过程。放射性药物也可以通过病人的呼吸道或消化道进入人体。放射性药物实际上是个分子载体，它依附于特定的生理组织或病理过程。放射性物质在药物的带领下在人体内做有目的的分布。发射型断层成像的目的就是要得到一个放射<br>性物质在人体内部的分布图。 </p><p><img src="/2020/06/03/PET-SPECT%E6%88%90%E5%83%8F%E4%B8%8ECT%E6%88%90%E5%83%8F%E7%9A%84%E5%8C%BA%E5%88%AB/image-20200603105809886.png" alt="image-20200603105809886"></p><p>PET和SPECT的主要区别是采用的核药不同，PET全程叫正电子发射成像，通常采用的是能够发射正电子的核药，如==C-11，N-13，O-15和 F-18==，在放射性衰退时会释放出正电子 (即带一个正电荷的电子)。正电子在自然界中生存的时间十分短暂，因为在自然界中正电子很快就会遇到一个 (带负电的) 电子。当正电子与电子发生作用时，它们的质量会湮灭 (即完全消失)，它们的质量完全转换为能量而产生出两个能量为 511 keV 的伽玛光子。这两个光子沿着相隔 180º 角的方向传播。也就是说，它们在一条直线上朝相反的方向射出。有一种特殊的伽玛照相机可专门用来检测这一对光子。这种特殊的伽玛照相机运用的是同时检测技术。当两个探测器同时各接收到一个能量为 511 keV 的伽玛光子时，说明在连接这两个探测器的线段上曾经有过一个正电子。</p><p><img src="/2020/06/03/PET-SPECT%E6%88%90%E5%83%8F%E4%B8%8ECT%E6%88%90%E5%83%8F%E7%9A%84%E5%8C%BA%E5%88%AB/image-20200603110137644.png" alt="image-20200603110137644"></p><p>而SPECT全称叫单光子发射断层成像，采用发射单个光子的核药，如$^{99}Tc、^{131}I、^{113}In、^{67}Ga、^{201}Tl、^{113}Xn$;</p><p><img src="/2020/06/03/PET-SPECT%E6%88%90%E5%83%8F%E4%B8%8ECT%E6%88%90%E5%83%8F%E7%9A%84%E5%8C%BA%E5%88%AB/image-20200603111107360.png" alt="image-20200603111107360"></p><p><img src="/2020/06/03/PET-SPECT%E6%88%90%E5%83%8F%E4%B8%8ECT%E6%88%90%E5%83%8F%E7%9A%84%E5%8C%BA%E5%88%AB/image-20200603111146266.png" alt="image-20200603111146266"></p><h2 id="图像重建方法上的不同点"><a href="#图像重建方法上的不同点" class="headerlink" title="图像重建方法上的不同点"></a>图像重建方法上的不同点</h2><p>发射成像需要对成像介质进行射线衰减修正；</p><p><img src="/2020/06/03/PET-SPECT%E6%88%90%E5%83%8F%E4%B8%8ECT%E6%88%90%E5%83%8F%E7%9A%84%E5%8C%BA%E5%88%AB/image-20200603111313807.png" alt="image-20200603111313807"></p><p><img src="/2020/06/03/PET-SPECT%E6%88%90%E5%83%8F%E4%B8%8ECT%E6%88%90%E5%83%8F%E7%9A%84%E5%8C%BA%E5%88%AB/image-20200603111400117.png" alt="image-20200603111400117"></p><p><img src="/2020/06/03/PET-SPECT%E6%88%90%E5%83%8F%E4%B8%8ECT%E6%88%90%E5%83%8F%E7%9A%84%E5%8C%BA%E5%88%AB/image-20200603111438883.png" alt="image-20200603111438883"></p><p><img src="/2020/06/03/PET-SPECT%E6%88%90%E5%83%8F%E4%B8%8ECT%E6%88%90%E5%83%8F%E7%9A%84%E5%8C%BA%E5%88%AB/image-20200603111455329.png" alt="image-20200603111455329"></p><p><img src="/2020/06/03/PET-SPECT%E6%88%90%E5%83%8F%E4%B8%8ECT%E6%88%90%E5%83%8F%E7%9A%84%E5%8C%BA%E5%88%AB/image-20200603111535455.png" alt="image-20200603111535455"></p><p><img src="/2020/06/03/PET-SPECT%E6%88%90%E5%83%8F%E4%B8%8ECT%E6%88%90%E5%83%8F%E7%9A%84%E5%8C%BA%E5%88%AB/image-20200603111656132.png" alt="image-20200603111656132"></p><p>比较复杂。</p><p><strong>参考文献：</strong></p>]]></content>
    
    <summary type="html">
    
      透射成像和发射成像的区别
    
    </summary>
    
    
      <category term="医学图像重建" scheme="https://Hubery-Lee.github.io/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA/"/>
    
    
      <category term="PET" scheme="https://Hubery-Lee.github.io/tags/PET/"/>
    
      <category term="SPECT" scheme="https://Hubery-Lee.github.io/tags/SPECT/"/>
    
      <category term="CT" scheme="https://Hubery-Lee.github.io/tags/CT/"/>
    
  </entry>
  
  <entry>
    <title>如何搭建感知器并使用其进行分类</title>
    <link href="https://hubery-lee.github.io/2020/06/02/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E6%84%9F%E7%9F%A5%E5%99%A8%E5%B9%B6%E4%BD%BF%E7%94%A8%E5%85%B6%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/"/>
    <id>https://hubery-lee.github.io/2020/06/02/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E6%84%9F%E7%9F%A5%E5%99%A8%E5%B9%B6%E4%BD%BF%E7%94%A8%E5%85%B6%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/</id>
    <published>2020-06-02T15:25:50.000Z</published>
    <updated>2020-06-04T16:26:45.661Z</updated>
    
    <content type="html"><![CDATA[<h1 id="😋如何搭建感知器并使用其进行分类"><a href="#😋如何搭建感知器并使用其进行分类" class="headerlink" title="😋如何搭建感知器并使用其进行分类"></a>😋如何搭建感知器并使用其进行分类</h1><p>[toc]</p><h2 id="💨python-编程基础，需要掌握几个库"><a href="#💨python-编程基础，需要掌握几个库" class="headerlink" title="💨python 编程基础，需要掌握几个库"></a>💨python 编程基础，需要掌握几个库</h2><ul><li>numpy</li><li>pandas</li><li>matplotlib</li></ul><h2 id="💖什么是感知器？"><a href="#💖什么是感知器？" class="headerlink" title="💖什么是感知器？"></a>💖什么是感知器？</h2><h3 id="🎈神经元与机器学习感知机"><a href="#🎈神经元与机器学习感知机" class="headerlink" title="🎈神经元与机器学习感知机"></a>🎈神经元与机器学习感知机</h3><p>信号在神经元中的传播过程如下：信号通过神经粒质与神经元树突结合，通过神经细胞的认知处理（分类等），由神经末梢输出信号。</p><p><img src="/2020/06/02/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E6%84%9F%E7%9F%A5%E5%99%A8%E5%B9%B6%E4%BD%BF%E7%94%A8%E5%85%B6%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/image-20200602160802363.png" alt="image-20200602160802363"><img src="/2020/06/02/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E6%84%9F%E7%9F%A5%E5%99%A8%E5%B9%B6%E4%BD%BF%E7%94%A8%E5%85%B6%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/image-20200602161216932.png" alt="image-20200602161216932"></p><p>感知器类似于生物神经系统中的神经元。特征数据$x_1,x_2,...x_m$，作为输入信号，权重因子$\omega_1,\omega_2,...\omega_m$,作信号接收单元，激活函数用于根据$\omega x$输入信号产生输出分类结果。其中，$x_0=1,\omega_0=y_0$</p><p><img src="/2020/06/02/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E6%84%9F%E7%9F%A5%E5%99%A8%E5%B9%B6%E4%BD%BF%E7%94%A8%E5%85%B6%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/image-20200602160731313.png" alt="image-20200602160731313"></p><p>感知机的基本数学原理，既是逻辑回归/线性回归，直白一点就是大学物理实验中的实验数据处理，数据拟合和类似最小二乘法的误差分析；</p><p><img src="/2020/06/02/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E6%84%9F%E7%9F%A5%E5%99%A8%E5%B9%B6%E4%BD%BF%E7%94%A8%E5%85%B6%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/1.png" alt></p><p>为了使拟合或分类效果最好，需要求一组$\omega$,要求方差最小即下式最小：$\widehat y$为预测数据，${(i)}$为第i个样本，下标为特征</p><p>$$<br>\begin{equation}<br>J(\boldsymbol{w})=\frac{1}{2} \sum_{i}\left(y^{(i)}-\widehat y^{(i)}\right)^{2}<br>\end{equation}<br>$$</p><p>线性回归或逻辑回归得目的是根据已有数据发现规律或现象，建立相应得模型，最终目的是利用模型进行预测；机器学习算法就是一种事物规律建模技术。训练机器学习算法，并用其对新的数据进行预测或分类。</p><p><img src="/2020/06/02/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E6%84%9F%E7%9F%A5%E5%99%A8%E5%B9%B6%E4%BD%BF%E7%94%A8%E5%85%B6%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/image-20200602220300807.png" alt="image-20200602220300807"></p><p><img src="/2020/06/02/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E6%84%9F%E7%9F%A5%E5%99%A8%E5%B9%B6%E4%BD%BF%E7%94%A8%E5%85%B6%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/image-20200602220058431.png" alt="image-20200602220058431"></p><p>机器学习算法的核心既是获得较合理的$\omega$, 要想获得$\omega$就需要利用数据集对算法进行训练。样本数据输入，预测值$\widehat y$与实际值之间会有偏差。要求训练样本足够多的情况下，偏差变小，逐渐收敛。那么，每个训练样本进行训练时，均需对权重因子进行更新。</p><p>$$<br>w_{j}:=w_{j}+\Delta w_{j}\<br>$$</p><h3 id="🚲最简单的感知机"><a href="#🚲最简单的感知机" class="headerlink" title="🚲最简单的感知机"></a>🚲最简单的感知机</h3><p>权重更新方法如下<br>$$<br>\begin{equation}\Delta w_{j}=\eta\left(y^{(i)}-\hat{y}^{(i)}\right) x_{j}^{(i)}\end{equation}<br>$$<br>其中，$\eta$成为学习率<br><img src="/2020/06/02/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E6%84%9F%E7%9F%A5%E5%99%A8%E5%B9%B6%E4%BD%BF%E7%94%A8%E5%85%B6%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/2.png" alt></p><h3 id="🛴自适应线性神经元与学习的收敛性"><a href="#🛴自适应线性神经元与学习的收敛性" class="headerlink" title="🛴自适应线性神经元与学习的收敛性"></a>🛴自适应线性神经元与学习的收敛性</h3><p>其采用线性激活函数$\phi(z)=z$，那么；<br><img src="/2020/06/02/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E6%84%9F%E7%9F%A5%E5%99%A8%E5%B9%B6%E4%BD%BF%E7%94%A8%E5%85%B6%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/3.png" alt><br><img src="/2020/06/02/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E6%84%9F%E7%9F%A5%E5%99%A8%E5%B9%B6%E4%BD%BF%E7%94%A8%E5%85%B6%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/image-20200602223450727.png" alt="image-20200602223450727"></p><p>权重更新采用梯度下降法：<br><img src="/2020/06/02/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E6%84%9F%E7%9F%A5%E5%99%A8%E5%B9%B6%E4%BD%BF%E7%94%A8%E5%85%B6%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/4.png" alt></p><h2 id="🍜如何搭建感知机并进行分类？"><a href="#🍜如何搭建感知机并进行分类？" class="headerlink" title="🍜如何搭建感知机并进行分类？"></a>🍜如何搭建感知机并进行分类？</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"></span><br><span class="line"><span class="comment"># # Implementing a perceptron learning algorithm in Python</span></span><br><span class="line"><span class="comment"># ## An object-oriented perceptron API</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Perceptron</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Perceptron classifier.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ------------</span></span><br><span class="line"><span class="string">    eta : float</span></span><br><span class="line"><span class="string">      Learning rate (between 0.0 and 1.0)</span></span><br><span class="line"><span class="string">    n_iter : int</span></span><br><span class="line"><span class="string">      Passes over the training dataset.</span></span><br><span class="line"><span class="string">    random_state : int</span></span><br><span class="line"><span class="string">      Random number generator seed for random weight</span></span><br><span class="line"><span class="string">      initialization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Attributes</span></span><br><span class="line"><span class="string">    -----------</span></span><br><span class="line"><span class="string">    w_ : 1d-array</span></span><br><span class="line"><span class="string">      Weights after fitting.</span></span><br><span class="line"><span class="string">    errors_ : list</span></span><br><span class="line"><span class="string">      Number of misclassifications (updates) in each epoch.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, eta=<span class="number">0.01</span>, n_iter=<span class="number">50</span>, random_state=<span class="number">1</span></span>):</span></span><br><span class="line">        self.eta = eta</span><br><span class="line">        self.n_iter = n_iter</span><br><span class="line">        self.random_state = random_state</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Fit training data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : &#123;array-like&#125;, shape = [n_samples, n_features]</span></span><br><span class="line"><span class="string">          Training vectors, where n_samples is the number of samples and</span></span><br><span class="line"><span class="string">          n_features is the number of features.</span></span><br><span class="line"><span class="string">        y : array-like, shape = [n_samples]</span></span><br><span class="line"><span class="string">          Target values.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        self : object</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        rgen = np.random.RandomState(self.random_state)</span><br><span class="line">        self.w_ = rgen.normal(loc=<span class="number">0.0</span>, scale=<span class="number">0.01</span>, size=<span class="number">1</span> + X.shape[<span class="number">1</span>])</span><br><span class="line">        self.errors_ = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.n_iter):</span><br><span class="line">            errors = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> xi, target <span class="keyword">in</span> <span class="built_in">zip</span>(X, y):</span><br><span class="line">                update = self.eta * (target - self.predict(xi))</span><br><span class="line">                self.w_[<span class="number">1</span>:] += update * xi</span><br><span class="line">                self.w_[<span class="number">0</span>] += update</span><br><span class="line">                errors += <span class="built_in">int</span>(update != <span class="number">0.0</span>)</span><br><span class="line">            self.errors_.append(errors)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">net_input</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Calculate net input&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> np.dot(X, self.w_[<span class="number">1</span>:]) + self.w_[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Return class label after unit step&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> np.where(self.net_input(X) &gt;= <span class="number">0.0</span>, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ## Training a perceptron model on the Iris dataset</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ### Reading-in the Iris data</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;https://archive.ics.uci.edu/ml/&#x27;</span></span><br><span class="line">        <span class="string">&#x27;machine-learning-databases/iris/iris.data&#x27;</span>, header=<span class="literal">None</span>)</span><br><span class="line">df.tail()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># ### Note:</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># You can find a copy of the Iris dataset (and all other datasets used in this book) in the code bundle of this book, which you can use if you are working offline or the UCI server at https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data is temporarily unavailable. For instance, to load the Iris dataset from a local directory, you can replace the line </span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#     df = pd.read_csv(&#x27;https://archive.ics.uci.edu/ml/&#x27;</span></span><br><span class="line"><span class="comment">#         &#x27;machine-learning-databases/iris/iris.data&#x27;, header=None)</span></span><br><span class="line"><span class="comment">#  </span></span><br><span class="line"><span class="comment"># by</span></span><br><span class="line"><span class="comment">#  </span></span><br><span class="line"><span class="comment">#     df = pd.read_csv(&#x27;your/local/path/to/iris.data&#x27;, header=None)</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;iris.data&#x27;</span>, header=<span class="literal">None</span>)</span><br><span class="line">df.tail()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ### Plotting the Iris data</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># select setosa and versicolor</span></span><br><span class="line">y = df.iloc[<span class="number">0</span>:<span class="number">100</span>, <span class="number">4</span>].values</span><br><span class="line">y = np.where(y == <span class="string">&#x27;Iris-setosa&#x27;</span>, -<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># extract sepal length and petal length</span></span><br><span class="line">X = df.iloc[<span class="number">0</span>:<span class="number">100</span>, [<span class="number">0</span>, <span class="number">2</span>]].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot data</span></span><br><span class="line">plt.scatter(X[:<span class="number">50</span>, <span class="number">0</span>], X[:<span class="number">50</span>, <span class="number">1</span>],</span><br><span class="line">            color=<span class="string">&#x27;red&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;setosa&#x27;</span>)</span><br><span class="line">plt.scatter(X[<span class="number">50</span>:<span class="number">100</span>, <span class="number">0</span>], X[<span class="number">50</span>:<span class="number">100</span>, <span class="number">1</span>],</span><br><span class="line">            color=<span class="string">&#x27;blue&#x27;</span>, marker=<span class="string">&#x27;x&#x27;</span>, label=<span class="string">&#x27;versicolor&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length [cm]&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;petal length [cm]&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.savefig(&#x27;images/02_06.png&#x27;, dpi=300)</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ### Training the perceptron model</span></span><br><span class="line">ppn = Perceptron(eta=<span class="number">0.1</span>, n_iter=<span class="number">10</span>)</span><br><span class="line">ppn.fit(X, y)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(ppn.errors_) + <span class="number">1</span>), ppn.errors_, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Number of updates&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.savefig(&#x27;images/02_07.png&#x27;, dpi=300)</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ### A function for plotting decision regions</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_decision_regions</span>(<span class="params">X, y, classifier, resolution=<span class="number">0.02</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># setup marker generator and color map</span></span><br><span class="line">    markers = (<span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;^&#x27;</span>, <span class="string">&#x27;v&#x27;</span>)</span><br><span class="line">    colors = (<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;lightgreen&#x27;</span>, <span class="string">&#x27;gray&#x27;</span>, <span class="string">&#x27;cyan&#x27;</span>)</span><br><span class="line">    cmap = ListedColormap(colors[:<span class="built_in">len</span>(np.unique(y))])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot the decision surface</span></span><br><span class="line">    x1_min, x1_max = X[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">    x2_min, x2_max = X[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),</span><br><span class="line">                           np.arange(x2_min, x2_max, resolution))</span><br><span class="line">    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)</span><br><span class="line">    Z = Z.reshape(xx1.shape)</span><br><span class="line">    plt.contourf(xx1, xx2, Z, alpha=<span class="number">0.3</span>, cmap=cmap)</span><br><span class="line">    plt.xlim(xx1.<span class="built_in">min</span>(), xx1.<span class="built_in">max</span>())</span><br><span class="line">    plt.ylim(xx2.<span class="built_in">min</span>(), xx2.<span class="built_in">max</span>())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot class samples</span></span><br><span class="line">    <span class="keyword">for</span> idx, cl <span class="keyword">in</span> <span class="built_in">enumerate</span>(np.unique(y)):</span><br><span class="line">        plt.scatter(x=X[y == cl, <span class="number">0</span>], </span><br><span class="line">                    y=X[y == cl, <span class="number">1</span>],</span><br><span class="line">                    alpha=<span class="number">0.8</span>, </span><br><span class="line">                    c=colors[idx],</span><br><span class="line">                    marker=markers[idx], </span><br><span class="line">                    label=cl, </span><br><span class="line">                    edgecolor=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plot_decision_regions(X, y, classifier=ppn)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length [cm]&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;petal length [cm]&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.savefig(&#x27;images/02_08.png&#x27;, dpi=300)</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#################################################################</span></span><br><span class="line"><span class="comment">## Adaptive linear neurons and the convergence of learning</span></span><br><span class="line"><span class="comment"># ...</span></span><br><span class="line"><span class="comment"># ## Minimizing cost functions with gradient descent</span></span><br><span class="line"><span class="comment"># ## Implementing an adaptive linear neuron in Python</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdalineGD</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;ADAptive LInear NEuron classifier.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ------------</span></span><br><span class="line"><span class="string">    eta : float</span></span><br><span class="line"><span class="string">      Learning rate (between 0.0 and 1.0)</span></span><br><span class="line"><span class="string">    n_iter : int</span></span><br><span class="line"><span class="string">      Passes over the training dataset.</span></span><br><span class="line"><span class="string">    random_state : int</span></span><br><span class="line"><span class="string">      Random number generator seed for random weight</span></span><br><span class="line"><span class="string">      initialization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Attributes</span></span><br><span class="line"><span class="string">    -----------</span></span><br><span class="line"><span class="string">    w_ : 1d-array</span></span><br><span class="line"><span class="string">      Weights after fitting.</span></span><br><span class="line"><span class="string">    cost_ : list</span></span><br><span class="line"><span class="string">      Sum-of-squares cost function value in each epoch.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, eta=<span class="number">0.01</span>, n_iter=<span class="number">50</span>, random_state=<span class="number">1</span></span>):</span></span><br><span class="line">        self.eta = eta</span><br><span class="line">        self.n_iter = n_iter</span><br><span class="line">        self.random_state = random_state</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; Fit training data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : &#123;array-like&#125;, shape = [n_samples, n_features]</span></span><br><span class="line"><span class="string">          Training vectors, where n_samples is the number of samples and</span></span><br><span class="line"><span class="string">          n_features is the number of features.</span></span><br><span class="line"><span class="string">        y : array-like, shape = [n_samples]</span></span><br><span class="line"><span class="string">          Target values.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        self : object</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        rgen = np.random.RandomState(self.random_state)</span><br><span class="line">        self.w_ = rgen.normal(loc=<span class="number">0.0</span>, scale=<span class="number">0.01</span>, size=<span class="number">1</span> + X.shape[<span class="number">1</span>])</span><br><span class="line">        self.cost_ = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n_iter):</span><br><span class="line">            net_input = self.net_input(X)</span><br><span class="line">            <span class="comment"># Please note that the &quot;activation&quot; method has no effect</span></span><br><span class="line">            <span class="comment"># in the code since it is simply an identity function. We</span></span><br><span class="line">            <span class="comment"># could write `output = self.net_input(X)` directly instead.</span></span><br><span class="line">            <span class="comment"># The purpose of the activation is more conceptual, i.e.,  </span></span><br><span class="line">            <span class="comment"># in the case of logistic regression (as we will see later), </span></span><br><span class="line">            <span class="comment"># we could change it to</span></span><br><span class="line">            <span class="comment"># a sigmoid function to implement a logistic regression classifier.</span></span><br><span class="line">            output = self.activation(net_input)</span><br><span class="line">            errors = (y - output)</span><br><span class="line">            self.w_[<span class="number">1</span>:] += self.eta * X.T.dot(errors)</span><br><span class="line">            self.w_[<span class="number">0</span>] += self.eta * errors.<span class="built_in">sum</span>()</span><br><span class="line">            cost = (errors**<span class="number">2</span>).<span class="built_in">sum</span>() / <span class="number">2.0</span></span><br><span class="line">            self.cost_.append(cost)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">net_input</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Calculate net input&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> np.dot(X, self.w_[<span class="number">1</span>:]) + self.w_[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">activation</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Compute linear activation&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Return class label after unit step&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> np.where(self.activation(self.net_input(X)) &gt;= <span class="number">0.0</span>, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(nrows=<span class="number">1</span>, ncols=<span class="number">2</span>, figsize=(<span class="number">10</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">ada1 = AdalineGD(n_iter=<span class="number">10</span>, eta=<span class="number">0.01</span>).fit(X, y)</span><br><span class="line">ax[<span class="number">0</span>].plot(<span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(ada1.cost_) + <span class="number">1</span>), np.log10(ada1.cost_), marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_ylabel(<span class="string">&#x27;log(Sum-squared-error)&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">&#x27;Adaline - Learning rate 0.01&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ada2 = AdalineGD(n_iter=<span class="number">10</span>, eta=<span class="number">0.0001</span>).fit(X, y)</span><br><span class="line">ax[<span class="number">1</span>].plot(<span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(ada2.cost_) + <span class="number">1</span>), ada2.cost_, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_ylabel(<span class="string">&#x27;Sum-squared-error&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">&#x27;Adaline - Learning rate 0.0001&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.savefig(&#x27;images/02_11.png&#x27;, dpi=300)</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ## Improving gradient descent through feature scaling</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># standardize features</span></span><br><span class="line">X_std = np.copy(X)</span><br><span class="line">X_std[:, <span class="number">0</span>] = (X[:, <span class="number">0</span>] - X[:, <span class="number">0</span>].mean()) / X[:, <span class="number">0</span>].std()</span><br><span class="line">X_std[:, <span class="number">1</span>] = (X[:, <span class="number">1</span>] - X[:, <span class="number">1</span>].mean()) / X[:, <span class="number">1</span>].std()</span><br><span class="line"></span><br><span class="line">ada = AdalineGD(n_iter=<span class="number">15</span>, eta=<span class="number">0.01</span>)</span><br><span class="line">ada.fit(X_std, y)</span><br><span class="line"></span><br><span class="line">plot_decision_regions(X_std, y, classifier=ada)</span><br><span class="line">plt.title(<span class="string">&#x27;Adaline - Gradient Descent&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length [standardized]&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;petal length [standardized]&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line"><span class="comment"># plt.savefig(&#x27;images/02_14_1.png&#x27;, dpi=300)</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(ada.cost_) + <span class="number">1</span>), ada.cost_, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Sum-squared-error&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line"><span class="comment"># plt.savefig(&#x27;images/02_14_2.png&#x27;, dpi=300)</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ## Large scale machine learning and stochastic gradient descent</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdalineSGD</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;ADAptive LInear NEuron classifier.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ------------</span></span><br><span class="line"><span class="string">    eta : float</span></span><br><span class="line"><span class="string">      Learning rate (between 0.0 and 1.0)</span></span><br><span class="line"><span class="string">    n_iter : int</span></span><br><span class="line"><span class="string">      Passes over the training dataset.</span></span><br><span class="line"><span class="string">    shuffle : bool (default: True)</span></span><br><span class="line"><span class="string">      Shuffles training data every epoch if True to prevent cycles.</span></span><br><span class="line"><span class="string">    random_state : int</span></span><br><span class="line"><span class="string">      Random number generator seed for random weight</span></span><br><span class="line"><span class="string">      initialization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Attributes</span></span><br><span class="line"><span class="string">    -----------</span></span><br><span class="line"><span class="string">    w_ : 1d-array</span></span><br><span class="line"><span class="string">      Weights after fitting.</span></span><br><span class="line"><span class="string">    cost_ : list</span></span><br><span class="line"><span class="string">      Sum-of-squares cost function value averaged over all</span></span><br><span class="line"><span class="string">      training samples in each epoch.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, eta=<span class="number">0.01</span>, n_iter=<span class="number">10</span>, shuffle=<span class="literal">True</span>, random_state=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.eta = eta</span><br><span class="line">        self.n_iter = n_iter</span><br><span class="line">        self.w_initialized = <span class="literal">False</span></span><br><span class="line">        self.shuffle = shuffle</span><br><span class="line">        self.random_state = random_state</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; Fit training data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : &#123;array-like&#125;, shape = [n_samples, n_features]</span></span><br><span class="line"><span class="string">          Training vectors, where n_samples is the number of samples and</span></span><br><span class="line"><span class="string">          n_features is the number of features.</span></span><br><span class="line"><span class="string">        y : array-like, shape = [n_samples]</span></span><br><span class="line"><span class="string">          Target values.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        self : object</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self._initialize_weights(X.shape[<span class="number">1</span>])</span><br><span class="line">        self.cost_ = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n_iter):</span><br><span class="line">            <span class="keyword">if</span> self.shuffle:</span><br><span class="line">                X, y = self._shuffle(X, y)</span><br><span class="line">            cost = []</span><br><span class="line">            <span class="keyword">for</span> xi, target <span class="keyword">in</span> <span class="built_in">zip</span>(X, y):</span><br><span class="line">                cost.append(self._update_weights(xi, target))</span><br><span class="line">            avg_cost = <span class="built_in">sum</span>(cost) / <span class="built_in">len</span>(y)</span><br><span class="line">            self.cost_.append(avg_cost)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partial_fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Fit training data without reinitializing the weights&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.w_initialized:</span><br><span class="line">            self._initialize_weights(X.shape[<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">if</span> y.ravel().shape[<span class="number">0</span>] &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">for</span> xi, target <span class="keyword">in</span> <span class="built_in">zip</span>(X, y):</span><br><span class="line">                self._update_weights(xi, target)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self._update_weights(X, y)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_shuffle</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Shuffle training data&quot;&quot;&quot;</span></span><br><span class="line">        r = self.rgen.permutation(<span class="built_in">len</span>(y))</span><br><span class="line">        <span class="keyword">return</span> X[r], y[r]</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_initialize_weights</span>(<span class="params">self, m</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Initialize weights to small random numbers&quot;&quot;&quot;</span></span><br><span class="line">        self.rgen = np.random.RandomState(self.random_state)</span><br><span class="line">        self.w_ = self.rgen.normal(loc=<span class="number">0.0</span>, scale=<span class="number">0.01</span>, size=<span class="number">1</span> + m)</span><br><span class="line">        self.w_initialized = <span class="literal">True</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_update_weights</span>(<span class="params">self, xi, target</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Apply Adaline learning rule to update the weights&quot;&quot;&quot;</span></span><br><span class="line">        output = self.activation(self.net_input(xi))</span><br><span class="line">        error = (target - output)</span><br><span class="line">        self.w_[<span class="number">1</span>:] += self.eta * xi.dot(error)</span><br><span class="line">        self.w_[<span class="number">0</span>] += self.eta * error</span><br><span class="line">        cost = <span class="number">0.5</span> * error**<span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> cost</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">net_input</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Calculate net input&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> np.dot(X, self.w_[<span class="number">1</span>:]) + self.w_[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">activation</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Compute linear activation&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Return class label after unit step&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> np.where(self.activation(self.net_input(X)) &gt;= <span class="number">0.0</span>, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ada = AdalineSGD(n_iter=<span class="number">15</span>, eta=<span class="number">0.01</span>, random_state=<span class="number">1</span>)</span><br><span class="line">ada.fit(X_std, y)</span><br><span class="line"></span><br><span class="line">plot_decision_regions(X_std, y, classifier=ada)</span><br><span class="line">plt.title(<span class="string">&#x27;Adaline - Stochastic Gradient Descent&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length [standardized]&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;petal length [standardized]&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line"><span class="comment"># plt.savefig(&#x27;images/02_15_1.png&#x27;, dpi=300)</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(ada.cost_) + <span class="number">1</span>), ada.cost_, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Average Cost&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line"><span class="comment"># plt.savefig(&#x27;images/02_15_2.png&#x27;, dpi=300)</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">ada.partial_fit(X_std[<span class="number">0</span>, :], y[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># # Summary</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- </span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># Readers may ignore the following cell</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      神经元与机器学习感知器
    
    </summary>
    
    
      <category term="机器学习" scheme="https://Hubery-Lee.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="感知器" scheme="https://Hubery-Lee.github.io/tags/%E6%84%9F%E7%9F%A5%E5%99%A8/"/>
    
      <category term="神经元" scheme="https://Hubery-Lee.github.io/tags/%E7%A5%9E%E7%BB%8F%E5%85%83/"/>
    
  </entry>
  
  <entry>
    <title>二维图像重建的一般流程</title>
    <link href="https://hubery-lee.github.io/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/"/>
    <id>https://hubery-lee.github.io/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/</id>
    <published>2020-06-02T15:01:15.000Z</published>
    <updated>2020-07-12T16:32:49.772Z</updated>
    
    <content type="html"><![CDATA[<h1 id="二维图像重建的一般流程"><a href="#二维图像重建的一般流程" class="headerlink" title="二维图像重建的一般流程"></a>二维图像重建的一般流程</h1><p>[toc]</p><h2 id="❓什么是图像重建？"><a href="#❓什么是图像重建？" class="headerlink" title="❓什么是图像重建？"></a>❓什么是图像重建？</h2><p>断层成像顾名思义就是要得到一个物体内部的截面图像。比如你想知道西瓜里面是什么样的，最简单的办法就是把西瓜切开 (图1.1)。显然对病人来说，这是万不可行之举。我们真想有个办法，不用动刀，就可把病人内部看得清清楚楚。</p><p>另一个例子。你想到一个美丽的街心公园去参观。可惜，公园正在维修，游人不得入内。你只好在公园的外围走走，拍几张照片。公园<br>内有两棵参天大树，极为壮观。你在公园的东面和南面对公园拍了照 ，颇为满意。回到家后，你用你的得意照片，居然画出了公园地图，并确定了那两棵树的位置 (图1.2右)。其实，要确定那两棵树的位置并不难。你只要把那两张照片按原本的方位放好。从照片上的每棵树画出一条垂线。</p><p><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200601090416943.png" alt="image-20200601090416943"><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200601090501929.png" alt="image-20200601090501929"></p><h2 id="💫图像重建的算法思想是什么？"><a href="#💫图像重建的算法思想是什么？" class="headerlink" title="💫图像重建的算法思想是什么？"></a>💫图像重建的算法思想是什么？</h2><p>断层成像是个数学问题。让我们一起做个有趣的数学习题吧。这里有个 2x2 的矩阵。 矩阵中的元素的数值暂时保密。我给你一些暗示： 第一行的和是 5。第二行的和是 4。第一列的和是 7。第二列的和是 2 (图1.3)。你可以算出这个 2x2 矩阵吗?</p><p><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200601090809554.png" alt="image-20200601090809554"></p><p>这个问题可以用解方程组的方法解决。设那些矩阵元素为未知数，列一个线性方程组：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>x_1+x_2=5;\<br>x_3+x_4=4;\<br>x_1+x_3=7;\<br>x_2+x_4=2;\<br>\end{aligned}<br>\end{equation}<br>$$</p><p>解这个方程组便得到;</p><p>$$<br>\begin{equation}x_1=3,x_2=2,x_3=4,x_4=0\end{equation}<br>$$<br>通过探测物体的投影数据，重建出物体的实际内部构造。这就是图像重建的一般思想。</p><h2 id="✔图像重建算法的数学基础有哪些？"><a href="#✔图像重建算法的数学基础有哪些？" class="headerlink" title="✔图像重建算法的数学基础有哪些？"></a>✔图像重建算法的数学基础有哪些？</h2><h3 id="🍕中心切片定理"><a href="#🍕中心切片定理" class="headerlink" title="🍕中心切片定理"></a>🍕中心切片定理</h3><p>中心切片定理是断层成像的理论基础。这个定理还有其它的称谓，如投影切片定理和傅里叶中心切片定理。二维图像的中心切片定理指出：二维函数 f(x, y) 的投影 p(s) 之傅里叶变换 P(ω) 等于函数 f(x, y) 的傅里叶变换 F(ωx, ωy) 沿与探测器平行的方向过原点的片段。</p><p><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200601104859436.png" alt="image-20200601104859436"></p><p><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200601105629394.png" alt></p><h3 id="🚩为什么要引入滤波？"><a href="#🚩为什么要引入滤波？" class="headerlink" title="🚩为什么要引入滤波？"></a>🚩为什么要引入滤波？</h3><p><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200601105835965.png" alt><br><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200601105911448.png" alt></p><p>第二个方案通常被称作处理FBP (Filtered Backprojection 先滤波后反投影) 算法。第二个方案比第一个方案知名度高得多。在断层成像领域里，函数|ω| 被称作斜坡滤波器。</p><h3 id="❤有哪些滤波重建方法？"><a href="#❤有哪些滤波重建方法？" class="headerlink" title="❤有哪些滤波重建方法？"></a>❤有哪些滤波重建方法？</h3><p>==<strong>滤波的思想</strong>==：在中心切片定理中，旋转中心被切片涂抹的更浓密，这将导致图像像素比较均匀（低频区域；高频区域是指图像对比度比较大的图像边缘区域），进而重构的图像中心区域比较模糊。那么滤波器的思想是将中心切片函数乘以一个与旋转中心距离相关的权重因子，使得切片在图像上涂抹的比较均匀。这样重构出来的图像才不会出现旋转中心模糊的现象。下面介绍一下有哪些图像重建及滤波方法。</p><h4 id="🛴方法1"><a href="#🛴方法1" class="headerlink" title="🛴方法1"></a>🛴方法1</h4><p><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200601111126392.png" alt></p><h4 id="🛵方法2"><a href="#🛵方法2" class="headerlink" title="🛵方法2"></a>🛵方法2</h4><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/ image-20200601111254399.png" alt="image-20200601111254399" style="zoom:80%;"><p><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200601111254399.png" alt></p><h4 id="🏍方法3"><a href="#🏍方法3" class="headerlink" title="🏍方法3"></a>🏍方法3</h4><p><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200601111406287.png" alt><br><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200601111430225.png" alt></p><h4 id="🧭算法一览表"><a href="#🧭算法一览表" class="headerlink" title="🧭算法一览表"></a>🧭算法一览表</h4><p><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200601111533233.png" alt></p><h2 id="👼扇形束投影算法如何转换到平行束投影算法"><a href="#👼扇形束投影算法如何转换到平行束投影算法" class="headerlink" title="👼扇形束投影算法如何转换到平行束投影算法"></a>👼扇形束投影算法如何转换到平行束投影算法</h2><p>==<strong>基本思想</strong>==：根据利用点扩散函数的移动不变性，可将扇形束投影重组成平行束投影；然而，在进行重组时将需要进行插值运算，这将导入不必要的误差。故而需要根据重组变换原理，采用变量替换原理，将适用于平行束投影算法中的变量替换成扇形束中的转换关系。</p><h3 id="🍚点扩散函数的移动不变性"><a href="#🍚点扩散函数的移动不变性" class="headerlink" title="🍚点扩散函数的移动不变性"></a>🍚点扩散函数的移动不变性</h3><p><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200602082326836.png" alt="image-20200602082326836"></p><p>对于平行光束成像，我们用极为重要的中心切片定理推导出了一些图像重建的算法。可是，对与扇形束成像，我们并没有相应的中心切片定理。我们只好想个别的办法来推导扇形束的图像重建算法。这个办法就是把扇形束的成像问题转化成平行光束的成像问题，把平行光束图像重建的算法修正一下然后应用于解决扇形束的成像问题中。 </p><p>假定探测器是匀速地绕物体转动，而且数据采样的角度区间也是均匀的。在这个假设下，平行光束的投影/反投影的点扩散函数 (PSF) 是移动不变的。换句话说，如果你把一个点源放在 x-y 平面上。放到哪里到无所谓，只要放在探测器的视野内就好。</p><p><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200602083037903.png" alt="image-20200602083037903"></p><p><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200602083341855.png" alt="image-20200602083341855"></p><h3 id="🍳扇形束射线如何用平行束来描述"><a href="#🍳扇形束射线如何用平行束来描述" class="headerlink" title="🍳扇形束射线如何用平行束来描述"></a>🍳扇形束射线如何用平行束来描述</h3><p>一个直截了当的方法是把所有的扇形束射线放在一起进行分组，把互相平行的射线分在一组，这样就把扇形束的成像问题简化为平行光束的成像问题。正如图3.4所示，每一条扇形束的射线都刚好对应一条平行光束的射线。这两条线是完全重合的。也就是说，每一个扇形束的数据 g(γ, β) 都刚好对应一个平行光束的数据 p(s, θ)，它们的坐标满足下列关系:<br>$$<br>\theta = \gamma +\beta \<br>s=Dsin\gamma<br>$$<br>其中 $$D$$ 为焦距，也就是从扇形的焦点到旋转中心的距离。当上面这两个关系成立时，这两个成像系统所测的数据是相同的:<br>$$<br>p(s,\theta)=g(\gamma,\beta)<br>$$<br><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200602083414444.png" alt="image-20200602083414444"></p><p><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200602084149649.png" alt="image-20200602084149649"></p><p><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200602084308687.png" alt="image-20200602084308687"></p><p><img src="/2020/06/02/%E4%BA%8C%E7%BB%B4%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%B5%81%E7%A8%8B/image-20200602084333949.png" alt="image-20200602084333949"></p><p><strong>参考文献：</strong></p><p>[1] 曾更生，医学图像重建</p>]]></content>
    
    <summary type="html">
    
      描述二维CT图像重建算法的一般思想
    
    </summary>
    
    
      <category term="图像重建" scheme="https://Hubery-Lee.github.io/categories/%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA/"/>
    
    
      <category term="二维CT图像重建" scheme="https://Hubery-Lee.github.io/tags/%E4%BA%8C%E7%BB%B4CT%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>利用VSCode调试Geant4项目和Qt项目</title>
    <link href="https://hubery-lee.github.io/2020/05/19/%E5%88%A9%E7%94%A8VSCode%E8%B0%83%E8%AF%95Geant4%E9%A1%B9%E7%9B%AE%E5%92%8CQt%E9%A1%B9%E7%9B%AE/"/>
    <id>https://hubery-lee.github.io/2020/05/19/%E5%88%A9%E7%94%A8VSCode%E8%B0%83%E8%AF%95Geant4%E9%A1%B9%E7%9B%AE%E5%92%8CQt%E9%A1%B9%E7%9B%AE/</id>
    <published>2020-05-19T12:57:46.000Z</published>
    <updated>2020-05-19T13:10:14.414Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🌌利用VSCode调试Geant4项目和Qt项目"><a href="#🌌利用VSCode调试Geant4项目和Qt项目" class="headerlink" title="🌌利用VSCode调试Geant4项目和Qt项目"></a>🌌利用VSCode调试Geant4项目和Qt项目</h1><p>==<strong>注意</strong>==</p><ul><li><p>VSCode只是一个具有用户交互界面、可设置断点调试的集成开发环境，并具有编辑器的一些特色功能，如：代码补全、格式自动化和语法自动检查等。直白的理解，他是一个具有很多集成功能的高端编辑器，属于前端，代码的编译链接执行需要交给其他一些软件，如CMake等。</p></li><li><p>Geant4和Qt均是基于c++语言，调试程序需要用gdb。那么，调试geant4和Qt程序与调试C++程序一样没有什么区别。</p></li></ul><h2 id="🧭c-如何开启调试模式"><a href="#🧭c-如何开启调试模式" class="headerlink" title="🧭c++如何开启调试模式"></a>🧭c++如何开启调试模式</h2><p>C++单文件编译</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">g++ main.cpp -o a.out</span><br></pre></td></tr></table></figure><p>C++单文件gdb调试</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">g++ -g main.cpp -o a.out</span><br><span class="line">gdb a.out</span><br></pre></td></tr></table></figure><h2 id="🚀geant4-和qt等项目文件如何用调试"><a href="#🚀geant4-和qt等项目文件如何用调试" class="headerlink" title="🚀geant4 和qt等项目文件如何用调试"></a>🚀geant4 和qt等项目文件如何用调试</h2><p>C++项目的链接通常采用可采用CMake，需要编写<code>CMakeLists.txt</code><br>如需打开调试模式，只需奖<code>CMAKE_BUILD_TYPE</code> 设置成<code>&quot;Debug&quot;</code>模式即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set(CMAKE_BUILD_TYPE &quot;Debug&quot;)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      vscode在手，天下我有
    
    </summary>
    
    
      <category term="编程工具学习与应用" scheme="https://Hubery-Lee.github.io/categories/%E7%BC%96%E7%A8%8B%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%BA%94%E7%94%A8/"/>
    
    
      <category term="vscode" scheme="https://Hubery-Lee.github.io/tags/vscode/"/>
    
  </entry>
  
  <entry>
    <title>科学上网方法</title>
    <link href="https://hubery-lee.github.io/2020/05/08/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E6%96%B9%E6%B3%95/"/>
    <id>https://hubery-lee.github.io/2020/05/08/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E6%96%B9%E6%B3%95/</id>
    <published>2020-05-07T16:07:51.000Z</published>
    <updated>2020-05-07T16:29:32.614Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🚚科学上网方法"><a href="#🚚科学上网方法" class="headerlink" title="🚚科学上网方法"></a>🚚科学上网方法</h1><h2 id="⚓google-bing检索"><a href="#⚓google-bing检索" class="headerlink" title="⚓google/bing检索"></a>⚓google/bing检索</h2><ul><li><code>谷歌上网助手</code></li><li><code>iGuge插件</code></li></ul><p>安装方法：</p><p><img src="/2020/05/08/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E6%96%B9%E6%B3%95/a.png" alt></p><h2 id="🚍文献搜索神器"><a href="#🚍文献搜索神器" class="headerlink" title="🚍文献搜索神器"></a>🚍文献搜索神器</h2><p><a href="https://www.researcher-app.com/"><code>researcher</code></a></p>]]></content>
    
    <summary type="html">
    
      推荐两款谷歌上网插件
    
    </summary>
    
    
      <category term="软件体验" scheme="https://Hubery-Lee.github.io/categories/%E8%BD%AF%E4%BB%B6%E4%BD%93%E9%AA%8C/"/>
    
    
      <category term="google" scheme="https://Hubery-Lee.github.io/tags/google/"/>
    
  </entry>
  
  <entry>
    <title>用VSCode的IDE调试CPP</title>
    <link href="https://hubery-lee.github.io/2020/05/05/%E7%94%A8VSCode%E7%9A%84IDE%E8%B0%83%E8%AF%95CPP/"/>
    <id>https://hubery-lee.github.io/2020/05/05/%E7%94%A8VSCode%E7%9A%84IDE%E8%B0%83%E8%AF%95CPP/</id>
    <published>2020-05-05T01:46:08.000Z</published>
    <updated>2020-05-05T01:50:09.856Z</updated>
    
    <content type="html"><![CDATA[<h1 id="💘VSCODE-IDE在C-C-项目编程中的使用"><a href="#💘VSCODE-IDE在C-C-项目编程中的使用" class="headerlink" title="💘VSCODE IDE在C/C++项目编程中的使用"></a>💘VSCODE IDE在C/C++项目编程中的使用</h1><h2 id="🌴IDE的作用"><a href="#🌴IDE的作用" class="headerlink" title="🌴IDE的作用"></a>🌴IDE的作用</h2><p>IDE的作用就是有用户交互界面的代码调试编辑器（也称集成开发环境，Integrated Development Environment）</p><h3 id="💨c-c-编程主要基于两类编译器"><a href="#💨c-c-编程主要基于两类编译器" class="headerlink" title="💨c/c++编程主要基于两类编译器"></a>💨c/c++编程主要基于两类编译器</h3><ul><li>gcc, <code>开源、更新较快</code></li><li>visual studio,<code>微软全家桶</code></li></ul><p>所有linux系统的均是用gcc，linux系统对c/c++的支持更好。linux系统的核心代码基本是用c/c++编写的。</p><p>windows系统上c/c++编程一般用<code>visual studio</code>,当然，为了用到与linux上一样的开源gcc编译器，可以在windows上安装<code>mingw</code>或者<code>cywin</code>两种中的任意一款编译器。</p><h3 id="🛴gcc编译器的没有图形Debug界面"><a href="#🛴gcc编译器的没有图形Debug界面" class="headerlink" title="🛴gcc编译器的没有图形Debug界面"></a>🛴gcc编译器的没有图形Debug界面</h3><p>visual studio自带的调试界面，编程比较方便。gcc的调试需要用<code>gdb</code>,而gdb存在的缺陷是其没有采用命令行调试，需要记住的命令太多，但缺少图像界面，大大降低了编程人员的生成效率。</p><p>由于gdb自身没有合适的IDE,项目配置通常用<code>makefile</code>。makefile继承linux系统下万物用命令行解决的风格。为了避免编写令人难懂的makefile文件，程序员开发了用于生成makefile的<code>cmake</code>工具 .</p><p>gcc等属于开源社区的软件，特点是版本多，没有统一的标准。导致很多公司开发了各自的IDE，如，JetBrain 公司的<code>Cion</code>, 微软公司的<code>VSCode</code>和IBM公司的<code>eclipse</code>等。VSCode,Cion和Eclipse均是top5的c/c++编辑器。其中，VSCode是后起之秀，由微软2015年发布的快平台编辑器。网上介绍较多，再此不再细说，感兴趣的同志可以自己去百度或谷歌一下。下面将介绍VSCode的C++代码调试。</p><h2 id="🚀VSCode"><a href="#🚀VSCode" class="headerlink" title="🚀VSCode"></a>🚀VSCode</h2><p>VSCode是一款IDE编辑器，注意是<code>编辑器</code>说白了就跟<code>记事本</code>一样，只是它额外具备配置编译环境和调试代码的功能。就跟notepat++很像。项目的编译环境配置文件通常由两个组成<code>task.json</code>和<code>launch.json</code>。</p><ul><li>task.json <code>负责配置生成可执行文件</code></li><li>launch.json <code>负责调试</code></li></ul><p>具体VSCode的使用文件可以参考<span class="exturl" data-url="aHR0cHM6Ly9jb2RlLnZpc3VhbHN0dWRpby5jb20vZG9jcw==">官方说明文档<i class="fa fa-external-link-alt"></i></span><br>下面分别从单文件调试和项目文件调试两个方面进行测试，具体测试文档可参看<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVRLNHkxODdrbg==">我的哔哩哔哩视频<i class="fa fa-external-link-alt"></i></span></p><h3 id="🚲单文件，单步调试"><a href="#🚲单文件，单步调试" class="headerlink" title="🚲单文件，单步调试"></a>🚲单文件，单步调试</h3><ul><li><p>配置生成可执行文件task.json</p></li><li><p>配置调试执行文件lauch.json</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;version&quot;: &quot;2.0.0&quot;,</span><br><span class="line">    &quot;tasks&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;type&quot;: &quot;shell&quot;,</span><br><span class="line">            &quot;label&quot;: &quot;C&#x2F;C++: cpp.exe build active file&quot;,</span><br><span class="line">            &quot;command&quot;: &quot;D:\\Qt\\Tools\\mingw730_64\\bin\\cpp.exe&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;-g&quot;,</span><br><span class="line">                &quot;$&#123;file&#125;&quot;,</span><br><span class="line">                &quot;-o&quot;,</span><br><span class="line">                &quot;$&#123;fileDirname&#125;\\$&#123;fileBasenameNoExtension&#125;.exe&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;options&quot;: &#123;</span><br><span class="line">                &quot;cwd&quot;: &quot;D:\\Qt\\Tools\\mingw730_64\\bin&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;problemMatcher&quot;: [</span><br><span class="line">                &quot;$gcc&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;group&quot;: &quot;build&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; 使用 IntelliSense 了解相关属性。 </span><br><span class="line">    &#x2F;&#x2F; 悬停以查看现有属性的描述。</span><br><span class="line">    &#x2F;&#x2F; 欲了解更多信息，请访问: https:&#x2F;&#x2F;go.microsoft.com&#x2F;fwlink&#x2F;?linkid&#x3D;830387</span><br><span class="line">    &quot;version&quot;: &quot;0.2.0&quot;,</span><br><span class="line">    &quot;configurations&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;g++.exe - 生成和调试活动文件&quot;,</span><br><span class="line">            &quot;type&quot;: &quot;cppdbg&quot;,</span><br><span class="line">            &quot;request&quot;: &quot;launch&quot;,</span><br><span class="line">            &quot;program&quot;: &quot;$&#123;fileDirname&#125;\\$&#123;fileBasenameNoExtension&#125;.exe&quot;,</span><br><span class="line">            &quot;args&quot;: [],</span><br><span class="line">            &quot;stopAtEntry&quot;: false,</span><br><span class="line">            &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;&quot;,</span><br><span class="line">            &quot;environment&quot;: [],</span><br><span class="line">            &quot;externalConsole&quot;: false,</span><br><span class="line">            &quot;MIMode&quot;: &quot;gdb&quot;,</span><br><span class="line">            &quot;miDebuggerPath&quot;: &quot;D:\\Qt\\Tools\\mingw730_64\\bin\\gdb.exe&quot;,</span><br><span class="line">            &quot;setupCommands&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;description&quot;: &quot;为 gdb 启用整齐打印&quot;,</span><br><span class="line">                    &quot;text&quot;: &quot;-enable-pretty-printing&quot;,</span><br><span class="line">                    &quot;ignoreFailures&quot;: true</span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            &quot;preLaunchTask&quot;: &quot;g++.exe build active file&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="🚍项目文件，单步调试"><a href="#🚍项目文件，单步调试" class="headerlink" title="🚍项目文件，单步调试"></a>🚍项目文件，单步调试</h3><ul><li>CMake <code>负责配置生成可执行文件</code></li><li>launch.json <code>负责调试</code></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">cmake_minimum_required(VERSION 3.10.0)</span><br><span class="line"># 定义项目名称变量PROJECT_NAME, 默认值为demo</span><br><span class="line">set(PROJECT_NAME demo)</span><br><span class="line"></span><br><span class="line">set(CMAKE_BUILD_TYPE &quot;Debug&quot;)</span><br><span class="line"></span><br><span class="line">set(CMAKE_CXX_STANDARD_REQUIRED 14)</span><br><span class="line">#----------------------------------------------------------------------------</span><br><span class="line"># Setup include directory for this project</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line">include_directories($&#123;PROJECT_SOURCE_DIR&#125;&#x2F;include)</span><br><span class="line">#----------------------------------------------------------------------------</span><br><span class="line"># Locate sources and headers for this project</span><br><span class="line"># NB: headers are included so they will show up in IDEs</span><br><span class="line">#</span><br><span class="line">file(GLOB sources $&#123;PROJECT_SOURCE_DIR&#125;&#x2F;src&#x2F;*.cc)</span><br><span class="line">file(GLOB headers $&#123;PROJECT_SOURCE_DIR&#125;&#x2F;include&#x2F;*.h)</span><br><span class="line"></span><br><span class="line"># 指定生成目标</span><br><span class="line">add_executable($&#123;PROJECT_NAME&#125; main.cc $&#123;sources&#125; $&#123;headers&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &#x2F;&#x2F; 使用 IntelliSense 了解相关属性。 </span><br><span class="line">    &#x2F;&#x2F; 悬停以查看现有属性的描述。</span><br><span class="line">    &#x2F;&#x2F; 欲了解更多信息，请访问: https:&#x2F;&#x2F;go.microsoft.com&#x2F;fwlink&#x2F;?linkid&#x3D;830387</span><br><span class="line">    &quot;version&quot;: &quot;0.2.0&quot;,</span><br><span class="line">    &quot;configurations&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;(gdb) 启动&quot;,</span><br><span class="line">            &quot;type&quot;: &quot;cppdbg&quot;,</span><br><span class="line">            &quot;request&quot;: &quot;launch&quot;,</span><br><span class="line">            &quot;program&quot;: &quot;$&#123;workspaceFolder&#125;\\build\\demo.exe&quot;,</span><br><span class="line">            &quot;args&quot;: [],</span><br><span class="line">            &quot;stopAtEntry&quot;: false,</span><br><span class="line">            &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;&quot;,</span><br><span class="line">            &quot;environment&quot;: [],</span><br><span class="line">            &quot;externalConsole&quot;: false,</span><br><span class="line">            &quot;MIMode&quot;: &quot;gdb&quot;,</span><br><span class="line">            &quot;miDebuggerPath&quot;: &quot;D:\\Qt\\Tools\\mingw730_64\\bin\\gdb.exe&quot;,</span><br><span class="line">            &quot;setupCommands&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;description&quot;: &quot;为 gdb 启用整齐打印&quot;,</span><br><span class="line">                    &quot;text&quot;: &quot;-enable-pretty-printing&quot;,</span><br><span class="line">                    &quot;ignoreFailures&quot;: true</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      VSCode你值得拥有。跨平台IDE编辑器VSCode，有了她你还要什么emacs?
    
    </summary>
    
    
      <category term="编程工具学习与应用" scheme="https://Hubery-Lee.github.io/categories/%E7%BC%96%E7%A8%8B%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%BA%94%E7%94%A8/"/>
    
    
      <category term="VSCode" scheme="https://Hubery-Lee.github.io/tags/VSCode/"/>
    
  </entry>
  
</feed>
